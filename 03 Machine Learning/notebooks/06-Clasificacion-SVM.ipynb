{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtnNtgWcU2Cc"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/03%20Machine%20Learning/notebooks/06-Clasificacion-SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmWhZfIxi6yU"
      },
      "source": [
        "# Clasificación: SVM\n",
        "\n",
        "En esta notebook trabajaremos la tarea de clasificación, además, mostraremos el uso del clasificador **SVM** (Support Vector Machine). Realizaremos un ejemplo con datos artificiales, con fines didácticos.\n",
        "\n",
        "Nos enfocaremos en los siguientes puntos:\n",
        "*   Uso de kernels.\n",
        "*   Efecto del parámetro $C$.\n",
        "*   Busqueda de hiperparámetros.\n",
        "*   Balanceo de clases.\n",
        "\n",
        "Usaremos la implementación de sklearn, llamada [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) (Support Vector Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glVe2E6ySpTP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DFox_ShDikzl"
      },
      "outputs": [],
      "source": [
        "#@title Funciones que necesitamos para graficar las fronteras de decisión\n",
        "\n",
        "def make_meshgrid(x, y, h=.02):\n",
        "    '''\n",
        "    función para hacer la malla de puntos para colorear las regiones de decisión,\n",
        "    la malla de puntos abarca la región donde se encuentran los puntos (x,y)\n",
        "    'h' es el tamaño de paso\n",
        "    '''\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, Z, **params)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Los primeros dos ejemplos son datasets artificiales, con fines ilustrativos**"
      ],
      "metadata": {
        "id": "xjhp3dYza856"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPf7wz7oWJos"
      },
      "source": [
        "## Ejemplo 1: Un caso linealmente separable\n",
        "\n",
        "En este primer ejemplo mostramos el uso básico del SVM como clasificador en un ejemplo ilustrativo con datos linealmente separables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDIhdWoGRZy"
      },
      "source": [
        "### El conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos la función [`make_blobs`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) que genera conjuntos de datos sintéticos formados por grupos (blobs) de puntos normalmente distribuidos."
      ],
      "metadata": {
        "id": "qHuGyi9McFbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rISP5BlIWWyq"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(n_samples=200,\n",
        "                  n_features=2,\n",
        "                  centers=2,\n",
        "                  random_state=57)\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[:,0], X[:,1],\n",
        "            c=y # Observar que el color lo especificamos con el arreglo de etiquetas\n",
        "            )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos el vector de etiquetas"
      ],
      "metadata": {
        "id": "5HIq5XFVIWez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "DJfDNImQWD0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4onAUGdhD7J"
      },
      "source": [
        "Veamos el balance entre etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egU7-MYohCZW"
      },
      "outputs": [],
      "source": [
        "print(f\"Instancias de la clase positiva: {y[y==1].shape[0]}. Porcentaje: {round(100*y[y==1].shape[0]/y.shape[0],2)}%\")\n",
        "print(f\"Instancias de la clase negativa: {y[y==0].shape[0]}. Porcentaje: {round(100*y[y==0].shape[0]/y.shape[0],2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ML proceso](https://drive.google.com/uc?id=1S9KVyZbkiciIEeC7cLi-epa62gfFM0pi)\n"
      ],
      "metadata": {
        "id": "RzsSKTWsgB3H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XImNnw5UGTmb"
      },
      "source": [
        "### La división *train/test*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P0AuOI-XPgV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n",
        "\n",
        "print(f\"X Train: {X_train.shape}\")\n",
        "print(f\"X Test: {X_test.shape}\")\n",
        "print(f\"Y Train: {y_train.shape}\")\n",
        "print(f\"Y Test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig4lTWnSGYbw"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vIIG3brra0O"
      },
      "source": [
        "Entrenemos y evaluemos el clasificador en el conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIjejnhTXZT8"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "#---- inicializar la clase ----\n",
        "clf = SVC(kernel='linear') # Sin hiperparametros se tiene C=1\n",
        "\n",
        "#---- entrenar el modelo ----\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#---- evaluar el modelo ----\n",
        "score = clf.score(X_train,y_train)  # Este score es el accuracy\n",
        "print(f\"Accuracy promedio de entrenamiento: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbV3kfepGd85"
      },
      "source": [
        "### Evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghRbg0DQrg7W"
      },
      "source": [
        "Evaluemos varias métricas en el conjunto de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3-71kBdrgu1"
      },
      "outputs": [],
      "source": [
        "clf.score(X_test,y_test)    # Este score es el accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc1KSNHB5n13"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, confusion_matrix\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(cm)\n",
        "plt.colorbar()\n",
        "plt.xticks([0,1])\n",
        "plt.yticks([0,1])\n",
        "plt.xlabel(\"Etiqueta predicha\")\n",
        "plt.ylabel(\"Etiqueta real\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kPTI1KSCMQU"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
        "print(f\"Recall: {recall_score(y_test,y_pred)}\")\n",
        "print(f\"Precision: {precision_score(y_test,y_pred)}\")\n",
        "print(f\"F1 Score: {f1_score(y_test,y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F9TGCOm5K5_"
      },
      "source": [
        "Obtuvimos métricas de rendimiento del 100%, **¿te parece sospechoso?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldaQuO7uENb8"
      },
      "outputs": [],
      "source": [
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "\n",
        "plot_contours(ax2, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaPwxUXhp5Ps"
      },
      "source": [
        "Algunos hiperparámetros:\n",
        "\n",
        "* `C`:  Este parámetro es fundamental para encontrar un equilibrio adecuado entre el ajuste del modelo a los datos de entrenamiento y la capacidad del modelo para generalizar a datos nuevos.\n",
        "* `kernel`: Tipo de kernel usado.\n",
        "\n",
        "\n",
        "Algunos métodos:\n",
        "\n",
        "*   `score()`: Accuracy del clasificador en el conjunto especificado.\n",
        "*   `predict()`: Predecir la clase del conjunto especificado usando el modelo ya entrenado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfUMq7L3cP5q"
      },
      "source": [
        "En este ejemplo, ¿qué efecto tiene el parámetro $C$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seLJmgpxb6ib"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "parametro_c = 0.1\n",
        "\n",
        "clf_c = SVC(C=parametro_c,kernel='linear') # Sin hiperparametros se tiene C=1\n",
        "clf_c.fit(X_train, y_train)\n",
        "clf_c.score(X_train,y_train)  # Este score es el accuracy\n",
        "\n",
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "plot_contours(ax1, clf_c, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "plot_contours(ax2, clf_c, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_c.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "c0QXz9v6ZREI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlqlbDHkTIsl"
      },
      "source": [
        "## Ejemplo 2: Un caso no linealmente separable\n",
        "\n",
        "Ahora, analicemos otro ejemplo *toy* que no sea linealmente separable. Usaremos direntes kernels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awsozxk0i4e9"
      },
      "source": [
        "### El conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX00M-qDi1zU"
      },
      "source": [
        "Creamos un conjunto de datos con una condición XOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDNOtk2FTRDv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "np.random.seed(17) # Fijamos un seed para la reproducibilidad de resultados\n",
        "\n",
        "X = np.random.randn(500, 2)\n",
        "y = np.array([int(np.logical_xor(x[0] > 0, x[1] > 0)) for x in X])  # las etiquetas las asignamos en función de la comparación x0>0 XOR x1>0\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[y==0, 0], X[y==0, 1], color='blue', label='Clase 0')\n",
        "plt.scatter(X[y==1, 0], X[y==1, 1], color='red',label='Clase 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFU_k_FvhpvK"
      },
      "source": [
        "Veamos el balance entre etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR_nNNfDhpvN"
      },
      "outputs": [],
      "source": [
        "print(f\"Instancias de la clase positiva: {y[y==1].shape[0]}. Porcentaje: {round(100*y[y==1].shape[0]/y.shape[0],2)}%\")\n",
        "print(f\"Instancias de la clase negativa: {y[y==0].shape[0]}. Porcentaje: {round(100*y[y==0].shape[0]/y.shape[0],2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy64NizLi95C"
      },
      "source": [
        "### Separación *train/test*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7-Hi2BmTUrd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2023)\n",
        "\n",
        "print(f\"X Train: {X_train.shape}\")\n",
        "print(f\"X Test: {X_test.shape}\")\n",
        "print(f\"Y Train: {y_train.shape}\")\n",
        "print(f\"Y Test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEmnVOw6XJqq"
      },
      "source": [
        "### Clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLnixjtrjGoE"
      },
      "source": [
        "#### Kernel Lineal\n",
        "\n",
        "Entrenemos el clasificador usando el kernel lineal. Observar que, por default, $C=1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt_JmIokV0xU"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccEI8ng4glyU"
      },
      "source": [
        "Observemos el accuracy en el conjunto de entrenamiento y prueba. En este caso, el método `score` de la clase `SVC` calcula el accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZMNw4GybN9X"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy promedio de entrenamiento: {round(clf.score(X_train, y_train),3)}\")\n",
        "print(f\"Accuracy promedio de prueba: {round(clf.score(X_test, y_test),3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI_ajLA3kp_-"
      },
      "source": [
        "Observemos la frontera de decisión calculada por el clasificador y los conjuntos de entrenamiento y prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YGTC1EmOh_nK"
      },
      "outputs": [],
      "source": [
        "#@title Graficar las fronteras de decisión\n",
        "\n",
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "\n",
        "plot_contours(ax2, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRZwWASUlWHl"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(kernel='linear',C=0.005)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Accuracy promedio de entrenamiento: {round(clf.score(X_train, y_train),3)}\")\n",
        "print(f\"Accuracy promedio de prueba: {round(clf.score(X_test, y_test),3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vkWV3cC1lcSH"
      },
      "outputs": [],
      "source": [
        "#@title Graficar las fronteras de decisión\n",
        "\n",
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "\n",
        "plot_contours(ax2, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tldkhHZLkq8P"
      },
      "source": [
        "#### Kernel Polinomial\n",
        "\n",
        "Dado que los datos no son linealmente separables, usemos un kernel no lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkr2Nws7kxAf"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(kernel='poly',gamma=2,degree=2,C=1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Accuracy promedio de entrenamiento: {round(clf.score(X_train, y_train),3)}\")\n",
        "print(f\"Accuracy promedio de prueba: {round(clf.score(X_test, y_test),3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OCZwYJXlF7S"
      },
      "outputs": [],
      "source": [
        "#@title Graficar las fronteras de decisión\n",
        "\n",
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "\n",
        "plot_contours(ax2, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGMoIZhmsUbQ"
      },
      "source": [
        "### ⭕ Ejercicio\n",
        "\n",
        "Probemos otros kernels. Tenemos disponibles varios kernels.\n",
        "\n",
        "Con los mismos conjuntos de prueba y entrenamiento y con $C=1$:\n",
        "\n",
        "1. Repetir el experimento de clasificación de arriba, usando otros kernels.\n",
        "2. En cada caso que pruebes grafica los puntos (los de prueba) y la frontera de decisión.\n",
        "3. En cada caso, reporta el valor de accuracy y F1 score, usando el conjunto de prueba solamente.\n",
        "\n",
        "**¿Qué kernel parece dar mejores métricas de rendimiento?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY4JoakxsULC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2023)\n",
        "\n",
        "'''\n",
        "------------------------\n",
        "COMPLETA EL CÓDIGO:\n",
        "* Usa un kernel que no sea lineal con C=1\n",
        "* Obten el accuracy en el conjunto de entrenamiento\n",
        "* Genera las predicciones sobre el conjunto de prueba\n",
        "* Reporta las métricas Accuracy y F1-score en el conjunto de prueba\n",
        "* Grafica las fronteras de decisión\n",
        "------------------------\n",
        "'''\n",
        "\n",
        "clf =\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ow4oqaBoiHmm"
      },
      "outputs": [],
      "source": [
        "#@title Graficar las fronteras de decisión\n",
        "\n",
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "\n",
        "plot_contours(ax2, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqs84jSTs43l"
      },
      "source": [
        "* El kernel lineal es mejor para datos linealmente separables. Es una opción cuando el conjunto de datos es grande.\n",
        "* El kernel Gaussiano (RBF) tiende a dar buenos resultados cuando no se tiene información adicional sobre los datos.\n",
        "* Los kernels polinomiales tienden a dar buenos resultados cuando los datos de entrenamiento están normalizados.\n",
        "\n",
        "[El truco del kernel](https://www.geogebra.org/m/xawkavxe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nXR_1f3m4Yr"
      },
      "source": [
        "⭕ Prueba también con otros valores de `C` y repite los pasos de arriba, ¿qué efecto tiene el modificar este valor en la clasificación y en la frontera de decisión?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2-UV1uOnQyH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2023)\n",
        "\n",
        "'''\n",
        "------------------------\n",
        "COMPLETA EL CÓDIGO:\n",
        "* Usa un kernel Gaussiano con diferentes valores de C\n",
        "* Obten el accuracy en el conjunto de entrenamiento\n",
        "* Genera las predicciones sobre el conjunto de prueba\n",
        "* Reporta las métricas Accuracy y F1-score en el conjunto de prueba\n",
        "* Grafica las fronteras de decisión\n",
        "------------------------\n",
        "'''\n",
        "\n",
        "clf ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3kcKeaCdjZ55"
      },
      "outputs": [],
      "source": [
        "#@title Graficar las fronteras de decisión\n",
        "\n",
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "\n",
        "plot_contours(ax2, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AFz2eTyjT3W"
      },
      "source": [
        "### ⚡ Usando gridsearch para encontrar los mejores parámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC23ZQAg7EpH"
      },
      "source": [
        "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) toma un estimador (por ejemplo, SVM) y un conjunto de parámetros del estimador. Sobre estos parámetros hace una busqueda para encontrar la combinación de parámetros que da mejores resultados en el estimador.\n",
        "\n",
        "GridSearchCV tiene métodos “fit” y “score” method, entre otros. Es decir, no es necesario tomar los parámetros e introducirlos en el estimador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVkQd-v1Z4aV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ymSFVzkcf03"
      },
      "source": [
        "Encuentra los mejores parámetros para el clasificador SVM utilizando grid search. Guíate por el desempeño en el set de entrenamiento y validación.\n",
        "\n",
        "Prueba los siguientes hyperparámetros.\n",
        "* kernel = linear, polynomial, rbf\n",
        "* C = 0.01, 0.1, 1.0, 10, 100\n",
        "* grado del polinomio = 1, 2, 3, 4 (solo para el kernel polinomial)\n",
        "* gamma = auto, scale:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJZKn4kxo7LH"
      },
      "source": [
        "Definimos los parámetros sobre los que se hará la busqueda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fehVJTIZZEmP"
      },
      "outputs": [],
      "source": [
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ('linear', 'poly', 'rbf'),\n",
        "              'degree': [2, 3, 4], 'gamma': ('auto', 'scale')}\n",
        "param_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6-yzMJUI40z"
      },
      "source": [
        "Realizamos una busqueda sobre estos parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_mFhIYkaG_y"
      },
      "outputs": [],
      "source": [
        "clf = SVC()\n",
        "gs = GridSearchCV(clf, param_grid)\n",
        "gs.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OntcfhwVrWgt"
      },
      "source": [
        "Veamos los mejores hiper-parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgCYpURZbCH2"
      },
      "outputs": [],
      "source": [
        "print(f\"Best score: {gs.best_score_:.4f}\")\n",
        "print(f\"Best params: {gs.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n2iAE_IrbCA"
      },
      "source": [
        "Definamos un clasificador SVM con estos mejores hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jclaEUreczue"
      },
      "outputs": [],
      "source": [
        "best_svm = SVC(C=100, kernel='poly', degree=2, gamma='auto')\n",
        "best_svm.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Train mean accuracy: {best_svm.score(X_train, y_train):6.4f}\")\n",
        "print(f\"Test mean accuracy: {best_svm.score(X_test, y_test):6.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_clf = gs.best_estimator_"
      ],
      "metadata": {
        "id": "-oShcfHimO_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_clf.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "TioFQXKImovN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "dIrDzJ2MmvKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE6AWhdh1OV"
      },
      "source": [
        "Graficamos la frontera de decisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTSvVYqTdEwM"
      },
      "outputs": [],
      "source": [
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, ax = plt.subplots(dpi=100)  # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "plot_contours(ax, best_svm, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "ax.set_title('Frontera de decisión del SVM')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 3: Clasificación Binaria\n",
        "\n",
        "Ahora veamos un ejemplo con un dataset real.\n",
        "\n",
        "- **Contenido**: Clasificación de tumores de mama (malignos o benignos)\n",
        "- **Tamaño**: 569 muestras con 30 características\n",
        "- **Target**: Binario (0: benigno, 1: maligno)\n",
        "- **Origen**: Repositorio UCI Machine Learning, Dr. William H. Wolberg (Universidad de Wisconsin)\n",
        "\n",
        "\n",
        "Las características provienen de imágenes digitalizadas de aspiraciones con aguja fina (FNA) de masas mamarias e incluyen:\n",
        "\n",
        "- Radio\n",
        "- Textura\n",
        "- Perímetro\n",
        "- Área\n",
        "- Suavidad\n",
        "- Compacidad\n",
        "- Concavidad\n",
        "- Puntos cóncavos\n",
        "- Simetría\n",
        "- Dimensión fractal\n",
        "\n",
        "Para cada característica, se incluyen:\n",
        "- Valor medio\n",
        "- Error estándar\n",
        "- \"Peor\" valor (media de los tres mayores valores)\n",
        "\n",
        "\n",
        "[Más información](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)"
      ],
      "metadata": {
        "id": "T-5Ap0PISGjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Features clave (5 seleccionadas por simplicidad):\n",
        "# 1. 'mean radius' (tamaño del núcleo celular)\n",
        "# 2. 'mean texture' (variación de color)\n",
        "# 3. 'mean perimeter'\n",
        "# 4. 'mean smoothness' (suavidad de bordes)\n",
        "# 5. 'mean compactness' (circularidad)\n",
        "\n",
        "# Target binario:\n",
        "# 0 = maligno, 1 = benigno (balance: 60%-40% aprox.)\n",
        "cols = ['mean radius', 'mean texture', 'mean perimeter', 'mean smoothness', 'mean compactness']\n",
        "df = pd.DataFrame(X, columns=data.feature_names)[cols]\n",
        "df['target'] = y\n",
        "df"
      ],
      "metadata": {
        "id": "aKOI-e9xSJ08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis Exploratorio"
      ],
      "metadata": {
        "id": "QT-kBS0Rwne-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Hay datos faltantes?"
      ],
      "metadata": {
        "id": "_IA-DBvBwA5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "jMtXjuTBwAXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En un problema de clasificación es muy importante ver el balance de las clases"
      ],
      "metadata": {
        "id": "Nu4eDt6-uS4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import countplot\n",
        "\n",
        "labels = np.unique(y)\n",
        "counts = df['target'].value_counts()\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(labels, counts)\n",
        "plt.xticks(labels)\n",
        "plt.title(\"Distribución de clases\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TB3rizZtUssV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "nSknZU7Tw14c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Impacto de la multicolinealidad en clasificación\n",
        "\n",
        "**Modelos afectados**:\n",
        "\n",
        "- **Modelos lineales**: Inestabilidad en coeficientes (Regresión Logística, SVM lineal).  \n",
        "- **Optimización con L2**: Pesos distorsionados (redes neuronales).  \n",
        "- **Modelos sensibles a escala**: Dominio de features redundantes (KNN, SVM-RBF).  \n",
        "\n",
        "**Modelos no afectados**\n",
        "- **Árboles y ensembles**: Random Forest, XGBoost (seleccionan features por importancia).  \n",
        "- **Reducción de dimensionalidad**: PCA, t-SNE (manejan correlaciones automáticamente).  \n",
        "\n",
        "**Acciones recomendadas**  \n",
        "1. Eliminar features redundantes (matriz de correlación, VIF).  \n",
        "2. Selección de features (SelectKBest, RFE).  \n",
        "3. Regularización (L1/Lasso para eliminar features).  \n",
        "4. PCA si la interpretabilidad no es prioritaria.  \n",
        "\n",
        "En resumen, la ML es crítica en modelos lineales o interpretativos. Es menos relevante en árboles o métodos no lineales. Hay que priorizar según objetivo: explicabilidad vs rendimiento.  "
      ],
      "metadata": {
        "id": "wXC52nN1vfTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import pairplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "pairplot(df, hue='target')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3_EXjt3ouaWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:,:-1].corr()"
      ],
      "metadata": {
        "id": "P-gpbgGauuig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "\n",
        "print(f\"X: {X.shape}\")\n",
        "print(f\"y: {y.shape}\")"
      ],
      "metadata": {
        "id": "NS0AqSxjx3f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de modelos de clasificación"
      ],
      "metadata": {
        "id": "udx29qcaaKDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenemos un primero modelo *baseline*. Sin preprocesamiento.\n",
        "\n",
        "⭕ Completa el código"
      ],
      "metadata": {
        "id": "UySD9pfZqC9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#--- Dividimos en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
        "\n",
        "#--- Inicializa una clase de SVC ---\n",
        "\n",
        "\n",
        "#--- Entrena el clasificador ---\n",
        "\n",
        "\n",
        "#--- Evalua en el conjunto de prueba ---\n",
        "y_pred = ...\n",
        "accuracy = ...\n",
        "f1 = ...\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "id": "9WAEZgrHaRtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora probemos el efecto de diferentes combinaciones de hiperparámetros usando un pipeline. Probemos:\n",
        "\n",
        "* Quitar algunas variables, por ejemplo, las correlacionadas.\n",
        "* Hacer reescalamiento.\n",
        "* Probar varios valores de $C$ y *kernel*.\n",
        "\n",
        "Además, reflexionemos sobre lo siguiente:\n",
        "\n",
        "En diagnóstico médico, se prioriza la **sensibilidad (recall)** para minimizar falsos negativos, ya que es más grave no detectar una enfermedad (ej: cáncer) que tener falsas alarmas. Complementariamente, se analiza el **F1-score** para balancear precisión y sensibilidad, junto con curvas **ROC-AUC** para evaluar el rendimiento general del modelo ante distintos umbrales de decisión."
      ],
      "metadata": {
        "id": "MfeYoS4GtH9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#---- Usando todas las features ---\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "\n",
        "#---- Escogiendo algunas variables ---\n",
        "# X = df[['mean radius', \t'mean texture', 'mean smoothness', 'mean compactness']].values\n",
        "# y = df.iloc[:,-1].values\n",
        "\n",
        "#--- Dividimos en train/test ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.25, random_state=2025)\n",
        "\n",
        "pl = Pipeline([\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('clf', SVC(C=3,kernel='linear'))])\n",
        "\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pl.predict(X_test)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], ['Benigno', 'Maligno'])\n",
        "plt.yticks([0, 1], ['Benigno', 'Maligno'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Los1vkwgtHUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gridsearch"
      ],
      "metadata": {
        "id": "PtbU-EOi0xfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
        "              'kernel': ['linear','rbf'],\n",
        "              'gamma': ['auto','scale']}\n",
        "\n",
        "clf = SVC()\n",
        "gs = GridSearchCV(clf, param_grid)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best score: {gs.best_score_:.4f}\")\n",
        "print(f\"Best params: {gs.best_params_}\")"
      ],
      "metadata": {
        "id": "IYQW7Hoi0zm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡ Retomemos el concepto de overfitting"
      ],
      "metadata": {
        "id": "N60YBhjV0hDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cs = np.logspace(-1,1.7,8)\n",
        "accs_train = []\n",
        "accs_test = []\n",
        "\n",
        "for c in cs:\n",
        "    pl = Pipeline([\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('clf', SVC(C=c,kernel='rbf'))])\n",
        "    pl.fit(X_train, y_train)\n",
        "    y_pred = pl.predict(X_test)\n",
        "    accs_test.append(accuracy_score(y_test, y_pred))\n",
        "    y_pred = pl.predict(X_train)\n",
        "    accs_train.append(accuracy_score(y_train, y_pred))\n",
        "\n",
        "plt.figure()\n",
        "plt.suptitle('C vs Accuracy')\n",
        "plt.plot(cs, accs_train, label='Train')\n",
        "plt.plot(cs, accs_test, label='Test')\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mLhWyB_xzpo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V6MZ3u18jmz"
      },
      "source": [
        "## Ejemplo 4: MNIST\n",
        "\n",
        "Ahora, trabajemos un ejemplo real, con dimensionalidad alta y no linealmente separable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uHRExg5kD_p"
      },
      "source": [
        "### El conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdhiyAZO8l_G"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBvmM8GDehp_"
      },
      "source": [
        "Veamos un para de instancias, con sus respectivas etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkCShEH9BYgF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(X[0].reshape(8,8),cmap='gray')\n",
        "plt.title(y[0])\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(X[1].reshape(8,8),cmap='gray')\n",
        "plt.title(y[1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordar que cada instancia es un vector de 64 entradas:"
      ],
      "metadata": {
        "id": "6pcgtiaK-HMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "2GlMsRAHtbY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eBhMj2loES4"
      },
      "source": [
        "Usando [numpy.unique()](https://numpy.org/doc/stable/reference/generated/numpy.unique.html), veamos el balanceo de las clases:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[150]"
      ],
      "metadata": {
        "id": "lM814nuOr0Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci9SdQyKnsLp"
      },
      "outputs": [],
      "source": [
        "u, c = np.unique(y, return_counts=True)\n",
        "\n",
        "print(f\"Etiquetas:\\n{u}\\n\")\n",
        "print(f\"Conteos de ocurrencia de cada etiqueta:\\n{c}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrB2HrSYn0bw"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.bar(u,c)\n",
        "plt.xticks(u)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GtM1Q0gj9Dk"
      },
      "source": [
        "### Separación train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG5fdfmEBUMI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=99,train_size=0.8)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShprRu5UkGvl"
      },
      "source": [
        "### Clasificación y evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3je8Rkg2BS42"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(X_train,y_train)\n",
        "y_train_pred = clf.predict(X_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(f\"Train Accuracy: {accuracy_score(y_train,y_train_pred)}\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test,y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "0t1anqLlsduz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZJ9Q5Ioe0BP"
      },
      "source": [
        "### ⭕ Ejercicio\n",
        "\n",
        "\n",
        "1. Haz una busqueda de hiperparámetros con GridSearchCV sobre los siguientes parámetros:\n",
        "\n",
        "    *   C: 0.1,1,10,100,1000\n",
        "    *   Kernel: lineal, polinomial (grados 3,5,7), Gaussiano ($\\gamma$ `auto`, 0.1, 1, 10).\n",
        "    *   `coef_0`: 0, 1, 2.\n",
        "\n",
        "2. Usando los mejores parámetros del `GridSearchCV` define un clasificador. Realiza las predicciones sobre el conjunto de prueba y evalua las predicciones usando las métricas accuracy, recall y la matriz de confusión.\n",
        "\n",
        "\n",
        "\n",
        "Reflexiona sobre las siguientes preguntas:\n",
        "\n",
        "1. ¿Por qué el accuracy en el conjunto de entrenamiento no es el mismo que el `best_score_`?\n",
        "2. ¿Por qué el accuracy en el conjunto de prueba no es el mismo que el `best_score_`?\n",
        "3. ¿Qué digitos son los que se están *confundiendo*?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajC79YoAe6Rx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}