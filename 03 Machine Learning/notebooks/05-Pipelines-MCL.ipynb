{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/03%20Machine%20Learning/notebooks/05-Pipelines-MCL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "yHlobrfdVG61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multicolinealidad, Regresi√≥n Polinomial y Pipelines\n",
        "\n",
        "* üîΩ Esta secci√≥n no forma parte del proceso usual de Machine Learning. Es una exploraci√≥n did√°ctica de alg√∫n aspecto del funcionamiento del algoritmo.\n",
        "* ‚ö° Esta secci√≥n incluye t√©cnicas m√°s avanzadas destinadas a optimizar o profundizar en el uso de los algoritmos.\n",
        "* ‚≠ï Esta secci√≥n contiene un ejercicio o pr√°ctica a realizar. A√∫n si no se establece una fecha de entrega, es muy recomendable realizarla para practicar conceptos clave de cada tema.\n"
      ],
      "metadata": {
        "id": "FkEjx6ZOVQAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 1: Multicolinealidad\n",
        "\n",
        "**Impacto de la Multicolinealidad**  \n",
        "* **Para predicci√≥n**: La multicolinealidad no es un problema (mientras no sea perfecta).  \n",
        "* **Para interpretaci√≥n**: Es un problema grave (coeficientes no confiables).  \n",
        "- **Soluciones**:  \n",
        "  - Regularizaci√≥n (Ridge/Lasso).  \n",
        "  - Eliminaci√≥n de variables redundantes.  \n",
        "  - Transformaciones (PCA).  \n",
        "\n",
        "**¬øC√≥mo detectarla?**  \n",
        "- **Matriz de correlaci√≥n** (valores > 0.8 o < -0.8).  \n",
        "- **VIF (Factor de Inflaci√≥n de Varianza)** > 5 o 10. [Implementaci√≥n en statsmodel](https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html)\n",
        "- **An√°lisis de componentes principales (PCA)** (autovalores cercanos a 0).  "
      ],
      "metadata": {
        "id": "wzXXkf8whgvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos el dataset de precios de casas incluido en colab\n",
        "\n",
        "| Columna           | Descripci√≥n                                                                 | Rango en el Dataset            | Tipo de dato |\n",
        "|-------------------|-----------------------------------------------------------------------------|--------------------------------|--------------|\n",
        "| longitude         | Medida de qu√© tan al oeste est√° una casa (valores m√°s altos: m√°s este) | -124.3 a -114.3               | float64      |\n",
        "| latitude          | Medida de qu√© tan al norte est√° una casa (valores m√°s altos: m√°s norte)     | 32.5 a 42.5                   | float64      |\n",
        "| housingMedianAge  | Edad mediana de las casas en un bloque (n√∫mero bajo = edificio nuevo)        | 1.0 a 52.0                    | float64      |\n",
        "| totalRooms        | N√∫mero total de habitaciones en un bloque                                    | 2.0 a 37,937.0                | float64      |\n",
        "| totalBedrooms     | N√∫mero total de dormitorios en un bloque                                     | 1.0 a 6,445.0                 | float64      |\n",
        "| population        | N√∫mero total de personas en un bloque                                        | 3.0 a 35,682.0                | float64      |\n",
        "| households        | N√∫mero total de hogares (grupos de personas en una unidad de vivienda)       | 1.0 a 6,082.0                 | float64      |\n",
        "| medianIncome      | Ingreso mediano por hogar en un bloque (en decenas de miles de USD)          | 0.5 a 15.0                    | float64      |\n",
        "| medianHouseValue  | Valor mediano de las casas en un bloque (en USD)                             | 14,999.0 a 500,001.0          | float64      |"
      ],
      "metadata": {
        "id": "bvtFQhrOpHGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/sample_data/california_housing_train.csv'\n",
        "df = pd.read_csv(path)\n",
        "df"
      ],
      "metadata": {
        "id": "LFzQlS_-O8Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(df['longitude'],df['latitude'],c=df['median_house_value'],cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4SO93ltxCUbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una manera de visualizar la multicolinealidad es ver las **correlaciones entre variables predictoras**"
      ],
      "metadata": {
        "id": "ZdAp154FptnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "corrs = df.corr()\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(corrs,annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PF09IlXETtKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import pairplot\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "pairplot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4MR_8w57GZ3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenemos un modelo de Regresi√≥n Lineal para este conjunto de datos"
      ],
      "metadata": {
        "id": "L1rnDfNK1r0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# ---- Si escogemos todas las variables ----\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df['median_house_value'].values\n",
        "\n",
        "# ---- Si eliminamos algunas variables ----\n",
        "# cols = df.iloc[:,:-1].columns.to_list()\n",
        "# cols_to_remove = ['total_bedrooms','households']\n",
        "# new_cols = [col for col in cols if col not in cols_to_remove]\n",
        "# X = df[new_cols].values\n",
        "# y = df['median_house_value'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=57)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "print(f\"Score en el conjunto de entrenamiento: {lr.score(X_train,y_train)}\") # coefficient of determination of the prediction\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "print(f\"MAE en el conjunto de prueba {mean_absolute_error(y_test,y_pred)}\")\n",
        "print(f\"MAPE en el conjunto de prueba {mean_absolute_percentage_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "id": "RTN_c7ZwT9Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∑ Como podemos confirmar, no es tanto que afecte al rendimiento. Su efecto se puede notar m√°s en la interpretabilidad de los coeficientes.\n",
        "\n",
        "üîΩ **Para observar el efecto de la multicolinealidad realicemos el siguiente experimento**. En cada corrida resampleamos aleatoriamente (con reemplazo) las muestras de entrenamiento y con este nuevo conjunto, hacemos un entrenamiento de regresi√≥n lineal. Luego guardamos los coeficientes del modelo y visualizamos la distribuci√≥n de estos."
      ],
      "metadata": {
        "id": "RNx-Fta7clFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ejemplo Bootstrapping\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "!gdown 1Ki25YePoHOkUItsoXhnFtVvN1cDffd5U\n",
        "\n",
        "# Ruta relativa donde est√° tu archivo en Drive\n",
        "file_path = 'bootstrapping_animation.html'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    html_content = f.read()\n",
        "\n",
        "display(HTML(html_content))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2z7rok_BfLvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[`resample` de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html)"
      ],
      "metadata": {
        "id": "gTbkebualjoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "\n",
        "n_iterations = 100  # N√∫mero de remuestreos\n",
        "coefficients = []\n",
        "\n",
        "cols = df.iloc[:,:-1].columns.to_list()\n",
        "X = df[cols].values\n",
        "y = df['median_house_value'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=57)\n",
        "\n",
        "# ---- En este caso es importante re-escalar para poder comparar entre desviaciones\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# --------------------------------------------------\n",
        "\n",
        "for _ in range(n_iterations):\n",
        "    X_resampled, y_resampled = resample(X_train, y_train,\n",
        "                                        random_state=np.random.randint(100)) # Bootstraping\n",
        "    # Entrenar modelo\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_resampled, y_resampled) # Entrenamos el modelo\n",
        "    coefficients.append(model.coef_) # Guardamos los coeficimientos\n",
        "\n",
        "coef_df = pd.DataFrame(coefficients, columns=cols) # Convertimos a dataframe\n",
        "coef_df.describe().round(2)  # Media, desviaci√≥n est√°ndar, percentiles"
      ],
      "metadata": {
        "id": "rbBOk-9nUWhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(coef_df.iloc[:,2:].values, tick_labels=cols[2:])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Variabilidad de los Coeficientes (Bootstrap)\")\n",
        "plt.ylabel(\"Valor del Coeficiente\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oHJK3fJSX1i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∑ Podemos ver que la desviaci√≥n es grande en las features con multicolinealidad, adem√°s de los cambios de signo."
      ],
      "metadata": {
        "id": "KFRlrXrRlGIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2: Regresi√≥n Polinomial"
      ],
      "metadata": {
        "id": "R2kzDPAshst8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos el siguiente dataset de datos de peces. Hay un total de 159 filas (muestras de entrenamiento) y 7 columnas en el conjunto de datos.\n",
        "\n",
        "Los detalles de cada columna son los siguientes\n",
        "\n",
        "![fishes.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPwAAADRCAYAAADomd+PAAAgAElEQVR4Xu2df8wdVbX35/53sZpci4p6ryhNlWoBITGtRQykhEZjKEKoVkjrjyIogq2giBZtQBAUg5hWEC3+KFERSUlRI8HQFEVqmyYqhQhRq8V7FdSWNxHt+5f33s++WSfr2Z2ZteecmTP7PGdNQugzZ8/ea6+1vnutvc+Z7/qX//7fq/DLNeAamAoN/IsDfirs7JN0DQQNOODdEVwDU6QBB/wUGdun6hpwwLsPuAamSAMO+Ckytk/VNeCAdx9wDUyRBioB/5//9ccpUoNP1TUwezTwH//+0srJ1AJ+7vP/bfZoYQJn8tcDB4sXHDl3AiV3kfvSAD5z9Mv+wwHflwFGGdcBP4r2pvNZB/wE290BP8HG60l0B3xPim9jWAd8G1qcrj4c8BNsbwf8BBuvJ9Ed8D0pvo1hHfBtaHG6+nDAT7C9HfATbLyeRB8L4J966qni29/+dvGXv/wlTPPVr351sWrVqqQpf/zjHy8+/elPJ7Vts9FvfvOb4qtf/WrxsY99rHje85436Jr7DzzwQHHRRRe1OdxQfaUCHh3q63Wve11xxhlnzJjXUAJED23durXYs2dPsNf9998fPl22bFkbXXsfLWmgc8AD9o985CPB8CeccEIQ+9577y2e+9znFh/60IfMaZx77rnF3XffbbZru8Evf/nL4lOf+lTx2te+tvjEJz4x6J773/nOd3pZhOI5pgIeHeo5oP+//vWvxbXXXmuCXvSQYoO//e1vxdNPP13Mnz+/uOOOO4K4qQt72/bz/so10DngP//5zxcveMELDjP8e9/73uKjH/1ocA4uogMZwAtf+MIZ0UcDHifSDqT/5t9LliwJ0Zc+zjnnnBBlfve73xXHHHPMINJwb968ecXOnTuLf/zjH8XrX//6AOr4wtGJ8FxvectbBs/HgOfvRx55JPR13HHHFW94wxvCM9zn+u1vfxvmdfrpp4dF7kc/+lFoe9ZZZxUvfvGLB8NWzb/OcZsAPgYsi9krXvGKgT7JXGKdSGb205/+NMhLVoDM3Jd5iK6Rk/vogsU9BrzY4jnPeU7x1re+1VxoHLDdaKBzwAPQG2+8cYZzx1Mh5TziiCOK5cuXB4chLfzCF74QmmnAx9E+/gyHBMAAFVC9+c1vLo466qji61//erFixYrgiJLeAmKi0T333FMqnwD7gx/8YIiOAARn14Dn35/73OcCaBiHcd/2trcF0OPwP/7xj4t3vetdg3Fe9rKXFW9/+9uLn/3sZ2GOX/nKV8Ic6+bfFeCr5jFnzpzirrvuCvMgIwPY3/rWt4IOWCi5Lr744kHGtn379gIQs8XRfWrA8+9f/epXYe4sgA8++ODAvt24tfdapYHOAW+l5ESWz3zmMwPnR1DAtXjx4uBUTQAvUSyOwtr5ABeOJ1E9/lsUpfvQe9O4b9JY2ePHTk5fkpHE48i8mP/GjRtnAGDt2rXFe97zntLMQxtylAiP3O9+97vDdgl9L126dJCdENF/8IMfhG1LWUqv5xwvHLLd0bqg/4ULF4asi0s/79AcrwZ6B7wGk0xdO0sOgJcozGEjUU/v4UX+v//978XBgwfDIgXI45S2CvA8T5ZB9JfrD3/4Q/G+971vAMC61Trlt/Rli65sWcikkHfu3LkF0Z2LuXDxWRngWRCI7IcOHSqQFdllcSgDvCzqZAKvec1rDtvOjNflp3u0zgGvo7VWNXv7M888M6S7Ek3k89tuuy2kiThiLoAnKpHKnn322YOTaED9+9//vuA8gnR/mAivo2lTVxwlwiMrB3ccnNZlFDHg+XvTpk2D85eUCC/zYo//8MMPhwXulltu8X18U4O30L5zwMs+98Mf/vAgRSWqyT5OgLRhw4ZwgMffl1122cChNOBZAKQdh0Bf/vKXByf4ul3bKb3oGXB+6UtfGkQ0Fi3Zv8pWRA7CUiN8PF/+vvnmm4t169aZgBgW8JJVyNmKBj/zQLfPPvtsSMGJzldeeeVAz3zGAi1nLFXbHT1/9MSWgW2UzFfORFrwYe+igQY6BzyyABQOzp555pkg2qte9aqCwzA5pdZA4kRbDthoq4EsIOc+p8bbtm0bK+AF1KSypLCA4eqrrw4LAGkwKbH8xiAV8KIfWUhIkU855ZSk7/mbAF77BMB7xzveMfiGRBaZJ598MixgHHjqb1AAJ4so2QBbmquuumrQHd/AiD6qDu3E/pzoY19+B5DD7xga4GTWNB0L4EVb1mENAJKv6SZJw23J3bSfVMCn6hL7sHDprwurniU9Z4HTP0qyxmk6P6s//7y5BsYK+Obi+RN1Gmgb8K7t2a8BB/wE29gBP8HG60l0B3xPim9jWAd8G1qcrj4c8BNsbwf8BBuvJ9Ed8D0pvo1hHfBtaHG6+nDAT7C9HfATbLyeRB8J8P/85z97EtuHdQ24BobVwFA01c888/+K5zsv/bA6b+U5t0ErapyqTiyfqSxEYT04VVrsabJug54UP8HDWj7jgM/YuJbxMhbdRetJA5bPOOB7MkzKsJbxUvrwNtOlActnHPAZ+4NlvIxFd9F60oDlMw74ngyTMqxlvJQ+vM10acDyGQd8xv5gGS9j0WetaLxxyFX1FuGf/vSn4iUveUlv87d8phXAf+1rXysee+yxMMkXvehFxfvf//5Gr1U20c53v/vdYteuXYFccrZflvFk/jjhrbfeWvz5z38Ot+CXg8+uq+uTn/xkYArucoyuZB+lX/x8x44dxctf/vLimmuuOawrSGB4/XjRokWBwTjFT3mmTV+2fGZkwAvYITxgkvfdd1+xe/fu4IBdXDg372q/8pWv7KL7rPq0jCfC4jQAEAYbmGwg54Bl9wMf+EAn8yGKcfUZyTqZmNEpTL8ULjnppJMOa/nrX/86MDl973vfC5+l+ik0cPJMG3OyfGZkwONs559//gwlsAiw+uMYv/jFL8JCAD010f9Nb3rTjOj/k5/8JHwGEwufaScimhO19HPSJxTVoliYWWFxgWZZ7vPZz3/+88CxRt+wzEzaImEZTxwkdhqtI3TABTkFuox1xGdlepa+yz6TPsXxcfaHHnoo2ODkk0+e4Qs//OEPi3379gUbwG5UlgrjL9gHxqPYD5gLQYS+8QPYkrhi34Kp58QTTwxtmWcsR52faaAB1DJ/Qkbovt74xjcG/n4NemRhkWUMFl38mAvfF3+s8kVsd9NNN5XOfZgFwPKZkQH/xS9+MRBVksbHKz6TvP7664sFCxYEckgUoKM/SuTv8847L0SmO++8s7jhhhtCPywkGD9+jj6/+c1vhjQI46xZsyYoFWNDniiRjXZwx11wwQVBb5s3bx70PYwi+3jGMp7IhO5JI8sAhY4BXZmOeL5Kz3Wf0ScXi7rYmH+zsMNxjz0BhmR/BAQWHJhwyzI/nF6ABE8+xUVoF9uXz2DhIXORcVkAYPCBCvzII48c+BIkmnAi4kt1fhaDvc6f2MqsXr06LE7a15GThWbLli0h1YfVifmKn9b5op47+GDL8I1vfGNod7N8ZmTAI5nsbfg3jodSWMllonoCOKc4BCnS7bffPlj1WTwkGlMmST9HpGHl1IqU6COpK4qnb1IkPtu7d+9gr2XRbw2t4Q4ftIwnQ8senuIXOD2EkhIJsQ08c1dccUVoLjoCmGyNiC4ahNjnwgsvDOCtsoHUBwDkgICIB2C5iHJwEbIg89nxxx8/kKXKBnGGov/Wz+jFXv9bfFAWIVmsJPOs8rP4DAKfYbERXdEPz0LoCcCRC0CXpfTIw3wlPdfy1fkifWILyXze+c53Bk7BYbNRy2daAbw4HqkdUVZW6Ngo2jCskux5jj322AFkcEwWDFK3qgMP3ScK3r9/fyg9JdcTTzwRFMgFASV9cogVp2Ed4rS1ri3jlQ0kgGNPz0Koo7G0l20YiyfOePTRRw+6gujy0ksvDYtBlQ10nwCCRSbmvGcRwR9YNFjEKdNFulu2768DPPORslfIhqwsJqmAZ+Gq8rP4jKPsMFJvWYcFPItWlS/Gcy/bIjdxKMtnRgY8io9XPIkSCCppjQj92c9+NhwwEa0lGscT0lEi/kwbWjKCutNilE2qRMpXdeDSRKHjbGsZTyJ2fIipM50ywEsU4TmJxk1soPsUW5dFPemTPS57fBYXndHJ51WAlwxRIt4wEZ70usrP4jmX+ZOe37CAl3HKfHHiAI/zrFy5cnA4IaeVRFkiCKsmaSMpCp+tX79+kCKxmlGEUQ42UDiHLRiJvdR1110XnpO9HM4S743Yp7GIkBJJhkFKhnNxSWqLHBSj1Id64wTvMGOlAB4wUWhCdMU4zF32y7LdorgEOmI/z1kJ2yX0eskllwxSSP6Gy55qwFxVNtApfbxloH/OY9A7dpHMSsaSMxqtjyrA0xeVcGXLob+STY3wLERVfhYvUrLAiK7EX6nFxzUs4Ot8ceIAr9M2lHLgwIFwmAOwUCCA5CLlI72OFwcWAy5OYUnNKUSBYxLlicqkcPq5MkPjGLQj5ZOxAQIFFuhTOOWl72HA18czKYBHLuYP8ERX3JOoyH22WLL1QZd6j6j1jP5OPfXUwdd5VTbQEV4WCfoXznvpn+c5LBW+erZrZV8VVgGevvV+mn7wkyYpPaDGR6v8LLarHHKKLrWuhgV8nS9OHOBFYUyKlV0fNmhwovSqgwieZa9V9pVN3XPaWFXt6vruA8RNxkwFvPSJDtCj3idrcNbpctjPZGzAif3L9uipNqzSTVs2bNLPqDKXzaXJ+E38RLe1fGbkPXydYGWHdsNOZBqfs4yXopOyPXzKc95mMjVg+UyngI9/JDOZKuxPast4KZLFP5JJecbbTK4GLJ/pFPCTq7Y8JLeMl4eULkVOGrB8xgGfk7UiWSzjZSy6i9aTBiyfccD3ZJiUYS3jpfThbaZLA5bPOOAz9gfLeBmL7qL1pAHLZyoB/8c/PlUcccS/9iS2D4sGDh36/24Dd4VGGsBnXvrSF1c+4xG+kTrH29harccrjY82CRqwfMYBn7EVLeNlLLqL1pMGLJ9xwPdkmJRhLeOl9OFtpksDls844DP2B8t4GYvuovWkActnHPA9GSZlWMt4KX14m+nSgOUzDviM/cEyXsaiu2g9acDyGQd8T4ZJGdYyXkofk9Ymd9733PVp+cxIgOd9ZwgpNONMGWuIEFtUsaII0UAZG0qs4LZ5vHM2oGU8ZOdtOAhDhFOOe+jorLPOOuxeHR9AKt8/toJdtgsK7Ca871CkQaZi+Uyqv8wWrn3LZ0YCvJBfaLJJXuifO3fuDALKmKivDGRlVFll7ep4vIUltU1i/z4XBMt4yBYTLwqZIguAkEcIEUldrYBUHnXrlWcANmwhjCa878w9xWdSed9nC9e+5TMjAR6lQ3EltEXiWLCS6Hua166KA1247OlTc5EvW7YsZBHQUAtzaBmPtzgijC6nnXbarKiKYhlPdAWzjyy6muFG36MtmVgV73r8KjP6FE5/6K+htRJaauxJBhHXGhD6LJhpNHWZXjTb4n0X+mnJLrW8ugZBKu+7fo2YeZA1VXHt6/nU+Sq2wG8h4YRuHQIYzdOv5ZQxhZsfneP32KCsnkNVILJ8ZmTACyklHGZCtgDooCeG5koTMNRxoMtKLPx19IfSYcGFPmndunWBLLOKx1uKAUDnBM1yHalin1G7ydiW8aQvTW0srKdw8muOfyibhSuwisdf86hTTwD2Wi4cFkBAwSx88LoPWHbIJoRKCpJScfAY7G3xvsOOJD7TBu977KfIzaIG0SdBSqiqy+ZT56v4Ibx+6F6qMkGqyaVrJWA3LuyEvindJmzL2AXQa7qv3gDPyrRz587A143QlJxCSdxDQLmHgFUc6AJk4ZOnckjMNS984HU83tOY0qNXveiSFkO6yLmJVJmRe3U8/jH9d8w1zxgCeHgKZXsgJJpC9FiX0rfJ+868BfBt8L7HgNfVlKqoo6v0qX01LiOlefZ1v/EYeitibaM0+K0gMXKEl4iMwcWxhKEU9k9WdD5DOVUc6Ow3ZYJlhycxVbBWolbUtAJeuNuJqmREOBz3WHRh6iVicK+Ox1+zAcd7aU17XeZ82jnrAN8m77sGfBu878MAvqmvIifVachCyYIPHTo0oE6fGMCjeCl1xESkqmZ8r45rXhuvjINNO2Ady+e0Al4WXRhnpf5a2b06Hn8N5Nj5dKHEUQDfJu+79hmJcKPwvg8D+GF8lTRdSoJNZIRH2ULtKxTRZffqONDL9mOy/5S+pYhEHeBTv1pqso/us62VnmnZcB5opvVeM74nh6plPP4ayHLwJ/z0pO8s2JLSx8VFtE3qvt5qk/c9Tun5u6wGQSoN9DCAl/mk+ipnLdQ6JKMVPMjZ1ERFePkqSIr3ofyye3Uc6NowtKOQBaf98Ng/8MADgwq1dQYUJR48eHBGva4+QTvK2E0AL99h669Iq+6V8fiX8f1T2BCueUo1SSlkK8LLoR7lp8q+BmyL910Dvg3e92EAjwxNfFXXD6BWApccME8U4Js6tcX5HRcd1F/9NR1rkts3AXzTeTaxgQBqlKqmsXzW+E3nQ/tx8L7Hcg3jq13MXeSyfGbkQ7thDFP3jDgXkZ0ywBxCccBR96ORtmXIpT/LeF3JKVFLvj4i26IYZBe/rutqDuPoN0dftXwmO8DLSs13llx8x0vhybKqNOMwap9jWMbrUjZSc4pwcrHwTlJNvi71EvctP7zJxVctn8kS8OM0WM5jWcbLWXaXrR8NWD7jgO/HLkmjWsZL6sQbTZUGLJ9xwGfsDpbxMhbdRetJA5bPOOB7MkzKsJbxUvrwNtOlActnnJc+Y39wXvqMjZOpaM5Ln6lhUsSyVuuUPrzNdGnA8hlP6TP2B8t4GYvuovWkActnHPA9GSZlWMt4KX14m+nSgOUzDviM/cEyXsaiu2g9acDyGQd8T4ZJGdYyXkof3ma6NGD5jAM+Y3+wjJex6C5aTxqwfMYB35NhUoa1jJfSh7eZLg1YPjMy4GExgVkWRs4+rlSedN535v36SXrjyzIe+ob0g0vIH8QGZTUDhrFPG6QiVdzw4/adVF9BT3WU2XV6FFZeSCi5YCCC/Ule/qpjHYo58oaxl+UzIwO+iuBvGGFTnolprCyCP2FShToZwE8SZ71lPPRVVhuA+zDPwGfX9C23WL+pfPV1tqvihu/ad5r6ip4DeuUtwaZvaQJufA1+QS7eONy9e3cgGqUv5vzEE0+UErTA+8Czo/io5TOdA76Ohx5ebuHh5hVYuMa5cDJej4W99oQTTgivyMoFvZLmnhfAl/Gk8wyRDsM9++yzRUzNlLLA9NnGMp7IpmmquSdMslKVBect41hHd+gFlmF0ffLJJwcdaf3GfPVVfWmbwZIjvG3Ikwr4vn1F2xp2GqmFkMpTTzvYmWLAalZhAF9WO0GzQU0s4C0eeri9oEOGVRUCTCG54DlSIT6DiP/RRx8tFi1aFN6Lv+OOO0JboQaq40nXBrQygT6BXTV2KuDj7Yqmgxb9wDfIwgmZBcQW6F7opoRXnYWxTL8xX31ZX9rWMOBu3759YM8UwOfkK9gjJpjknsVTn5JV0S9FOu68884Z1Zl4Fvuw8E4k4CWV1kw1dXTT4hRVzwF4HK0sTavjSRcwzWbAxxRUWs84Uswxv23btuBUZayrdWlw7NDYiuxASBl1+qtBbgEeR0+pWSC27NpXygCfwlOfskWRNlK9B92J/SC0HDULtYJEZyl9Kg99bMSyQyJ90JGyLytzsNkMeHQoICdK69JTHD5BKDlnzpygaiFPZCFuCnir9ht0ZEQoUlaIRKV+gAV4MoKUmgXj8pVxAF6KtUDrLv7NFmJiAZ/KQx8bsQyYmvrYAV++AWD/uHfv3nDoo7+N0NE+frIp4Kv6Eg58SlNJFdsmEZ5zBMk6ymYXLxi6xFQMkDZ8ZVjAl1XWoS/uk8VwgKqzACFnXbt2baAXZxGYWMCn8tDHgBfnER56vUcnpY8zAIs2eRpSeuYoejviiCMGNeW4D6iJuFKXjIUBgOlagLrcd51+ha9eio3I2cE555wTzlQ4HyCt14UrkMGK8NRdu+SSS4qrrroqfL3LXG688cYCXnxds2BcvjIs4HVdRPmaNOaujyslcYLPIo1O28hCx5LS8zWDvnAAnCiVhz52ChyGw6PHH3+8oJoKp75cUv0U5xDueV0iKXYILVMbyiyPrd3dtYwXj8xpsD78lIUA8FCQEz0S/QVYZRE+5vbX+hUgSl9sE6TmPGPz3TPOyzhSfDIF8NQWzMlXhgU8z+G7t912W/jqjYvS6VJsIu6XvTsLpdSia8NHLZ8ZeQ+f4u5Nebhjrm+cSarRpow3W9pYxmsyT3RKZJevPps8G7et6quNMWaTr8R+PIrOU5+1fGYsgE8VVtpJXToOMfjhAmloWbnepv1OWnvLeJM2ny7kdV+ZqVXLZ7IEvPyIg4jEpX+U04XT5NqnZbxc5R6nXO4rswDw43SYnMdywOdsnTxls3wmywifpyrHL5VlvPFL5CPmrgHLZxzwGVvQMl7GortoPWnA8hkHfE+GSRnWMl5KH95mujRg+Yzz0mfsD85Ln7FxMhXNeekzNUyKWNZqndKHt5kuDVg+4yl9xv5gGS9j0V20njRg+YwDvifDpAxrGS+lD28zXRqwfMYBn7E/WMbLWHQXrScNWD7jgO/JMCnDWsZL6cPbTJcGLJ9xwGfsD5bxMhbdRetJA5bPOOB7MkzKsJbxUvrwNtOlActnRgb8uLnFY/NZXOO8XAGdE9RLvKe9atWq3jj0m7qeZTzpD1IFfS1evDi8cCQcc5oFpqkMXbbnLUiumErbsmkXMqX68Sg8/bzvDg0YnARckGIKQ5C8R3/55Zcf9gozPnz11VcXF110kem7ls+MDPgU4r42DZRCcaXHQ76FCxcG2mRetd24cWMh9M1tytVFX5bxZEwYZYSFhns4FSw3woUO0QJXG+/CtznPMgIO+m+DCMKSU3QG+QZXqh8Py9MvBB+QuAhtOgxBy5cvDwsec2ZhZqGOi6WwMN5yyy0Dooy6uVk+0zng++Yaj6uepBrWcphxfG4ZTwNeCCPlno7qOBOXODcOtG/fvpDxUBtAVw2Sz6AJ5zMWSYnAVZz0wl0Pb9sjjzwSKMZ1hsH49ENko86ARLVUwNfx6jMvWHnI4ObNmzcjW2BcaM6FJ//uu+8eMB9v3bo1yAGjL3rBL4i49IWccPSLvrStNU+/NW/9HPx1mvmGz6R+wF133RUAf/PNNxeHDh06LCDxzv+BAwcKoX3LFvC5cY0L59ikkGmMAngdJTWw+Dc8anDTc23evHnAgSefQbuE4+/atSu0gdK6jt8+rg0Abfhxxx0XIpV+jsjGZ5oXn/41p14c4S1e/R07dhQrV64MJJFkb0KkKc/xNxe1D4R2S6Lp6tWrw6JG5iPbIkAPDwO6KPMTrde6eWtQVlUH0m2kXxZLze4kz0Idpqmyq0Bv+UxnET43XnoUlOtedljj1UV4FjeAReSPI6mmXtIZDzTUervDvhaOPABfxkl/7bXXhmIKcQoe/63HixcfC/BNePV132XPscXR1NnCJYcMEuEl+9DVYsqAKYugZpmt2oqkbFGkDaDWdRaE3o2KNlkDPjdeehTHJeytdWlRLp9Zq3Ud4HEgcRwNBMC3ZcuWAGT2+aSQpIpEyMsuu2wACPrWVONlnPRVdNGxg8tBF5z4pKZsEaSoiAX4Jrz6ep6xvHoBZExrD5+y3bAWOrFPE8CzkEjpMDKiNWvWhEWYQ7usAZ8TL72OVLmAOUWOUQCv6am18+pDTCluKI4U00nrE+mYk14DqM7xhdqa50mdm0b4Jrz68Tw1QMqos+MIr9u3CXhszQIUbxHk9D3OFqTGwDHHHBMWZoJU6tmT5TOdpfS58NKjvHvvvXdwYp0CtFzaWMarivCSXYmDaeclelxwwQWD8lBQfsthkiwGRF8OlAAEVNRSlgrnk28DGIPCF2V86noBILOiDzl5jgtFWBG+Ca9+vJggL9z2XHw1SxCSlD7OAGJAtQ14OR9h/ix88nWx6EbrTLCD3EIpnhXgc+alJ2rFl/Dm5wLsKjmaAF73wemy/r2Bdl4WQP4++uijB2WnpDCnOOGePXuKBQsWhBNsqQhTx0lfF+GJrOvXrx+Mh4PzNWlqSh+PW8erH4OUvznU45Se7YresrBgsbWRr8G6Bjz2QR70zzaKi7E5OCTTinXIQqkLS2YD+BTQzCau8ZT5ttUmFfDDjFdmk5hHXVJLfe4xLPd8Ux+I5zTMuHo+ccHNYXTW1jNd8tVbPjNySt+WEnQ/zjX+f9qwjNe27jnrePrpp4uzzz471DkjIul6cW2P12V/pO9SGptx+Ld8VdjluH33bflMloB3rvF+AM+oRHXAzkUhkLIfn/Tt1Knjyw9+aM+Jd/wT3tR+JqndRAJ+khTcpayW8boc2/ueTA1YPpNlhJ9MVbcvtWW89kf0HiddA5bPOOAztrBlvIxFd9F60oDlMw74ngyTMqxlvJQ+vM10acDyGeelz9gfnJc+Y+NkKprz0mdqmBSxrNU6pQ9vM10asHzGU/qM/cEyXsaiu2g9acDyGQd8T4ZJGdYyXkof3ma6NGD5jAM+Y3+wjJex6C5aTxqwfMYB35NhUoa1jJfSh7eZLg1YPuOAz9gfLONlLLqL1pMGLJ9xwPdkmJRhLeOl9OFtpksDls+MDPhUPu+u1G5xmE8DLz265UWRKs7zrnRf1W/MFNz1+JYP6PHLqLpS5MOPYL197LHHQnPIJnmrU7j/wQHv3ceEnLQV5uaYfjpl3KZtOgd86ov5TQWvat+Ulx6jLF26NJANwMQKFfANN9yQHUd72Xwt48kzFud5W7pP7Semykp9LrVdUx/Q/bI48OacADV1TPwI5lheHeaCdhv2X+H+BwcQwfAabtw3LEM8C3NQ15flMyNHeAvwffPS4xx61bXk7dogTfq3jCd9WZznwp9O+05PMzoAAA5ZSURBVJ07d86gqYJVJeaRp/199913GI+8vLYsz6xYsaJ0OhrwEhlhqtG88Ranu5Zh2bJlYbHmdV1e3YUpFgLO0047LdhW2GKgmC7jxddC8vov/Qi/HjTV999/f4jOBIWyYh08A2tsDFjNbItfaZnixRiGoVkP+Nx46YXje9OmTY1X+CZAbattCuBTOc+lqokUgqiyjXD3S4UUzSPPMxArUqQBnnfNVafnLICXvngPHZCx5TjqqKNm8NXLZ5rLXp5jQZk/f354bv/+/YF7j+h8xx13BHJHoeaK+eFpDwtvGUOxXvCRU4pRMB/6hPsuvmKK7jL70u/pp59e3HnnnYG6Wy6eRRZNV9WWfwyTFXYW4XPipZfCAyjo4osvnhgihBTAN6VARgdli4Q4NQCDb14WRU3HxP73uuuuC5Vq6miaBPDx3jWV6bbqOWGZLUvpNZe7rugSgyIGvK7YU7UVSckKpQ3Zh9SME1otFirNXz8rAZ8bLz1KFiZWqXzSpeLb6LsrwJcVRNQEkBxAPfjgg4HIcsmSJYMFUhNgxgUryyI8iwiRmf2rXLLPJUWvKuJQVjBE01Wn7OFTwBu3SXmmyq4CeLYcsm2Sgzyym1kP+Bx46csK/1XRD7cB0Lb7SAE8YzbhPKd9mW3KTpmlmMWiRYtmnIOQIZA2V6WpApy6k2uLyx459dmLPl0fN+BZIIUfXtuY+6TrbEt0FsCZCgfDa9euDVz0cu4wq/fwOfDSS2qn01AqeBCdqg6c2gbtKP2lAr4J5znyyB5Z6wV+ejjQqavGflb2v+LsRFh0t2HDhnD+UXd2oCvSkGrLSbYsFPRdB3g+09+mCL2zFFOMM5SybU1KtE6N8PpMQfwmllEDXuxBZlPG2z+KT1jPWj7Tyh4+Z156nYY++eSTxamnnnpYOV5LiX19bhlPy9WE81yiPMUXOT3mdJmCjELyiPNSFopDOT6TYgjC844jx8+UpfTcE7kYB/0TtaU8cl1dNmGd5XQf2XRtNQkmBw8eDF+DxdsDxm0T8PQn9dvF1+fOnTujGqwGPIGGA0U5c0g5Z2nLxyyfGRnwKYI25SSPD4SkoN4orKNdcoGn6GCYNpbxyvpsOs8q29TxwDe1pwBGl6W29BHPQ9LkHGrcN9WxNdc2P7d8ZiyAbzoh56X/P41Zxmuq10lpL6fbRHa+huO8gIyi7CuzSZnTuOS0fCZLwDsv/XQDntnLD2/4Nwdj/Cim6a/jxgWynMaZSMDnpMA+ZbGM16dsPnaeGrB8JssIn6cqxy+VZbzxS+Qj5q4By2cc8Blb0DJexqK7aD1pwPIZB3xPhkkZ1jJeSh/eZro0YPmM89Jn7A/OS5+xcTIVzXnpMzVMiljWap3Sh7eZLg1YPuMpfcb+YBkvY9FdtJ40YPmMA74nw6QMaxkvpQ9vM10asHzGAZ+xP1jGy1h0F60nDVg+44DvyTApw1rGS+nD20yXBiyfccBn7A+W8TIW3UXrSQOWzzjgezJMyrCW8VL68DbTpQHLZ0YGfBUvfQo3Oa9Zrl+/vrj99tvNFyP65r/vw20s44lMZbpO5Wovo7uqmmuKTcuebTJG/Hwd3768o3755ZcfxjbLC1gQdlx00UWBg29aLstnRgZ8FcFfKjc5Bj3ppJNMe9QRCcaUR2ZnE9LAMp5Mo0zXqaQLZTRgVeqpsyn2WbhwYWkhhiZj6LEtvn0hJ+VNurjIA8Qnt9xyy4CEYkJMPrKYls+MDfB1/PTCXaZ5z6FT5rVILhYEHAo2UNhNYEGBKpn74thlnOAja6/nDizjNQG8xQ8v5CJVfPAQTwD4m2666TAed8AFPTNMOFA1x0QlwkHPfYuPXqvc4tsXmqlDhw4dliXCqXDgwIFCaLF6NuXYhrd8ZiyAt/jphSqYdhRFOOOMM4qHH364ePTRRwshUOQzLkAP7xpRHYJArpinfGza7Xggy3ipgLf44YVqqo4PnsVV87hTeWXHjh2Bg10oyeGspzJLnELrbCPmkNd89FqdqXz7yI7PHH/88YOFRp5lATr//POTMsiOTTm27i2faQXwwn+mZwX3F0BO5aevaqcBL3zfjKOrfnhKf2Zx7LHHznAqsQlMqan88BYfPIDXpZSIwMJ3V5fSx4Cv47KTSaRsSaQNoNa89EKJpnnwxoa4ngcaC+DLVlFdjABHgsRQLsgML7300lD1Q7fbtWvXjHI8muY43sNrumkH/JlhcdWXBkwqP7zFBx/v4bVN+gQ8i5osPlBirVmzJqT4HNp5hJ+5ArUS4esAn8pPX7aiawd0wFeHDuvQLpUfvoyzX/PBjxPwzLYJ3z7nCHv37g2lsIRDPqViTM8BufXhe4/wqfz0sn+UQxa91+NQrw7wo3zt07rGW+zQMl7qHl4KSlj88BYffB3gy7KDsvS8jo8+Vl0Tvn3xM/rQ2wyP8GOO8AwnX68IN7nmhtdOxD6eA7jHH3888MdT0ZPLAnzMUz5byA7bAjw6TOWHr+ODrwO8LNBHHnnkYeyyw+zhxU2b8O2zoOlqOB7hD48+I6f0TQKaxWfeBR99E/lya5sK+CZyN7VBLnzwOXPBN9F/120tnxkr4K3JOh/9TA1ZxrP02fRz54NvqrH82ls+kxXgnY++X8AzuvPB5wfiJhJNFOCbTGwa2lrGmwYd+BybacDymawifLOpzf7WlvFmvwZ8hk01YPmMA76pRsfY3jLeGEXxoSZEA5bPOOAzNqRlvIxFd9F60oDlM85L35NhUoZ1XvoULXkbrQHnpZ9gf7BW6wmemovekQYsn/GUviPFt9GtZbw2xvA+ZpcGLJ9xwGdsb8t4GYvuovWkActnHPA9GSZlWMt4KX14m+nSgOUzDviM/cEyXsaiu2g9acDyGQd8T4ZJGdYyXkof3ma6NGD5jAM+Y3+wjJex6C5aTxqwfGYkwPPuNCyywjrLHMvYVbgHy+w999wTGEl0e62XOt5z56Wv9iAh+JQWixcvLqBuFl6AOnKKnvwyDAtLDVfMcpsqU928LF7+VH8ahVylD079TgFfxiwKScLcuXMDm6lcQn4I2ywXlMdllyZY4N/XXHPNgHHUyQyqYSC6khYsrNB2C8MNb8DV6T0VYG23K6PUajJG3bxiZp1h/WnSOPU7BTzG0QQJQqUEb/wNN9wQgB2znfCMFJ7gM+ioYbY599xzi/POOy+QMeIIW7duDSSXUFbX8dI3cZBJa2sZTy+oMYmljn7oWeudyLpv376g91NOOWUGrbR8BvUzn0FHLRGYBf6hhx6aUReAfi2uecanH/yCegPYlasK8Mhw4oknDgID7chYJFDwN1li1byQff78+YWw447iT5pTX8Yjq4VZZ968eZXZSV+c+pbPjJTSY7SYLpp7RBfhCY/ZZflcjHX99dcH9lqubdu2FUJtLRVFVq9eHZwOQ1fx0ldlC5MG7jJ5LePVAV4vtLENdu/eHRZXrs2bNw8WZ+GQu/DCC8NWDRZhLlhhhcIK21EgBLpq+gC8dVzz+jkYZaGTlueqAK+3hSwyl112WYEvrFixIowllNRl8xLZt2/fXsyZM2cgOwvgMP4U6xEu/pUrVwYdbNy4ccC+rO3XJ6e+5TMjA57VeOfOnSH9BpTU8nrqqafCvSuuuGJwj+IE2kAYYMmSJYMVkvMAFg+JVGUpWBUv/WwAd9uAJxXVGZMstPxf00XprRIssbrOH8CDARbAx/bSTm0RU+rxqgJADBgq3Nx6662BUx8ZhKsOmYjggF/3FTPcatnpe1h/qlo46zKUPjn1Owe8sM3eddddgVaY/wup5KZNmwJHOPdiBWn6Y3FCcdAqA2kG0lH3f5OwSFjGsyJ8WSTENlu2bAkgIhOjTBNMwUQsIqneGmiK8dheYiPaW4CXgy+KY1D+iS0CmUKdDUmJ8R+45SkWeeWVV4ZzIWjQWHzI7OR5ssA62Ufxp64B3zanvuUzI0d4lClcdDgRkb7qnjYwz5B+yX5eUre6CO+AL1+mynjp0TWAJsvSepeCEZyZcIqvI3zcjz6hju2lM4g6wDM2fsHzGqQW4GWr+P3vfz8APf5bBxB9/iMaik/XrUO7qsVnGMAjQ1+c+mMBvFAJY0Q54Km6J6mlOIIsEBiUiCKAjyNKHS/9JETrYWS0jFcV4XF2/qP2XgwyIucFF1wQ9t6Sia1bt25wMCoVYDmswjayD47tRf8UfqBNHeCxK31IdVd9mFgX4fEFzhcoNcaz8d9xxoh/8HUkqT7zYqET2QWAurBkqj8NC/i+OPUtn2klwsshGymkHKKV3dMGlvrdpHlcy5cvD+V9BfA4FKmnlAJONdAwwMr1Gct4GvB6DmRNq1atGpy+a71z5sLf1AgQ3UumhU3YN+/Zs6dYsGBB+IaEw1TSTj678cYbi/3794fTfcC0YcOGkCXUAZ7Mbf369YPxeE4WFWtbRlQGuLI4seXTX9Xq53UBSea1dOnScOiI7FzD+tOwgJcFCX2zbeLClzk4LNNZW5z6ls+0AvhRAEMkYf84W4pHjKKL+FnLeKOMVcZPH3O/S/kmQCcXbfg9RdNvRyw+/FHmop8d1zhN5B0np77lM70Dvonipq2tZby29cHJ9tNPPx1KPvNNCxFUin62PZb3140GLJ9xwHej91Z6tYzXyiBRJ0R1wM7Fj1/kULWLsbzP9jVg+YwDvn2dt9ajZbzWBvKOZo0GLJ9xwGdsast4GYvuovWkActnHPA9GSZlWMt4KX14m+nSgOUzDviM/cEyXsaiu2g9acDymVrA9ySzD+sacA2MoIHnP//fKp+uBPwI4/mjrgHXQKYacMBnahgXyzXQhQYc8F1o1ft0DWSqAQd8poZxsVwDXWjAAd+FVr1P10CmGnDAZ2oYF8s10IUGHPBdaNX7dA1kqgEHfKaGcbFcA11owAHfhVa9T9dAphr4H2dBvpqMDsmQAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "mLYg0H4SSGG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Las variables independientes son \"Especie\", \"Longitud1\", \"Longitud2\", \"Longitud3\", \"Altura\" y \"Anchura\".\n",
        "* La variable dependiente es \"Peso\".\n",
        "\n",
        "Tenemos que **estimar el peso del pez bas√°ndonos en sus mediciones**."
      ],
      "metadata": {
        "id": "lYdh1ysxS_b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/fishes.csv'\n",
        "df = pd.read_csv(url)\n",
        "df"
      ],
      "metadata": {
        "id": "ibZ_qoLb-a1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descripci√≥n de Features:\n",
        "\n",
        "- **Species**: Especie del pez (ej. Bream, Smelt).\n",
        "- **Weight**: Peso del pez en gramos.\n",
        "- **Length1**: Longitud 1 (vertical) en cm.\n",
        "- **Length2**: Longitud 2 (diagonal) en cm.\n",
        "- **Length3**: Longitud 3 (horizontal) en cm.\n",
        "- **Height**: Altura del pez en cm.\n",
        "- **Width**: Ancho del pez en cm."
      ],
      "metadata": {
        "id": "didMyz64RK8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "‚≠ï Pr√°ctica\n",
        "\n",
        "Construye un modelo de Regresi√≥n Lineal (Polinomial) para predecir el peso de un pez en funci√≥n de las variables predictoras.\n",
        "\n",
        "**Preprocesamiento**\n",
        "\n",
        "* Verifica si hay valores faltantes.\n",
        "* Verifica la correlaci√≥n entre variables usando el m√©todo [corr()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) del dataframe. Considera eliminar las variables con correlaci√≥n para evitar la multicolinealidad. **Prueba con ambas opciones:** dejar todas las variables o no.\n",
        "* Explora la relaci√≥n entre pares de variables usando [pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html) de seaborn. Esto te puede ayudar a visualizar qu√© variables est√°n m√°s correlacionadas con la variable a predecir, adem√°s, de dar una idea de c√≥mo es la relaci√≥n.\n",
        "* Verifica el rango de las variables (no solamente el rango, sino tambi√©n el m√°ximo y m√≠nimo). **Prueba con diferentes tipos de re-escalamiento y sin re-escalamiento**.\n",
        "* Usar PolinomialFeatures en funci√≥n de tus observaciones del punto anterior. **Prueba con diferentes grados del polinomio.**\n",
        "* Usa la codificaci√≥n one-hot para la(s) variable(s) categ√≥rica(s). **Prueba ambas opciones: incluye esta variable o no.**\n",
        "\n",
        "**Regresi√≥n Lineal**\n",
        "\n",
        "Entrena un modelo de RL separando el 75% para entrenamiento y reporta la m√©trica de rendimiento MAE y MAPE. **Adem√°s, prueba usando regularizaci√≥n**\n",
        "\n",
        "\n",
        "\n",
        "**Pasos a realizar**\n",
        "\n",
        "1.   Primero prueba con el siguiente modelo: Regresi√≥n Polinomial de grado 2 con todas las variables num√©ricas, sin re-escalamiento, sin la variable categ√≥rica (intenta implementarlo como pipeline).\n",
        "2.  El mismo modelo anterior pero implementado como pipeline, en caso de que no lo hayas hecho as√≠ en el punto anterior.\n",
        "3.  Prueba diferentes modelos considerando las combinaciones de t√©cnicas descritas arriba. Reporta el modelo que haya logrado el RMSE m√°s bajo.\n",
        "\n",
        "\n",
        "\n",
        "**Responde las siguientes preguntas:**\n",
        "\n",
        "* ¬øQu√© efecto tiene dejar todas las variables contra quitar variables correlacionadas?\n",
        "* ¬øCu√°l es el grado que mejor funcion√≥?"
      ],
      "metadata": {
        "id": "7N9f-krrUCCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos la variable dependiente y target."
      ],
      "metadata": {
        "id": "lQuFSjNHMLJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Weight'].values\n",
        "print(y.shape)\n",
        "\n",
        "X_df = df.drop(columns='Weight')\n",
        "print(X_df.shape)"
      ],
      "metadata": {
        "id": "uGzSc5zVMK_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An√°lisis Exploratorio"
      ],
      "metadata": {
        "id": "ZMpyLiZQOP89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.iloc[:,1:].corr()"
      ],
      "metadata": {
        "id": "rjy6FJnJVB5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import pairplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pairplot(X_df.iloc[:,1:])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWbWIxhCaTh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∑ ¬øCu√°les variables estan correlacionadas?"
      ],
      "metadata": {
        "id": "Lxo2Qp_MXnmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quitamos las variables correlacionadas: Nos quedamos solamente con `Lenght1` de las tres longitudes.\n",
        "\n"
      ],
      "metadata": {
        "id": "7VwJbOpmN0TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.columns.to_list()"
      ],
      "metadata": {
        "id": "W-wQ4509Yq_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns_to_keep = ['Species', 'Length1', 'Length2', 'Length3', 'Height', 'Width']\n",
        "columns_to_keep = ['Species', 'Length1', 'Height', 'Width']\n",
        "X_df = X_df[columns_to_keep]\n",
        "X_df"
      ],
      "metadata": {
        "id": "fSKkmBz6PkDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos las variables categ√≥ricas"
      ],
      "metadata": {
        "id": "OeuSudn3OWs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_df['Species'].unique()"
      ],
      "metadata": {
        "id": "kwzYWHuqbnrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import countplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "countplot(X_df['Species'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iQq1zsQ_TcYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos la codificaci√≥n *one-hot* cuidando de quitar una de las columnas finales para no introducir una variable colineal."
      ],
      "metadata": {
        "id": "glXqvxa2fJfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_df = pd.get_dummies(X_df,dtype='int',drop_first=True)\n",
        "X_df"
      ],
      "metadata": {
        "id": "0_eJ1_7ROY9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos s√≥lo las variables categ√≥ricas"
      ],
      "metadata": {
        "id": "pDwbL6ERfT5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_df.iloc[:,3:]\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "UZOArUhZbbL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos todas las variables"
      ],
      "metadata": {
        "id": "2M7Rh6y-bal3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_df.values\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "_dNYha68fV9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos s√≥lo las variables de mediciones"
      ],
      "metadata": {
        "id": "SQaDcs7EbxCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_df.iloc[:,:3].values\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "e4NAMGWtbwro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenemos el modelo de regresi√≥n lineal"
      ],
      "metadata": {
        "id": "KdOyIXdUUrow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=573,\n",
        "                                                    train_size=0.75)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "\n",
        "print(f\"Score en el conjunto de entrenamiento: {lr.score(X_train,y_train)}\") # coefficient of determination of the prediction\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "print(f\"MAE en el conjunto de prueba {mean_absolute_error(y_test,y_pred)}\")\n",
        "print(f\"MAPE en el conjunto de prueba {mean_absolute_percentage_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "id": "Si9EtnWLUrLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∑ El rendimiento es muy malo, a√∫n cuando R^2 es alto"
      ],
      "metadata": {
        "id": "HinFlDqteBGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "#----- IMPORTA LO NECESARIO ----\n",
        "\n",
        "#-------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=573,\n",
        "                                                    train_size=0.75)\n",
        "\n",
        "#--- INSERTA AQU√ç EL RE-ESCALAMIENTO ---\n",
        "\n",
        "\n",
        "X_train_scl = ...\n",
        "X_test_scl = ...\n",
        "\n",
        "#---------------------------------------\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scl,y_train)\n",
        "\n",
        "print(f\"Score en el conjunto de entrenamiento: {lr.score(X_train_scl,y_train)}\") # coefficient of determination of the prediction\n",
        "\n",
        "y_pred = lr.predict(X_test_scl)\n",
        "print(f\"MAE en el conjunto de prueba {mean_absolute_error(y_test,y_pred)}\")\n",
        "print(f\"MAPE en el conjunto de prueba {mean_absolute_percentage_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "id": "yEe8S0ISf_AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∑ ¬øY si probamos regularizaci√≥n Ridge, o similar? ¬øjunto con selecci√≥n de features?"
      ],
      "metadata": {
        "id": "XRPzdvtzjnYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2b: Pipelines"
      ],
      "metadata": {
        "id": "WOrKcOaJfWcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un **pipeline** en scikit-learn es una secuencia de transformaciones y un estimador final que se aplican a los datos de manera automatizada. Sirve para encadenar m√∫ltiples pasos de preprocesamiento (como escalado, imputaci√≥n, etc.) y un modelo de machine learning en un √∫nico objeto, garantizando consistencia y evitando fugas de datos durante la validaci√≥n cruzada.  \n",
        "\n",
        "**Ventajas:**  \n",
        "- **Simplifica el c√≥digo:** Combina todos los pasos en un √∫nico objeto.  \n",
        "- **Previene data leakage:** Asegura que las transformaciones se apliquen correctamente durante la validaci√≥n cruzada.  \n",
        "- **Facilita el mantenimiento:** Cambios en el flujo son m√°s f√°ciles de implementar.  \n",
        "- **Reproducibilidad:** Estandariza el proceso de entrenamiento y predicci√≥n.  \n",
        "- **Optimizaci√≥n integrada:** Permite usar `GridSearchCV` o `RandomizedSearchCV` en todos los pasos del pipeline.  \n",
        "\n",
        "Documentaci√≥n: [`sklearn.pipeline.Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).  "
      ],
      "metadata": {
        "id": "f6K7f87nezsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ML proceso](https://drive.google.com/uc?id=1S9KVyZbkiciIEeC7cLi-epa62gfFM0pi)\n",
        "\n",
        "Encapsulando todo en pipelines:\n",
        "\n",
        "![ML pipeline](https://drive.google.com/uc?id=1vaB4LfliQeomlbbiVua_cQGYnioQHYfY)"
      ],
      "metadata": {
        "id": "RttZphGttSJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=57)\n",
        "\n",
        "pl = Pipeline([\n",
        "               ('scl',StandardScaler()),\n",
        "               ('pf',PolynomialFeatures(degree=2,include_bias=False)),\n",
        "               ('lr',Ridge())])\n",
        "\n",
        "pl.fit(X_train,y_train)\n",
        "print(f\"R2 en el conjunto de entrenamiento: {pl.score(X_train,y_train)}\")\n",
        "\n",
        "y_pred = pl.predict(X_test)\n",
        "print(f\"MAE en el conjunto de prueba {mean_absolute_error(y_test,y_pred)}\")\n",
        "print(f\"MAPE en el conjunto de prueba {mean_absolute_percentage_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "id": "vXzbD6bYOMDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∑ Ha mejorado el rendimiento. Probemos varias combinaciones de hiperpar√°metros"
      ],
      "metadata": {
        "id": "jWK9UduCkkKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Un ejemplo de overfitting"
      ],
      "metadata": {
        "id": "p4aDHMyJiQ6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente es un claro ejemplo de overfitting. Observa c√≥mo la m√©trica de rendimiento es mucho mejor en el conjunto de entrenamiento que en el conjunto de prueba"
      ],
      "metadata": {
        "id": "Tdp_c3QIizE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=57)\n",
        "\n",
        "pl = Pipeline([\n",
        "               ('scl',StandardScaler()),\n",
        "               ('pf',PolynomialFeatures(degree=10,include_bias=False)),\n",
        "               ('lr',LinearRegression())])\n",
        "\n",
        "pl.fit(X_train,y_train)\n",
        "print(f\"R2 en el conjunto de entrenamiento: {pl.score(X_train,y_train)}\")\n",
        "\n",
        "y_train_pred = pl.predict(X_train)\n",
        "print(f\"MSE en el conjunto de entrenamiento {mean_absolute_error(y_train,y_train_pred)}\")\n",
        "y_pred = pl.predict(X_test)\n",
        "print(f\"MSE en el conjunto de prueba {mean_absolute_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "id": "7P-qWzHAiUyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(y_train,y_train_pred,label='Entrenamiento')\n",
        "plt.scatter(y_test,y_pred,label='Prueba')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"Valores reales\")\n",
        "plt.ylabel(\"Valores predichos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qrQ8R_Pxi7pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probando varias opciones"
      ],
      "metadata": {
        "id": "0IUC-LpUfY96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos varios algoritmos para regresi√≥n:"
      ],
      "metadata": {
        "id": "gqok3uLGJLCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "estimadores = [Ridge(0.5),Ridge(2),Lasso(0.5),Lasso(2),ElasticNet(0.5),ElasticNet(2),LinearRegression()]\n",
        "\n",
        "min_error = 10000\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=57)\n",
        "\n",
        "for E in estimadores:\n",
        "    pl = Pipeline([\n",
        "                ('scl',StandardScaler()),\n",
        "                ('pf',PolynomialFeatures(degree=2,include_bias=False)),\n",
        "                ('lr',E)])\n",
        "    pl.fit(X_train,y_train)\n",
        "    y_pred = pl.predict(X_test)\n",
        "    error = mean_absolute_percentage_error(y_test,y_pred)\n",
        "    if error < min_error:\n",
        "        min_error = error\n",
        "        print(f\"Error MAPE m√≠nimo: {min_error}\")\n",
        "        print(E)"
      ],
      "metadata": {
        "id": "YcSW0SlIDSwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Otros regresores\n",
        "\n",
        "Hay m√°s algoritmos para hacer regresi√≥n. Algunos de ellos son:\n",
        "\n",
        "* [K nearest neighbors (KNN)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
        "* [Decision Tree Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
        "\n",
        "En cada uno de ellos, hay que aprender c√≥mo funciona el m√©todo para aprender a elegir los hiperpar√°metros."
      ],
      "metadata": {
        "id": "SrCxb3mXJ5VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=57)\n",
        "\n",
        "# pl = Pipeline([('scl',StandardScaler()),\n",
        "#                ('lr',KNeighborsRegressor())])\n",
        "\n",
        "pl = Pipeline([('scl',StandardScaler()),\n",
        "               ('lr',DecisionTreeRegressor(criterion='squared_error'))])\n",
        "\n",
        "pl.fit(X_train,y_train)\n",
        "print(f\"Score en el conjunto de entrenamiento: {pl.score(X_train,y_train)}\") # coefficient of determination of the prediction\n",
        "\n",
        "y_pred = pl.predict(X_test)\n",
        "print(f\"MAPE en el conjunto de prueba {mean_absolute_percentage_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "id": "lMd9vswYJQMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∑ ¬øC√≥mo podemos probar combinaciones de muchos hiperpar√°metros? **Grid Search** (proximamente)"
      ],
      "metadata": {
        "id": "DP4Lje81owty"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlZp8bZio9x-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}