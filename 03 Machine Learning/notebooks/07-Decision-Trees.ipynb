{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3cv9-x_gKat"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP_2022/blob/main/03%20Machine%20Learning/notebooks/07-Decision-Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6TaZpW8qma6"
      },
      "source": [
        "# √Årboles de decisi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLY1XR5rjmL4"
      },
      "source": [
        "<img src=\"https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/img/DT.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHVlH2Bud4Da"
      },
      "source": [
        "En esta notebook usaremos el clasificador [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) de scikit-learn.\n",
        "\n",
        "Primero, observaremos algunas caracteristicas generales del m√©todo y despu√©s, lo usaremos en un problema de clasificaci√≥n con un dataset cl√°sico del machine learning.\n",
        "\n",
        "üéØ Los objetivos de esta notebook son:\n",
        "\n",
        "1. Familiarizarse con el uso del algoritmo y sus hiperpar√°metros principales.\n",
        "2. Percibir las particularidades de este algoritmo y compararlo con otros algoritmos.\n",
        "3. Usar el algoritmo en un dataset real.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcheG_cRD9_a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XJ2MgCSHFmBY"
      },
      "outputs": [],
      "source": [
        "#@title Funci√≥n para graficar la frontera de decisi√≥n\n",
        "\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "import numpy as np\n",
        "\n",
        "def graficar_FD(X,y,clf,h=0):\n",
        "    '''\n",
        "    X es todas las instancias las cuales incluiremos en el gr√°fico\n",
        "    '''\n",
        "    assert X.shape[1] == 2   # S√≥lo funciona para datos en dimensi√≥n 2\n",
        "    feature_1, feature_2 = np.meshgrid(\n",
        "    np.linspace(X[:,0].min()-h, X[:, 0].max()+h),\n",
        "    np.linspace(X[:, 1].min()-h, X[:, 1].max()+h)\n",
        "    )\n",
        "    grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
        "    y_grid_pred = clf.predict(grid)\n",
        "    y_grid_pred = y_grid_pred.reshape(feature_1.shape)\n",
        "    display = DecisionBoundaryDisplay(\n",
        "    xx0=feature_1, xx1=feature_2, response=y_grid_pred\n",
        "    )\n",
        "    display.plot()\n",
        "    display.ax_.scatter(\n",
        "        X[:, 0], X[:, 1], c=y, edgecolor=\"black\"\n",
        "    )\n",
        "    plt.show()\n",
        "    return display.ax_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6vhe29d5uVK"
      },
      "source": [
        "El m√≥dulo `dtreeviz` es √∫til para la visualizaci√≥n de √°rboles de decisi√≥n y la interpretaci√≥n de modelos ([documentaci√≥n](https://github.com/parrt/dtreeviz))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKhWGzhP5hNG"
      },
      "outputs": [],
      "source": [
        "!pip install -qq dtreeviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHm65FMfuY4K"
      },
      "source": [
        "# Ejemplo 1: Un ejemplo ilustrativo\n",
        "\n",
        "Con este ejemplo, exploraremos el uso b√°sico del √°lgoritmo y observaremos las caracter√≠sticas y particularidades del clasificador DT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tia5xfFLylY"
      },
      "source": [
        "## 1. Datos linealmente separables con una l√≠nea horizontal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4D3IsxALKe2"
      },
      "source": [
        "### Conjunto de datos\n",
        "\n",
        "En este primer ejemplo generamos un conjunto de datos linealmente separables con `make_blobs`. Estos datos pueden ser separados con una l√≠nea v√©rtical, es decir con una condici√≥n de tipo\n",
        "\n",
        "* Si $x>\\alpha$ entonces $(x,y)\\in\\text{clase}_0$.\n",
        "* Si $x<\\alpha$ entonces $(x,y)\\in\\text{clase}_1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9r0a-hD4Uli"
      },
      "source": [
        "Primero, generamos y visualizamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqZPXmUYN9ro"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(n_samples=600,centers=2,random_state=31)\n",
        "\n",
        "# colors = {0: 'blue', 1: 'red'} # Forzar a que cada clase tenga un color determinado\n",
        "colors = ['blue' if yi==0 else 'red' for yi in y] # Forzar a que cada clase tenga un color determinado\n",
        "\n",
        "plt.figure()\n",
        "# plt.scatter(X[:,0],X[:,1],c=[colors[yi] for yi in y])\n",
        "plt.scatter(X[:,0],X[:,1],c=colors)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkBPTaa84anV"
      },
      "source": [
        "Dividimos los datos en *train/test*. Entrenamos el √°rbol de decisi√≥n usando la implementaci√≥n de scikit-learn `sklearn.tree.DecisionTreeClassifier`. Realizamos la predicci√≥n sobre el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N36oEEHK4YK4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101) # 70% entrenamiento y 30% prueba\n",
        "\n",
        "clf = DecisionTreeClassifier()  # Inicializar el modelo con los hiperpar√°metros por defecto\n",
        "clf = clf.fit(X_train,y_train)  # Entrenar el modelo\n",
        "y_pred = clf.predict(X_test)    # Predecir las etiquetas para el conjunto de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQwJ_57zLOBE"
      },
      "source": [
        "### Entrenamiento y evaluaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVBqAM525NRI"
      },
      "source": [
        "Como es de esperar, obtenemos el 100% en todas las m√©tricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paSzESRGOEOh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),3)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx66pAxiLCPb"
      },
      "source": [
        "### Visualizaci√≥n del √°rbol (opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CawGwBEF5Yhs"
      },
      "source": [
        "Veamos el √°rbol de decisi√≥n usando [`export_text`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html) del m√≥dulo `tree` de scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no7nskN-OhcG"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=['x','y'])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkmSBhGdPPS1"
      },
      "outputs": [],
      "source": [
        "_ = graficar_FD(X,y,clf,h=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArjtpE4M3nEh"
      },
      "source": [
        "## Datos linealmente separables con una l√≠nea no vertical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkozO0Ay6UD1"
      },
      "source": [
        "Transformamos los datos para ahora sean separables con l√≠nea no horizontal. Para esto, rotamos cada punto un √°ngulo $\\theta=\\frac{\\pi}{4}=45¬∞$, adem√°s, trasladamos la clase *positiva* con el vector $z=(-1,-2)$.\n",
        "\n",
        "**Ocultamos el c√≥digo por limpieza**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AsmIGzTx6TmQ"
      },
      "outputs": [],
      "source": [
        "#@title Conjunto de datos\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "theta = np.pi/4 # √Ångulo de rotaci√≥n\n",
        "R = np.array([[np.cos(theta),-np.sin(theta)],[np.sin(theta),np.cos(theta)]]) # Matriz de rotaci√≥n\n",
        "\n",
        "Xr = np.transpose(R@np.transpose(X)) # Rotamos el dataset\n",
        "\n",
        "idxs = np.where(y==1)[0]   # Obtenemos los √≠ndices donde y=1\n",
        "\n",
        "Xr[idxs,:] = Xr[idxs,:] + np.array([-1,-2])\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(9,5),sharey=True)\n",
        "axs[0].scatter(X[:,0],X[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[0].set_title(\"Original dataset\")\n",
        "axs[1].scatter(Xr[:,0],Xr[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[1].set_title(\"Transformed dataset\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehKSVwpH_r0B"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xr, y, test_size=0.3, random_state=101) # 70% training and 30% test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Mgg6M1NZ9m"
      },
      "source": [
        "### Entrenamiento y evaluaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwjCPJ_6NgoY"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier()  # Create Decision Tree classifier object\n",
        "clf = clf.fit(X_train,y_train)  # Train Decision Tree Classifier\n",
        "y_pred = clf.predict(X_test)    # Predict the response for test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYrghH9rC-F9"
      },
      "source": [
        "Dados que los datos siguen siendo linealmente separables, seguimos obteniendo el 100% en todas las m√©tricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lSQ8DO4_zwA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),5)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOcQyoF-NomE"
      },
      "source": [
        "### Visualizaci√≥n del √°rbol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNNHtZ2DHm-"
      },
      "source": [
        "Sin embargo, el √°rbol empieza a hacerse m√°s complejo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK2bQQc5_4yd"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=['x','y'])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0smc2XnR1F3"
      },
      "source": [
        "La frontera de decisi√≥n no es la que esperar√≠amos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx8i-5bGCUUq"
      },
      "outputs": [],
      "source": [
        "_ = graficar_FD(Xr,y,clf,h=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMZFacpJqyQj"
      },
      "source": [
        "Como podemos ver, este clasificador no separa con una l√≠nea en general, a√∫n si los datos son linealmente separables. **Los √°rboles de decisi√≥n obtienen una FD compuesta de segmentos de l√≠nea verticales y horizontales.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11W12kCidBep"
      },
      "source": [
        "### Efecto de perturbaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr0pJ-nKSfQo"
      },
      "source": [
        "Ahora, observemos el efecto de perturbar levemente el conjunto de datos. ¬øQu√© le pasa al arbol de decisi√≥n?\n",
        "\n",
        "Este tipo de perturbaciones pueden ocurrir como resultado de errores de medici√≥n o de la presencia de outliers.\n",
        "\n",
        "Movemos un par de puntos cerca de la FD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hUiUrdOdH9b"
      },
      "outputs": [],
      "source": [
        "Xrp = Xr.copy()\n",
        "Xrp[192] = Xrp[192] + np.array([-1,-2])\n",
        "Xrp[486] = Xrp[486] + np.array([2,1])\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(9,5),sharey=True)\n",
        "axs[0].scatter(Xr[:,0],Xr[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[0].set_title(\"Original dataset\")\n",
        "axs[1].scatter(Xrp[:,0],Xrp[:,1],c=['blue' if yi==0 else 'red' for yi in y])\n",
        "axs[1].set_title(\"Perturbed dataset\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiWGKgphQJFU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xrp, y, test_size=0.3, random_state=101) # 70% training and 30% test\n",
        "\n",
        "clf = DecisionTreeClassifier()  # Create Decision Tree classifier object\n",
        "clf = clf.fit(X_train,y_train)  # Train Decision Tree Classifier\n",
        "y_pred = clf.predict(X_test)    # Predict the response for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl_M9fD2QJFW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),5)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5f2V5DEQJFX"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=['x','y'])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbmVDMdXQJFY"
      },
      "outputs": [],
      "source": [
        "_ = graficar_FD(Xrp,y,clf,h=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOHwPFOmX7zx"
      },
      "source": [
        "# Ejemplo 2: MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew7tZerDkAYF"
      },
      "source": [
        "Ver la diferencia entre normalizar o no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le5lbPpXX_oj"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "X = digits.data\n",
        "y = digits.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG9-Y5TVYWxR"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpuc3WXfSJFc"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy entrenamiento: {clf.score(X_train,y_train)}\")\n",
        "print(f\"Accuracy prueba: {clf.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gWKa8KHS99Y"
      },
      "source": [
        "Viendo las m√©tricas, ¬øhay se√±ales de entrenamiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMzvZFqlYwRN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred, average='macro'),3)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred, average='macro'),3)}\")\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CIDRJC9Y7NU"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "\n",
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,feature_names=[f'pixel_{j+1}' for j in range(X.shape[1])])\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uP__ydLXPNJ"
      },
      "source": [
        "### No es necesaria la normalizaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bquVwsUweOax"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "\n",
        "# ----- Normalizando ----\n",
        "pl = Pipeline([('scl',MinMaxScaler()),\n",
        "               ('clf',DecisionTreeClassifier())])\n",
        "pl.fit(X_train,y_train)\n",
        "print(f\"Accuracy de prueba (Normalizando): {pl.score(X_test,y_test)}\")\n",
        "\n",
        "# ---- Sin normalizar ----\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "print(f\"Accuracy de prueba (Sin normalizar): {clf.score(X_test,y_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taNnvpVFfgTS"
      },
      "source": [
        "### Efecto de los hiperpar√°metros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ijxtqwiUTuU"
      },
      "source": [
        "Veamos cu√°l es el efecto en el accuracy de cambiar el par√°metro `max_depth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdTS7E0-TG1T"
      },
      "outputs": [],
      "source": [
        "depths = [2,3,4,5,6,7,8,9,10,11]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for d in depths:\n",
        "    clf = DecisionTreeClassifier(max_depth=d)\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    train_scores.append(clf.score(X_train,y_train))\n",
        "    test_scores.append(clf.score(X_test,y_test))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(depths,train_scores,label='Entrenamiento')\n",
        "plt.plot(depths,test_scores,label='Prueba')\n",
        "plt.axhline(0.835,color='gray',linestyle='--')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY2wWtUTWT_X"
      },
      "source": [
        "Con la ayuda de gridsearch, veamos cu√°l es la mejor profundidad que podemos obtener"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKOmR3XTUzuC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gs = GridSearchCV(estimator = DecisionTreeClassifier(),\n",
        "                  param_grid = {'max_depth': depths})\n",
        "gs.fit(X_train,y_train)\n",
        "print(gs.best_params_)\n",
        "print(f\"Accuracy de prueba con el mejor clasificador: {gs.best_estimator_.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0uXYModWQsy"
      },
      "source": [
        "### Comparaci√≥n con otros algoritmos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX-9U_75WS-m"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import time\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
        "\n",
        "dt_times = []\n",
        "for j in range(5):\n",
        "    start = time.time()\n",
        "    clf = DecisionTreeClassifier(max_depth=None)\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "    end = time.time()\n",
        "    dt_times.append(end-start)\n",
        "print(f\"Tiempo promedio de ejecuci√≥n DT: {np.mean(dt_times)}\")\n",
        "\n",
        "svm_times = []\n",
        "for j in range(5):\n",
        "    start = time.time()\n",
        "    clf = SVC(kernel='linear')\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "    end = time.time()\n",
        "    svm_times.append(end-start)\n",
        "print(f\"Tiempo promedio de ejecuci√≥n SVM: {np.mean(svm_times)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiHH6O5dbgM9"
      },
      "source": [
        "¬øC√≥mo se compara el rendimiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08bgv1Y0bmTI"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "\n",
        "clf = SVC()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "print(f\"Accuracy de prueba (SVM): {clf.score(X_test,y_test)}\")\n",
        "\n",
        "print(f\"Accuracy de prueba (DT): {gs.best_estimator_.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l744DLSs6FIg"
      },
      "source": [
        "# Ejemplo 3: PIMA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VupVs1qxEAIR"
      },
      "source": [
        "## 1. El conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3vFmHPULcpU"
      },
      "source": [
        "Este dataset fue creado por el *National Institute of Diabetes and Digestive and Kidney Diseases* de Estados Unidos. El objetivo del dataset es predecir el diagnostico de cu√°ndo un paciente tiene diabetes o no, basado en ciertas mediciones incluidas en el dataset. Varias restricciones fueron usadas en la selecci√≥n de estas instancias para filtrar el dataset. En particular, se trata pacientes femeninas de al menos 21 a√±os de edad pertenecientes al grupo ind√≠gena Pima de Arizona.\n",
        "\n",
        "Las variables incluidas son el numero de embarazos la paciente ha tenido, su BMI, nivel de insulina, edad, entre otras.\n",
        "\n",
        "El dataset se encuentra en https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvSDcCiBD_4M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/diabetes.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OBIK856IEcw"
      },
      "source": [
        "## Entrenar el clasificador y resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qMqoQT3IPXY"
      },
      "source": [
        "Escogemos las *features* que usaremos y definimos el dataset de features y el vector de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOUwwCd5S3DO"
      },
      "outputs": [],
      "source": [
        "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
        "\n",
        "X = df[feature_cols].values    # Features\n",
        "y = df['label'].values         # Target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOLVREgOIhWN"
      },
      "source": [
        "Dividimos los datos en train/test. Entrenamos el √°rbol de decisi√≥n usando la implementaci√≥n de scikit-learn sklearn.tree.DecisionTreeClassifier. Realizamos la predicci√≥n sobre el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpZUvwi7Ig1u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsso9OE3BVk_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),5)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "target_labels = ['no diabetes','diabetes']\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g',\n",
        "            xticklabels=target_labels,\n",
        "            yticklabels=target_labels)\n",
        "s_cm.set(xlabel='Predicted',ylabel='Real')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXSNV3Kej-zy"
      },
      "source": [
        "## Importancia de las features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "004cEhuKaxFb"
      },
      "source": [
        "Podemos obtener la importancia de las features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTVRCjRpaw1z"
      },
      "outputs": [],
      "source": [
        "clf.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4RvkQpOamub"
      },
      "outputs": [],
      "source": [
        "importances_df = pd.DataFrame({'feature':feature_cols,'importancia':np.round(clf.feature_importances_,3)})\n",
        "importances_df.sort_values(by='importancia',ascending=False,inplace=True)\n",
        "importances_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHIxJ_6Wj6dH"
      },
      "source": [
        "## Visualizaciones de los √°rboles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77CcvUVsSghj"
      },
      "source": [
        "Al visualizar √°rboles de decisi√≥n recuerda que el escalamiento no es necesario, en general. Si decides escalar, esto tiene repercusiones en la visualizaci√≥n del √°rbol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUt9Z3-WlEvk"
      },
      "source": [
        "### Con scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as_iRGyHj8h0"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "text_representation = export_text(decision_tree=clf,\n",
        "                                       feature_names=feature_cols)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoyVuldWk1I6"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "fig = plt.figure(figsize=(25,20))   # Definimos una figura m√°s grande para que quepa\n",
        "_ = plot_tree(clf, feature_names=feature_cols,\n",
        "                   class_names=['0','1'],\n",
        "                   filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbHmh8pCWmzi"
      },
      "source": [
        "### Using [graphviz](https://graphviz.org/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d_KAeh3SOpv"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "graph.write_png('diabetes.png')\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3PQex_sRsnz"
      },
      "source": [
        "### Using [dtreeviz](https://github.com/parrt/dtreeviz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvKybSONxSut"
      },
      "outputs": [],
      "source": [
        "from dtreeviz import model\n",
        "\n",
        "X_scl = pl['selector'].transform(X)\n",
        "\n",
        "ct = model(pl['clasificador'], X_scl, y, feature_names = feature_cols)\n",
        "ct.view(fontname='DejaVu Sans')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_8WgZDGWjWm"
      },
      "source": [
        "Si queremos salvar la imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq9Rqb3aWl85"
      },
      "outputs": [],
      "source": [
        "v = ct.view(fontname='DejaVu Sans')\n",
        "v.save(\"tree.svg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH4LAHlzH97g"
      },
      "source": [
        "#‚≠ï **Pr√°ctica**:\n",
        "\n",
        "¬øPuedes subir las m√©tricas de desempe√±o de este clasificador en este dataset? A continuaci√≥n hay algunas opciones que puedes probar:\n",
        "\n",
        "* Observar la variable 'bmi', tiene valores 0, ¬øqu√© sentido tienen estos?\n",
        "    * Puedes quitar esas instancias.\n",
        "    * Puedes quitar la variable.\n",
        "* Cambiar el conjunto de features, ya sea manualmente o con alg√∫n m√©todo como [VarianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold), [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html), etc.\n",
        "* Realizar un gridsearch en los par√°metros del clasificador: `max_depth`, `criterion`, `min_samples_leaf`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwbg6Q2uYs85"
      },
      "source": [
        "A continuaci√≥n se muestra una estrategia para obtener alrededor de 75% de accuracy.\n",
        "\n",
        "Esta estrategia usa un imputador para reemplazar los valores 0 con el promedio. Adem√°s, se hace selecci√≥n de features. Todo se junta en un pipeline.\n",
        "\n",
        "**Adem√°s, realizamos un gridsearch en un pipeline.**\n",
        "\n",
        "Puedes probar modificando algunos pasos para buscar obtener un mejor rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_UHvMG_UADb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/diabetes.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7MUiy728wC1"
      },
      "outputs": [],
      "source": [
        "feature_names = df.columns.to_list()[:-1]\n",
        "\n",
        "print(f\"Nombres de las features: {feature_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq-gOmZJ8q1a"
      },
      "outputs": [],
      "source": [
        "X = df.loc[:,feature_names].values\n",
        "y = df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyBoAydZQX-w"
      },
      "source": [
        "### ‚ö° GridSearch con pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tJwQ9WFbJLX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"selector__threshold\": [0,0.1,0.2,0.5],\n",
        "    \"clasificador__criterion\": ['gini','entropy'],\n",
        "    \"clasificador__max_depth\": [None,10],\n",
        "    \"clasificador__min_samples_split\": [2,3,4]\n",
        "}\n",
        "\n",
        "search = GridSearchCV(pl, param_grid, n_jobs=2)\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
        "print(search.best_params_)\n",
        "\n",
        "best_clf = search.best_estimator_\n",
        "\n",
        "print(f\"Accuracy en el entrenamiento: {best_clf.score(X_train,y_train)}\")\n",
        "print(f\"Accuracy en la prueba: {best_clf.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuklND0fX1TF"
      },
      "outputs": [],
      "source": [
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),3)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
