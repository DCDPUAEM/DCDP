{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/03%20Machine%20Learning/notebooks/08-Comparacion-clasificadores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "Mat1flvJsPzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparación de varios clasificadores\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1lcj0sqCwfqbV1DHGyYKsq6SNlkKpKEXY )\n",
        "\n",
        "En esta notebook compararemos el rendimiento y tiempo de ejecución de varios algoritmos de clasificación.\n",
        "\n",
        "* `KNeighborsClassifier`: Clasifica comparando una instancia de acuerdo a las etiquetas de los vecinos más cercanos en el espacio de features.\n",
        "\n",
        "* `AdaBoostClassifier`: Es un meta-algoritmo que crea un ensamble de clasificadores con una técnica diferente al *bagging*.\n",
        "\n",
        "* `BaggingClassifier`: Es un meta-algoritmo que crea un ensamble de clasificadores usando *bagging*.\n",
        "\n",
        "* `GaussianNB` (Bayes Ingenuo Gaussiano): Se clasifican las instancias calculando la probabilidad de que cada instancia pertenezca a cada clase, dadas sus features, bajo la suposición de que las features siguen una distribución normal y son independientes entre sí dadas la clase (esta última es la suposición *naive*)."
      ],
      "metadata": {
        "id": "qNZ3oEPzie8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score"
      ],
      "metadata": {
        "id": "KElM9HcL2Ky1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX1OW2RQ03yE"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=1001)"
      ],
      "metadata": {
        "id": "E6rkc4Lc7MML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corremos un entrenamiento por cada clasificador, midiendo el tiempo de entrenamiento y el accuracy en el conjunto de prueba."
      ],
      "metadata": {
        "id": "HyS9ypaEz20M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = [DecisionTreeClassifier(),RandomForestClassifier(),\n",
        "        SVC(),LogisticRegression(),\n",
        "        GaussianNB(),KNeighborsClassifier(),\n",
        "        AdaBoostClassifier(estimator=SVC(),algorithm='SAMME'),\n",
        "        AdaBoostClassifier(estimator=GaussianNB(),algorithm='SAMME'),\n",
        "        BaggingClassifier(estimator=SVC())]\n",
        "\n",
        "names = [x.__class__.__name__ for x in clfs]  # Obtener el nombre de cada clasificador, como <string>\n",
        "names[-3] += '_SVC'\n",
        "names[-2] += '_GNB'\n",
        "names[-1] += '_SVC'\n",
        "times = []\n",
        "accs = []\n",
        "\n",
        "for clf in clfs:\n",
        "    pl = Pipeline([('scl',StandardScaler()),\n",
        "                    ('clf',clf)])\n",
        "    start = time.time()\n",
        "    pl.fit(X_train,y_train)\n",
        "    end = time.time()\n",
        "    times.append(end-start)\n",
        "    y_pred = pl.predict(X_test)\n",
        "    accs.append(accuracy_score(y_test,y_pred))\n",
        "\n",
        "resultados_df = pd.DataFrame(data={'algoritmo': names,\n",
        "                   'accuracy': accs,\n",
        "                   'duración': times})"
      ],
      "metadata": {
        "id": "s6obQjVQ1A_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corremos **5** entrenamiento por cada clasificador, midiendo el tiempo **promedio** de entrenamiento y el accuracy **promedio** en el conjunto de prueba.\n",
        "\n",
        "⏰ Esta celda tarda alrededor de 3 minutos."
      ],
      "metadata": {
        "id": "C9bWuU_Wz-ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = [DecisionTreeClassifier(),RandomForestClassifier(),\n",
        "        SVC(),LogisticRegression(),\n",
        "        GaussianNB(),KNeighborsClassifier(),\n",
        "        AdaBoostClassifier(estimator=SVC(),algorithm='SAMME'),\n",
        "        AdaBoostClassifier(estimator=GaussianNB(),algorithm='SAMME'),\n",
        "        BaggingClassifier(estimator=SVC())]\n",
        "\n",
        "names = [x.__class__.__name__ for x in clfs]  # Obtener el nombre de cada clasificador, como <string>\n",
        "names[-3] += '_SVC'\n",
        "names[-2] += '_GNB'\n",
        "names[-1] += '_SVC'\n",
        "times = []\n",
        "accs = []\n",
        "\n",
        "for clf in clfs:\n",
        "    times_clf = []\n",
        "    accs_clf = []\n",
        "    for k in range(5):\n",
        "        pl = Pipeline([('scl',StandardScaler()),\n",
        "                        ('clf',clf)])\n",
        "        start = time.time()\n",
        "        pl.fit(X_train,y_train)\n",
        "        end = time.time()\n",
        "        times_clf.append(end-start)\n",
        "        y_pred = pl.predict(X_test)\n",
        "        accs_clf.append(accuracy_score(y_test,y_pred))\n",
        "    times.append(np.mean(times_clf))\n",
        "    accs.append(np.mean(accs_clf))\n",
        "    accs_clf.append(accuracy_score(y_test,y_pred))\n",
        "resultados_df = pd.DataFrame(data={'algoritmo': names,\n",
        "                   'accuracy': accs,\n",
        "                   'duración': times})"
      ],
      "metadata": {
        "id": "2UHtoFGCxkFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rendimiento"
      ],
      "metadata": {
        "id": "SOoqHAJMii1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_df.sort_values(by='accuracy',ascending=False)"
      ],
      "metadata": {
        "id": "lriWx6XX7mgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='algoritmo',y='accuracy',data=resultados_df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Algoritmo')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LjkJOim1epe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tiempo de ejecución"
      ],
      "metadata": {
        "id": "uogMiTuPilq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordenados de más rápido a más lento"
      ],
      "metadata": {
        "id": "9LIDueA9EKg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_df.sort_values(by='duración',ascending=True)"
      ],
      "metadata": {
        "id": "EWs9Sgkl8Qrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = resultados_df.index.to_list()\n",
        "idxs.remove(6)\n",
        "idxs\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='algoritmo',y='duración',data=resultados_df.loc[idxs])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Algoritmo')\n",
        "plt.ylabel('Duración (s)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ANcYGwxSe_-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se presenta la complejidad big-O de algunos algoritmos:\n",
        "\n",
        "* Naive Bayes: $O(Nd)$\n",
        "* k-NN: $O(1)$ (space complexity of training is $O(Nd)$ since the data needs to be stored, which also takes time).\n",
        "* SVM: $O(N^2)$ or $O(N^3)$ depending on the kernel.\n",
        "* DecisionTree: $O(n\\log n)$"
      ],
      "metadata": {
        "id": "Dj5Z3tK3ZLGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparación de las fronteras de decisión: Ejemplo 3"
      ],
      "metadata": {
        "id": "OdquLkqdDGiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Conjunto de datos\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = make_blobs(n_samples=600,centers=2,random_state=31)\n",
        "\n",
        "theta = np.pi/4 # Ángulo de rotación\n",
        "R = np.array([[np.cos(theta),-np.sin(theta)],[np.sin(theta),np.cos(theta)]]) # Matriz de rotación\n",
        "\n",
        "Xr = np.transpose(R@np.transpose(X)) # Rotamos el dataset\n",
        "\n",
        "idxs = np.where(y==1)[0]   # Obtenemos los índices donde y=1\n",
        "\n",
        "Xr[idxs,:] = Xr[idxs,:] + np.array([-1,-2])\n",
        "\n",
        "X1, y1 = Xr, y\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.scatter(X1[:,0],X1[:,1],c=y1)\n",
        "plt.axis('off')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QwY3_IF6DJAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clfs = [DecisionTreeClassifier(),RandomForestClassifier(),\n",
        "        SVC(kernel='linear'),LogisticRegression(),\n",
        "        GaussianNB(),KNeighborsClassifier(),\n",
        "        SVC(),]\n",
        "\n",
        "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
        "\n",
        "for clf,ax in zip(clfs,axs.flatten()):\n",
        "    clf.fit(X1,y1)\n",
        "    ax.scatter(X1[:,0],X1[:,1],c=y1)\n",
        "    DecisionBoundaryDisplay.from_estimator(clf, X1,\n",
        "                                           ax=ax,alpha=0.5)\n",
        "    ax.set_title(clf.__class__.__name__)\n",
        "    ax.axis('off')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "6CxPrnJyDK7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparación de las fronteras de decisión: Ejemplo 2"
      ],
      "metadata": {
        "id": "GKBuGXK5cV0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = make_blobs(n_samples=100, centers=2, random_state=30) # 27\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[:,0],X[:,1],c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vQ1iwfSXOlm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "clfs = [DecisionTreeClassifier(),RandomForestClassifier(),\n",
        "        SVC(kernel='linear'),LogisticRegression(),\n",
        "        GaussianNB(),KNeighborsClassifier(),SVC()]\n",
        "\n",
        "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
        "\n",
        "for clf,ax in zip(clfs,axs.flatten()):\n",
        "    clf.fit(X,y)\n",
        "    ax.scatter(X[:,0],X[:,1],c=y)\n",
        "    DecisionBoundaryDisplay.from_estimator(clf, X,\n",
        "                                           ax=ax,alpha=0.5)\n",
        "    ax.set_title(clf.__class__.__name__)\n",
        "    ax.axis('off')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hEnSNbrxaRbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_6q-HKObqiR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}