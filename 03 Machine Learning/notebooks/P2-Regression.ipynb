{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Pr√°ctica 2</h1>\n",
        "<h2>Regresi√≥n</h2>\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/03%20Machine%20Learning/notebooks/P2-Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "En esta pr√°ctica realizar√°s la tarea de regresi√≥n para predecir el precio de casas en el dataset [Ames Housing](https://www.kaggle.com/datasets/shashanknecrothapa/ames-housing-dataset).\n",
        "\n",
        "El dataset Ames Housing contiene informaci√≥n sobre ventas de viviendas en Ames, Iowa, entre 2006 y 2010. Incluye 80 variables (num√©ricas y categ√≥ricas) que describen caracter√≠sticas de las casas, como √°rea habitable, calidad, a√±o de construcci√≥n, y ubicaci√≥n. La variable objetivo es SalePrice (precio de venta). Tiene 2,930 observaciones y es com√∫nmente usado para practicar modelos de regresi√≥n en machine learning."
      ],
      "metadata": {
        "id": "IivJa6G-wmP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset:"
      ],
      "metadata": {
        "id": "A8WvE43HxA28"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F68Mxk8eTMiv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/AmesHousing.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.drop(columns=[\"Order\",\"PID\"], inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Verifica si hay datos faltantes, en caso de que s√≠, realiza la imputaci√≥n usando la estrategia que elijas."
      ],
      "metadata": {
        "id": "RLkAG8tprNcr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FD-NByfrlTVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Usando el m√©todo `describe` del dataframe, observa los rangos de cada variable num√©rica.\n",
        "\n",
        "* ¬øCu√°l es la variable con los valores m√°s altos?\n",
        "* ¬øCu√°l es la variable con el rango de valores m√°s angosto?"
      ],
      "metadata": {
        "id": "nUiFp94_uEMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examina la correlaci√≥n entre variables. **Observa que aqu√≠ est√° tambi√©n la variable target**"
      ],
      "metadata": {
        "id": "oY1J4NDXqdpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df_numeric = df.select_dtypes(include=['int64', 'float64'])  # S√≥lo queremos considerar las variables num√©ricas para este an√°lisis\n",
        "corr_mat = df_numeric.corr().round(2)\n",
        "\n",
        "plt.figure(figsize=(17, 15))\n",
        "sns.heatmap(corr_mat, annot=True, cmap='coolwarm',cbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bI_ZBVySloy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Responde aqu√≠: ¬øCu√°les son las parejas de variables que presentan el **problema** de multicolinealidad?\n",
        "\n",
        "De cada grupo de variables con multicolinealidad qu√©date s√≥lo con una de ellas y elimina la(s) otra(s)."
      ],
      "metadata": {
        "id": "cbftOpiyqOGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Observa las relaciones entre las variables num√©ricas predictoras y la variable target:"
      ],
      "metadata": {
        "id": "XrPI6Ft8vGL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seleccionar solo columnas num√©ricas\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Crear pair plot (relaci√≥n entre variables num√©ricas y 'SalePrice')\n",
        "sns.pairplot(\n",
        "    data=df[numeric_cols],\n",
        "    y_vars=['SalePrice'],          # Variable objetivo\n",
        "    x_vars=numeric_cols.drop('SalePrice'),  # Todas las num√©ricas excepto target\n",
        "    height=3,\n",
        "    aspect=0.8,\n",
        "    plot_kws={'alpha': 0.5}\n",
        ")\n",
        "\n",
        "plt.suptitle('Relaci√≥n entre variables num√©ricas y SalePrice', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CLKxq9BZu-gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Elige una variable que consideres que tiene mucha relaci√≥n con la variable target y eliminala."
      ],
      "metadata": {
        "id": "_6QybryqvQAO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9f-Yw9DPvc7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Aplica la codificaci√≥n *one-hot* a las variables categ√≥ricas. Usa la opci√≥n `drop_first=True` para evitar la multicolinealidad en las variables binarias resultantes."
      ],
      "metadata": {
        "id": "DcfGb_Qtqtax"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-l5bodJl045"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Realiza las siguientes acciones:\n",
        "\n",
        "1. Haz una divisi√≥n train/test con la proporci√≥n 80%/20%.\n",
        "2. Define un pipeline con los siguientes pasos:\n",
        " * Escalador\n",
        " * Selector de features\n",
        " * Polinomial Features, elige el grado que consideres necesario (si eliges un valor muy alto puede ser muy tardado el proceso).\n",
        " * Algoritmo de regresi√≥n lineal ElasticNet.\n",
        "3. Entrena con el conjunto de entrenamiento y muestra el coeficiente $R^2$ en el conjunto de entrenamiento y prueba.\n",
        "4. Obten las predicciones para el conjunto de prueba.\n",
        "5. Evalua el rendimiento usando las m√©tricas MAE, MAPE y [RMSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html). Esta √∫ltima no la hemos usado hasta el momento, es otra medici√≥n de qu√© tan alejados est√°n las predicciones del valor real, entre m√°s bajo es mejor."
      ],
      "metadata": {
        "id": "Med2SoprtvIa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsyH--gEv6zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Repite el experimento del punto anterior cambiando el algoritmo por alguno de los siguientes:\n",
        "* [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
        "* [kNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)"
      ],
      "metadata": {
        "id": "3Fdx-wnswG7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IIf_92Eawic3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}