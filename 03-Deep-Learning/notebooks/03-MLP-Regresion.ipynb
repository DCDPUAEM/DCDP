{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/03-Deep-Learning/notebooks/03-MLP-Regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "WOLu-Lu0cVKM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Redes Neuronales MLP para regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Conectar la notebook en modo GPU (**en este caso no es muy necesario**)\n",
        "\n",
        "Entorno de ejecución → Cambiar tipo de entorno de ejecución\n",
        "\n",
        "Algunas consideraciones:\n",
        "\n",
        "* No dejar la notebook conectada sin actividad ya que Colab penaliza esto al asignar un entorno con GPU.\n",
        "* No pedir el entorno con GPU si no se va a usar."
      ],
      "metadata": {
        "id": "J4xDK8oN01Fd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "En esta notebook describiremos cómo resolver un problema de regresión usando una red neuronal MLP.\n",
        "\n",
        "Usaremos el conjunto de datos [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) y construiremos un modelo para predecir la eficiencia en el uso de combustible (en MPG, millas por galón) de vehiculos hechos entre 1970 y 1980. La descripción de cada vehículo incluye atributos como: número de cilíndros, potencia, país de origen y peso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## El conjunto de datos\n",
        "\n",
        "El dataset original se puede encontrar en [UCI Machine Learning Repository](archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/DCDPUAEM/DCDP/main/03-Deep-Learning/data/auto-mpg.data\"\n",
        "!wget --no-cache --backups=1 {url}"
      ],
      "metadata": {
        "id": "w3Ail5CFfagf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leemo el conjunto de datos en un dataframe."
      ],
      "metadata": {
        "id": "yV-4vQmmtBRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "df = pd.read_csv('auto-mpg.data', names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "WtdIwDvHn2H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWuJTKEDM-f"
      },
      "source": [
        "### Limpieza de los datos\n",
        "\n",
        "El dataset contiene algunos valores desconocidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEJHhN65a2VV"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPN0KBHa_WI"
      },
      "source": [
        "Eliminemos las filas con valores faltantes, ya que son pocas. También podríamos imputar valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4ZUDosChC1UN"
      },
      "outputs": [],
      "source": [
        "clean_df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKitwaH4v8h"
      },
      "source": [
        "La columna `\"Origin\"` es categorica, la codificamos con \"one-hot\" encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oh_df = pd.get_dummies(data=clean_df,columns=['Origin'])\n",
        "oh_df"
      ],
      "metadata": {
        "id": "nRF26smsqNrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reemplazamos los nombres del origen"
      ],
      "metadata": {
        "id": "lJST2Qb2tkRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWNTD2QjBWFJ"
      },
      "outputs": [],
      "source": [
        "oh_df.rename(columns={'Origin_1':'USA',\n",
        "                      'Origin_2':'Europe',\n",
        "                      'Origin_3':'Japan'},\n",
        "             inplace=True)\n",
        "oh_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos las features y la variable dependiente."
      ],
      "metadata": {
        "id": "W2hkgNdHtoO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = oh_df.iloc[:,1:].values\n",
        "y = oh_df['MPG'].values\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "wR5w7hEksRJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### División en conjuntos de entrenamiento y prueba\n",
        "\n",
        "Ahora dividimos el set de datos en un set de entrenamiento y otro de prueba.\n",
        "\n",
        "Usaremos el conjunto de prueba en la evaluacion final de nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.85,random_state=189)\n",
        "\n",
        "print(f\"Train size: {X_train.shape[0]}\")\n",
        "print(f\"Test size: {X_test.shape[0]}\")  "
      ],
      "metadata": {
        "id": "OJj_uC9fsCZ2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRklxK5s388r"
      },
      "source": [
        "### Normalizamos\n",
        "\n",
        "Inspeccionemos los rangos de las variables continuas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oh_df.iloc[:,1:7].plot.hist(subplots=True, legend=True)"
      ],
      "metadata": {
        "id": "zrQeJXuOtNyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywmerQ6dSox"
      },
      "source": [
        "Es una buena práctica normalizar funciones que utilizan diferentes escalas y rangos. Aunque el modelo *podría* converger sin normalización de features, esto suele dificultar el entrenamiento.\n",
        "\n",
        "**Observaciones**: \n",
        "1. Aunque sólo entrenamos el escalador con el conjunto de datos de entrenamiento, este escalador también se utilizará para normalizar el conjunto de datos de prueba. Necesitamos hacer eso para proyectar el conjunto de datos de prueba en la misma distribución en la que el modelo ha sido entrenado.\n",
        "2. El reescalamiento debe aplicarse a cualquier otro dato que entre aal modelo, junto con la codificación de un punto que hicimos anteriormente. Eso incluye el conjunto de pruebas, así como los datos en vivo cuando el modelo se usa en producción."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scl = scaler.fit_transform(X_train)\n",
        "X_test_scl = scaler.transform(X_test) "
      ],
      "metadata": {
        "id": "PPL3d9P86bR9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "### Construye el modelo\n",
        "\n",
        "Construyamos nuestro modelo. Aquí, utilizaremos un modelo `sequential` con dos capas ocultas y una capa de salida que devuelve un único valor continuo. \n",
        "\n",
        "Observa la elección de optimizador, métricas de rendimiento, función de costo y funciones de activación."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos definir directamente el modelo, como en la notebook pasada:"
      ],
      "metadata": {
        "id": "t1vbCIpSY3QU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c26juK7ZG8j-"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "layers.Dense(64, activation='relu', input_shape=[X_train_scl.shape[1]]),\n",
        "layers.Dense(64, activation='relu'),\n",
        "layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model.compile(loss='mse',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['mae', 'mse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos también definirlo por medio de una función para generar nuevos modelos similares posteriormente:"
      ],
      "metadata": {
        "id": "TQ66z0UrY7GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[X_train_scl.shape[1]]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "    model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "_vIdIKtQZAAD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "### Inspeccione el modelo\n",
        "\n",
        "Use el método `.summary` para imprimir una descripción simple del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReAD0n6MsFK-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt6W50qGsJAL"
      },
      "source": [
        "### ⏸A little detour...\n",
        "\n",
        "Observemos que ya podríamos realizar predicciones con el modelo sin entrenar. Es decir, los pesos están inicializados\n",
        "\n",
        "Tomamos un *batch* de 10 ejemplos de los datos de entrenamiento y realizamos las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d-gBaVtGTSC"
      },
      "outputs": [],
      "source": [
        "example_batch = X_train_scl[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podríamos medir su error MSE, o cualquier otra métrica de rendimiento."
      ],
      "metadata": {
        "id": "vIzDOy188yac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_train[:10],example_result)"
      ],
      "metadata": {
        "id": "Pac0G5-T8oea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### Entrenamos el modelo\n",
        "\n",
        "Entrenamos el modelo durante 1000 épocas, registramos la precisión de entrenamiento y validación en el objeto `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD7qHCmNIOY0"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  X_train_scl, y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Podríamos visualizar la historia del entrenamiento durante cada época en un dataframe usando las estadísticas almacenadas en el diccionario `history.history`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xj91b-dymEy"
      },
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la siguiente función para graficar las métricas de rendimiento durante el entrenamiento."
      ],
      "metadata": {
        "id": "y0BirpL1ufpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Abs Error [MPG]')\n",
        "    plt.plot(history.epoch, history.history['mae'],\n",
        "            label='Train Error')\n",
        "    plt.plot(history.epoch, history.history['val_mae'],\n",
        "            label = 'Val Error')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "    plt.plot(history.epoch, history.history['mse'],\n",
        "            label='Train Error')\n",
        "    plt.plot(history.epoch, history.history['val_mse'],\n",
        "            label = 'Val Error')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lguXVmMsioiT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6XriGbVPh2t"
      },
      "outputs": [],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqsuANc11FYv"
      },
      "source": [
        "Este gráfico muestra poca mejora, o incluso degradación en el error de validación después de aproximadamente 100 épocas. **Esta es una señal de overfitting**.\n",
        "\n",
        "Repitamos el entrenamiento con menos épocas. \n",
        "\n",
        "Observa el parámetro `verbose`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdMZuhUgzMZ4"
      },
      "outputs": [],
      "source": [
        "model_me = build_model()\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "history = model_me.fit(X_train_scl, y_train, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0)\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Métricas de rendimiento"
      ],
      "metadata": {
        "id": "CeqBAG7Hb9Nm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "Veamos qué tan bien generaliza el modelo al usar el **conjunto de prueba**, el cual no fue usado para entrenar el modelo. Esto nos dice qué tan bien podemos esperar que el modelo prediga cuándo lo usamos en el mundo real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl_yNr5n1kms"
      },
      "outputs": [],
      "source": [
        "loss, mae, mse = model_me.evaluate(X_test_scl, y_test, verbose=2)\n",
        "\n",
        "print(f\"MAE para las predicciones en el conjunto de prueba: {np.round(mae,4)} MPG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### Predicciones\n",
        "\n",
        "Finalmente, prediga los valores de MPG utilizando datos en el conjunto de pruebas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "outputs": [],
      "source": [
        "y_pred = model_me.predict(X_test_scl).flatten()\n",
        "\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19wyogbOSU5t"
      },
      "source": [
        "Parece que nuestro modelo predice razonablemente bien. Echemos un vistazo a la distribución de errores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-OHX4DiXd8x"
      },
      "outputs": [],
      "source": [
        "error = y_pred - y_test\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Error en la predicción [MPG]\")\n",
        "plt.ylabel(\"Conteos\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⭕ Práctica"
      ],
      "metadata": {
        "id": "Zl7IlJJgcE9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Repite el experimento usando 100 épocas y sin normalizar los datos, ¿qué le sucede a las métricas de rendimiento?\n",
        "\n",
        "2. Usando los datos normalizados, cambia los parámetros del módelo: \n",
        "    * Número de capas ocultas\n",
        "    * Funciones de activación de las capas ocultas\n",
        "    * Optimizador\n",
        "    \n",
        "    ¿Puedes subir las métricas de rendimiento?\n",
        "\n",
        "3. ¿Mejora el rendimiento de tu modelo si imputas los 6 valores faltantes?"
      ],
      "metadata": {
        "id": "wWAn3u8giOxG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQVNlT6ycEzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "* El error cuadrático medio (MSE) es una función de pérdida común utilizada para problemas de regresión. Otra métrica de regresión común es el error absoluto medio (MAE). \n",
        "* Cuando las features de datos de entrada numéricos tienen valores con diferentes rangos, cada característica debe escalarse independientemente al mismo rango.\n",
        "* Si no hay muchos datos de entrenamiento, es preferible usar una red pequeña con pocas capas ocultas para evitar el sobreajuste.\n",
        "* El entrenamiento con pocas épocas es una técnica útil para evitar el sobreajuste. Otra técnica es el *early stopping** (coming soon...)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}