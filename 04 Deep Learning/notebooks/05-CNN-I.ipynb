{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TgLUQd5WLOm"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/05-CNN-I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFc78aDaWLOo"
      },
      "source": [
        "<h1>Clasificaci√≥n con Redes Neuronales Convolucionales</h1>\n",
        "\n",
        "En esta notebook usaremos una red neuronal convolucional (CNN) para un problema de clasificaci√≥n de im√°genes, adem√°s, compararemos esta arquitectura con la arquitectura MLP.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?id=1bzFBdsAq40yN95k2pA5X2OGsXf-40v0t\" width=\"600\" />\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq-bgFf-WLOq"
      },
      "source": [
        "El CIFAR-10 (Canadian Institute For Advanced Research) es un conjunto de datos cl√°sico en visi√≥n por computadora, compuesto por 60,000 im√°genes en color (32x32 p√≠xeles) distribuidas en 10 clases distintas: avi√≥n, autom√≥vil, p√°jaro, gato, ciervo, perro, rana, caballo, barco y cami√≥n. Cada clase contiene 6,000 im√°genes, con 5,000 para entrenamiento y 1,000 para prueba. Su tama√±o reducido y su diversidad lo convierten en un benchmark ideal para comparar modelos de aprendizaje autom√°tico, especialmente en tareas de clasificaci√≥n de im√°genes. A diferencia de MNIST, donde las MLP pueden alcanzar altos rendimientos, CIFAR-10 presenta mayores desaf√≠os debido a variaciones en iluminaci√≥n, trasfondos y perspectivas, lo que resalta la ventaja de arquitecturas basadas en convoluciones (CNN).\n",
        "\n",
        "Su objetivo principal es servir como punto de referencia para evaluar la capacidad de los modelos para generalizar caracter√≠sticas visuales jer√°rquicas y espaciales.\n",
        "\n",
        "[Fuente oficial](https://www-cs-toronto-edu.translate.goog/~kriz/cifar.html?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tc)\n",
        "\n",
        "\\\\\n",
        "\n",
        "| **Clase**  | **Descripci√≥n**       |  \n",
        "|------------|-----------------------|  \n",
        "| 0          | Avi√≥n (airplane)      |  \n",
        "| 1          | Autom√≥vil (automobile)|  \n",
        "| 2          | P√°jaro (bird)         |  \n",
        "| 3          | Gato (cat)            |  \n",
        "| 4          | Ciervo (deer)         |  \n",
        "| 5          | Perro (dog)           |  \n",
        "| 6          | Rana (frog)           |  \n",
        "| 7          | Caballo (horse)       |  \n",
        "| 8          | Barco (ship)          |  \n",
        "| 9          | Cami√≥n (truck)        |  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN71Ul1JWLOx"
      },
      "source": [
        "Verifiquemos que el entorno de ejecuci√≥n en Colab sea GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln6imMSY8vLe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print('GPU presente en: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "k3j2mv8_2lyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ Obervar que ahora, cada instancia en el dataset es un tensor 3-dimensional."
      ],
      "metadata": {
        "id": "An4rR2Gv3dn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "random_idxs = np.random.choice(range(X_train.shape[0]),size=5,replace=True)\n",
        "\n",
        "fig, axs = plt.subplots(1,5,figsize=(15,5))\n",
        "for i, idx in enumerate(random_idxs):\n",
        "  axs[i].imshow(X_train[idx])\n",
        "  axs[i].title.set_text(f'Label: {y_train[idx,0]}')\n",
        "  axs[i].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kIOUqS1k3j8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos el balanceo de clases"
      ],
      "metadata": {
        "id": "zmSiKxgu-MBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes, countings = np.unique(y_train,return_counts=True)\n",
        "\n",
        "classes_names = ['Avi√≥n', 'Autom√≥vil', 'P√°jaro', 'Gato', 'Ciervo', 'Perro', 'Rana', 'Caballo', 'Barco', 'Cami√≥n']\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(classes, countings)\n",
        "plt.xlabel('Clase')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.title('Distribuci√≥n de clases')\n",
        "plt.xticks(classes,labels=classes_names,rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FTlYDzU07xkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  stratify=y_train,\n",
        "                                                  test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")"
      ],
      "metadata": {
        "id": "tYRidB693Nx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos el preprocesamiento usual"
      ],
      "metadata": {
        "id": "9WIuY2-S6oAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rango de valores de X_train: {X_train.min()} - {X_train.max()}\")\n",
        "print(f\"Rango de valores de X_val: {X_val.min()} - {X_val.max()}\")\n",
        "print(f\"Rango de valores de X_test: {X_test.min()} - {X_test.max()}\")"
      ],
      "metadata": {
        "id": "qwWgQJXk3caE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_val = X_val.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "print(f\"Rango de valores de X_train: {X_train.min()} - {X_train.max()}\")\n",
        "print(f\"Rango de valores de X_val: {X_val.min()} - {X_val.max()}\")\n",
        "print(f\"Rango de valores de X_test: {X_test.min()} - {X_test.max()}\")"
      ],
      "metadata": {
        "id": "maVZ-ETg6s5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "from seaborn import heatmap\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    plt.figure(figsize=(11,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title(\"Validation and Training Loss\",fontsize=14)\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='validation')\n",
        "    plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title(\"Validation and Training Accuracy\",fontsize=14)\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='validation')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate(model,X,y):\n",
        "    y_pred_proba = model.predict(X)\n",
        "    y_pred = np.argmax(y_pred_proba,axis=1)\n",
        "    print(f\"Accuracy: {accuracy_score(y,y_pred)}\")\n",
        "    print(f\"F1 Score: {f1_score(y,y_pred,average='macro')}\")\n",
        "    cm = confusion_matrix(y_pred=y_pred,y_true=y)\n",
        "    plt.figure()\n",
        "    heatmap(cm,\n",
        "            fmt='g',\n",
        "            annot=True,\n",
        "            xticklabels=classes_names,\n",
        "            yticklabels=classes_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "m1DsBSS5EtEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDgmrWsWLO6"
      },
      "source": [
        "## Modelo MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos dos modelos"
      ],
      "metadata": {
        "id": "r8N4IymFAHVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Input, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def build_model(input_shape,small=True):\n",
        "    if small:\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=input_shape))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "        model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "    else:\n",
        "        model = Sequential()\n",
        "        model.add(Input(shape=input_shape))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "        model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "d9Qn_Q0YAJBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  MLP 1"
      ],
      "metadata": {
        "id": "J9qcQrsQO4Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp_1 = build_model((32,32,3),small=True)\n",
        "model_mlp_1.summary()"
      ],
      "metadata": {
        "id": "gpwVTGIX-cUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=3, min_lr=1e-6)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,\n",
        "                               restore_best_weights=True)"
      ],
      "metadata": {
        "id": "16y6NTg2-6z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚åö El entrenamiento tarda alrededor de 2 minutos"
      ],
      "metadata": {
        "id": "9i4Sj1wnIjnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_mlp_1.fit(X_train, y_train,\n",
        "                        batch_size=64,\n",
        "                        epochs=100,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[reduce_lr, early_stopping])"
      ],
      "metadata": {
        "id": "7SUEdizP_AFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_curves(history)"
      ],
      "metadata": {
        "id": "8z9txapm_Em4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ En estas curvas es muy notorio la acci√≥n del callback `ReduceLROnPlateau`."
      ],
      "metadata": {
        "id": "myiMP_FKODJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluemos el modelo en el conjunto de prueba"
      ],
      "metadata": {
        "id": "imBYkoukOvBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp_1.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "bHLiJq19JYyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hagamos una evaluaci√≥n m√°s detallada"
      ],
      "metadata": {
        "id": "UG553rzyOxnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model_mlp_1,X_test,y_test)"
      ],
      "metadata": {
        "id": "knJiODygMqBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP 2"
      ],
      "metadata": {
        "id": "mH70J73xO7Kx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos con una arquitectura MLP m√°s compleja (observa el n√∫mero de capas, tama√±o y n√∫mero total de par√°metros)"
      ],
      "metadata": {
        "id": "U6Qbn8iaO8tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp_2 = build_model((32,32,3),small=False)\n",
        "model_mlp_2.summary()"
      ],
      "metadata": {
        "id": "xaDjd2RtACLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ Observa que estamos usando los mismos callbacks inicializados del entrenamiento pasado. ¬øEs esto correcto?"
      ],
      "metadata": {
        "id": "vNeGPgbYJLqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚åö Este entrenamiento tarda alrededor de 4 minutos con GPU"
      ],
      "metadata": {
        "id": "H7ned6YjJuNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_mlp_2.fit(X_train, y_train,\n",
        "                        batch_size=64,\n",
        "                        epochs=100,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[reduce_lr, early_stopping])"
      ],
      "metadata": {
        "id": "gFGeEhIBBZ4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_curves(history)"
      ],
      "metadata": {
        "id": "c467CbhFE4mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos un mejor entrenamiento y un desempe√±o ligeramente superior"
      ],
      "metadata": {
        "id": "I4eqstHaJ85_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp_2.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "7E1HK-WZJmLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model_mlp_2,X_test,y_test)"
      ],
      "metadata": {
        "id": "eO9jSm4rMlBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo CNN"
      ],
      "metadata": {
        "id": "UAaPrAH8-5Zm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZFIorONDhG9"
      },
      "source": [
        "Definamos ahora un modelo con arquitectura CNN. Usaremos las capas [`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/) para las operaciones de convoluci√≥n y [`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/) para el pooling.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?id=1bzFBdsAq40yN95k2pA5X2OGsXf-40v0t\" width=\"600\" />\n",
        "</p>\n",
        "\n",
        "\n",
        "**Importante**: Observa la elecci√≥n de los hiperpar√°metros `padding=\"same\"` y `strides=1`. Esta elecci√≥n asegura que las salidas de cada capa convolucional tenga las mismas dimensiones que las entradas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yySANB-NNr4w"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input\n",
        "from keras.models import Sequential\n",
        "\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Input(shape=(32, 32, 3)))\n",
        "#----- PARTE CONVOLUCIONAL -------\n",
        "model_cnn.add(Conv2D(32, 3, activation='relu',\n",
        "                     padding=\"same\",\n",
        "                     strides=1))\n",
        "model_cnn.add(MaxPooling2D())\n",
        "model_cnn.add(Conv2D(64, 3, activation='relu',\n",
        "                     padding=\"same\", # Probemos comentando esta l√≠nea\n",
        "                     strides=1))\n",
        "model_cnn.add(MaxPooling2D())\n",
        "model_cnn.add(Conv2D(128, 3, activation='relu',\n",
        "                     padding=\"same\",\n",
        "                     strides=1))\n",
        "model_cnn.add(MaxPooling2D())\n",
        "#----- PARTE MLP ----------\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(512, activation='relu'))\n",
        "model_cnn.add(Dense(10, activation='softmax'))  # recordar que esta capa est√° fija por el problema\n",
        "\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSL8Y3n7rLtL"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model_cnn.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚åö El entrenamiento tarda alrededor de 3 minutos"
      ],
      "metadata": {
        "id": "jatsDo5DK8Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_cnn.fit(X_train, y_train,\n",
        "                        batch_size=64,\n",
        "                        epochs=100,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[reduce_lr, early_stopping])"
      ],
      "metadata": {
        "id": "O5ffxZFPCwJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_curves(history)"
      ],
      "metadata": {
        "id": "ObqUTHjYE6lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "wOQGhAOOLBAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model_cnn,X_test,y_test)"
      ],
      "metadata": {
        "id": "ERQ9BoSdLC1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ Observar que tenemos un rendimiento muy superior con esta red CNN al modelo MLP 2, a√∫n cuando el MLP es m√°s grande que el CNN (3.8 millones de par√°metros vs 1.1 millones de par√°metros). Esto exhibe el hecho de que las redes CNN son arquitecturas especialidas en problemas relacionados con im√°genes."
      ],
      "metadata": {
        "id": "7vjOgUfuMyMi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_lw22KscL6Rp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}