{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/02-MLP-Regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "WOLu-Lu0cVKM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Redes Neuronales MLP para regresi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Conectar la notebook en modo GPU (**en este caso no es muy necesario**)\n",
        "\n",
        "Entorno de ejecuci√≥n ‚Üí Cambiar tipo de entorno de ejecuci√≥n\n",
        "\n",
        "Algunas consideraciones:\n",
        "\n",
        "* No dejar la notebook conectada sin actividad ya que Colab penaliza esto al asignar un entorno con GPU.\n",
        "* No pedir el entorno con GPU si no se va a usar."
      ],
      "metadata": {
        "id": "J4xDK8oN01Fd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "En esta notebook describiremos c√≥mo resolver un problema de regresi√≥n usando una red neuronal MLP.\n",
        "\n",
        "Usaremos el conjunto de datos [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) y construiremos un modelo para predecir la eficiencia en el uso de combustible (en MPG, millas por gal√≥n) de vehiculos hechos entre 1970 y 1980. La descripci√≥n de cada veh√≠culo incluye atributos como: n√∫mero de cil√≠ndros, potencia, pa√≠s de origen y peso."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recuerda la simbolog√≠a de las secciones:\n",
        "\n",
        "* üîΩ Esta secci√≥n no forma parte del proceso usual de Machine Learning. Es una exploraci√≥n did√°ctica de alg√∫n aspecto del funcionamiento del algoritmo.\n",
        "* ‚ö° Esta secci√≥n incluye t√©cnicas m√°s avanzadas destinadas a optimizar o profundizar en el uso de los algoritmos.\n",
        "* ‚≠ï Esta secci√≥n contiene un ejercicio o pr√°ctica a realizar. A√∫n si no se establece una fecha de entrega, es muy recomendable realizarla para practicar conceptos clave de cada tema."
      ],
      "metadata": {
        "id": "_Y4PPm3cn3TI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## El conjunto de datos\n",
        "\n",
        "El dataset original se puede encontrar en [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/9/auto+mpg).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leemo el conjunto de datos en un dataframe."
      ],
      "metadata": {
        "id": "yV-4vQmmtBRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/DCDPUAEM/DCDP/main/04%20Deep%20Learning/data/auto-mpg.data\"\n",
        "\n",
        "df = pd.read_csv(url,\n",
        "                header=0,\n",
        "                index_col=0,\n",
        "                na_values = \"?\",\n",
        "                comment='\\t',\n",
        "                skipinitialspace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "WtdIwDvHn2H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWuJTKEDM-f"
      },
      "source": [
        "### Limpieza de los datos\n",
        "\n",
        "El dataset contiene algunos valores desconocidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEJHhN65a2VV"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPN0KBHa_WI"
      },
      "source": [
        "Eliminemos las filas con valores faltantes, ya que son pocas. Tambi√©n podr√≠amos imputar valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUDosChC1UN"
      },
      "outputs": [],
      "source": [
        "clean_df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKitwaH4v8h"
      },
      "source": [
        "La columna `\"Origin\"` es categorica, la codificamos con \"one-hot\" encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oh_df = pd.get_dummies(data=clean_df,columns=['Origin'],\n",
        "                       drop_first=True,dtype=int)\n",
        "oh_df"
      ],
      "metadata": {
        "id": "nRF26smsqNrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reemplazamos los nombres del origen"
      ],
      "metadata": {
        "id": "lJST2Qb2tkRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWNTD2QjBWFJ"
      },
      "outputs": [],
      "source": [
        "oh_df.rename(columns={\n",
        "                    # 'Origin_1':'USA',\n",
        "                      'Origin_2':'Europe',\n",
        "                      'Origin_3':'Japan'},\n",
        "             inplace=True)\n",
        "oh_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos las features y la variable dependiente."
      ],
      "metadata": {
        "id": "W2hkgNdHtoO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = oh_df.iloc[:,1:].values\n",
        "y = oh_df['MPG'].values\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "wR5w7hEksRJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### Divisi√≥n en conjuntos de entrenamiento y prueba\n",
        "\n",
        "Ahora dividimos el set de datos en un set de entrenamiento y otro de prueba.\n",
        "\n",
        "Usaremos el conjunto de prueba en la evaluacion final de nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.python import train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.85,random_state=189)\n",
        "\n",
        "print(f\"Train size: {X_train.shape[0]}\")\n",
        "print(f\"Test size: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "OJj_uC9fsCZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRklxK5s388r"
      },
      "source": [
        "### Normalizamos\n",
        "\n",
        "Inspeccionemos los rangos de las variables continuas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oh_df.iloc[:,1:7].plot.hist(subplots=True, legend=True)"
      ],
      "metadata": {
        "id": "zrQeJXuOtNyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywmerQ6dSox"
      },
      "source": [
        "Es una buena pr√°ctica normalizar funciones que utilizan diferentes escalas y rangos. Aunque el modelo *podr√≠a* converger sin normalizaci√≥n de features, esto suele dificultar el entrenamiento.\n",
        "\n",
        "**Observaciones**:\n",
        "1. Aunque s√≥lo entrenamos el escalador con el conjunto de datos de entrenamiento, este escalador tambi√©n se utilizar√° para normalizar el conjunto de datos de prueba. Necesitamos hacer eso para proyectar el conjunto de datos de prueba en la misma distribuci√≥n en la que el modelo ha sido entrenado.\n",
        "2. El reescalamiento debe aplicarse a cualquier otro dato que entre al modelo, junto con la codificaci√≥n de un punto que hicimos anteriormente. Eso incluye el conjunto de pruebas, as√≠ como los datos en vivo cuando el modelo se usa en producci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scl = scaler.fit_transform(X_train)\n",
        "X_test_scl = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "PPL3d9P86bR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "### Construcci√≥n del modelo\n",
        "\n",
        "Construyamos nuestro modelo. Aqu√≠, utilizaremos un modelo `sequential` con dos capas ocultas y una capa de salida que devuelve un √∫nico valor continuo.\n",
        "\n",
        "Observa la elecci√≥n de optimizador, m√©tricas de rendimiento, funci√≥n de costo y funciones de activaci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos definir directamente el modelo, como en la notebook pasada:"
      ],
      "metadata": {
        "id": "t1vbCIpSY3QU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c26juK7ZG8j-"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "layers.Dense(64, activation='relu', input_shape=[X_train_scl.shape[1]]),\n",
        "layers.Dense(64, activation='relu'),\n",
        "layers.Dense(1, activation=None)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model.compile(loss='mse',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['mae', 'mse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ö° Podemos tambi√©n definirlo por medio de una funci√≥n para generar nuevos modelos similares posteriormente:"
      ],
      "metadata": {
        "id": "TQ66z0UrY7GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[X_train_scl.shape[1]]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "    model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "_vIdIKtQZAAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "### Inspeccionemos el modelo\n",
        "\n",
        "Use el m√©todo `.summary` para imprimir una descripci√≥n simple del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReAD0n6MsFK-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt6W50qGsJAL"
      },
      "source": [
        "### üîΩ Acerca de la inicializaci√≥n de los pesos\n",
        "\n",
        "Observemos que ya podr√≠amos realizar predicciones con el modelo sin entrenar. Es decir, los pesos est√°n inicializados\n",
        "\n",
        "Tomamos un *batch* de 10 ejemplos de los datos de entrenamiento y realizamos las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d-gBaVtGTSC"
      },
      "outputs": [],
      "source": [
        "example_batch = X_train_scl[:10]\n",
        "example_predictions = model.predict(example_batch)\n",
        "example_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podr√≠amos medir su error MSE, o cualquier otra m√©trica de rendimiento."
      ],
      "metadata": {
        "id": "vIzDOy188yac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_train[:10],example_predictions)"
      ],
      "metadata": {
        "id": "Pac0G5-T8oea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### Entrenamos el modelo\n",
        "\n",
        "Entrenamos el modelo durante 1000 √©pocas, registramos la precisi√≥n de entrenamiento y validaci√≥n en el objeto `history`.\n",
        "\n",
        "*El entrenamiendo deber√≠a durar alrededor de 1 minuto.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD7qHCmNIOY0"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  X_train_scl, y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Podr√≠amos visualizar la historia del entrenamiento durante cada √©poca en un dataframe usando las estad√≠sticas almacenadas en el diccionario `history.history`.\n",
        "\n",
        "Realizaremos algunas manipulaciones adicionales con las historia del entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xj91b-dymEy"
      },
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la siguiente funci√≥n para graficar las m√©tricas de rendimiento durante el entrenamiento."
      ],
      "metadata": {
        "id": "y0BirpL1ufpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Abs Error [MPG]')\n",
        "    plt.plot(history.epoch, history.history['mae'],\n",
        "            label='Train Error')\n",
        "    plt.plot(history.epoch, history.history['val_mae'],\n",
        "            label = 'Val Error')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "    plt.plot(history.epoch, history.history['mse'],\n",
        "            label='Train Error')\n",
        "    plt.plot(history.epoch, history.history['val_mse'],\n",
        "            label = 'Val Error')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lguXVmMsioiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6XriGbVPh2t"
      },
      "outputs": [],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqsuANc11FYv"
      },
      "source": [
        "Este gr√°fico muestra poca mejora, o incluso degradaci√≥n en el error de validaci√≥n despu√©s de aproximadamente 100 √©pocas. **Esta es una se√±al de overfitting**.\n",
        "\n",
        "Repitamos el entrenamiento con menos √©pocas.\n",
        "\n",
        "Observa el par√°metro `verbose`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdMZuhUgzMZ4"
      },
      "outputs": [],
      "source": [
        "model_me = build_model()\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "history = model_me.fit(X_train_scl, y_train, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0)\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### M√©tricas de rendimiento"
      ],
      "metadata": {
        "id": "CeqBAG7Hb9Nm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "Veamos qu√© tan bien generaliza el modelo al usar el **conjunto de prueba**, el cual no fue usado para entrenar el modelo. Esto nos dice qu√© tan bien podemos esperar que el modelo prediga cu√°ndo lo usamos en el mundo real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl_yNr5n1kms"
      },
      "outputs": [],
      "source": [
        "loss, mae, mse = model_me.evaluate(X_test_scl, y_test, verbose=2)\n",
        "\n",
        "print(f\"MAE para las predicciones en el conjunto de prueba: {np.round(mae,4)} MPG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### Predicciones\n",
        "\n",
        "Finalmente, predecimos los valores de MPG utilizando los datos del conjunto de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "outputs": [],
      "source": [
        "y_pred = model_me.predict(X_test_scl).flatten()\n",
        "\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19wyogbOSU5t"
      },
      "source": [
        "Veamos la distribuci√≥n de errores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-OHX4DiXd8x"
      },
      "outputs": [],
      "source": [
        "error = y_pred - y_test\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Error en la predicci√≥n [MPG]\")\n",
        "plt.ylabel(\"Conteos\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚≠ï Pr√°ctica"
      ],
      "metadata": {
        "id": "Zl7IlJJgcE9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realiza las siguientes tareas. En las primeras 5 tareas el objetivo es experimentar y reflexionar sobre el efecto de distintos aspectos del entrenamiento en el rendimiento del modelo.\n",
        "\n",
        "1. Repite el entrenamiendo del modelo usando 100 √©pocas **sin normalizar los datos**, ¬øqu√© le sucede a las m√©tricas de rendimiento y curvas de entrenamiento?\n",
        "\n",
        "2. Repite el entrenamiendo del modelo usando 100 √©pocas, normalizaci√≥n de los datos y **con alguna funci√≥n de activaci√≥n en la capa de salida (tanh o sigmoide)**, ¬øqu√© le sucede a las m√©tricas de rendimiento y curvas de entrenamiento?\n",
        "\n",
        "4. Repite el entrenamiendo del modelo usando 100 √©pocas, normalizaci√≥n de los datos y **con la funci√≥n de activaci√≥n ReLU en la capa de salida**, ¬øqu√© le sucede a las m√©tricas de rendimiento y curvas de entrenamiento?\n",
        "\n",
        "5. Comprueba el modelo que entrenamos en la notebook (con 100 √©pocas, normalizaci√≥n y sin funci√≥n de activaci√≥n en la salida) con los siguientes algoritmos de ML cl√°sico:\n",
        " * Regresi√≥n Lineal\n",
        " * Regresi√≥n Polinomial\n",
        " * Regresor KNN\n",
        " Comprueba los modelos usando MAE en el conjunto de prueba. ¬øCu√°l tuvo mejor desempe√±o?  \n",
        "\n",
        "El objetivo en la siguiente tarea es experimentar para encontrar un mejor modelo que suba las m√©tricas de rendimiento del modelo. **Cuidado con el overfitting.**\n",
        "\n",
        "5. Usando los datos normalizados, prueba con diferentes combinaciones de los par√°metros del m√≥delo:\n",
        "    * N√∫mero de capas ocultas\n",
        "    * N√∫mero de nueronas en las capas ocultas\n",
        "    * Funciones de activaci√≥n de las capas ocultas\n",
        "    * Optimizador y tasa de entrenamiento\n",
        "\n",
        " Puedes hacer el modelo m√°s sencillo o m√°s complejo. Reporta la combinaci√≥n de par√°metros que produjo el mejor resultado.\n",
        "\n",
        "En esta √∫ltima tarea probaras c√≥mo es recibir nuevos datos para realizar predicciones con tu mejor modelo que hayas obtenido.\n",
        "\n",
        "6. Ya que tengas tu mejor modelo, toma el archivo `mpg_new_data.csv` del repositorio y obten las predicciones para estos datos. Compararemos contra los valores reales. Guarda estas predicciones en un archivo CSV."
      ],
      "metadata": {
        "id": "wWAn3u8giOxG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQVNlT6ycEzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "* El error cuadr√°tico medio (MSE) es una funci√≥n de p√©rdida com√∫n utilizada para problemas de regresi√≥n. Otra m√©trica de regresi√≥n com√∫n es el error absoluto medio (MAE).\n",
        "* Cuando las features de datos de entrada num√©ricos tienen valores con diferentes rangos, cada caracter√≠stica debe escalarse independientemente al mismo rango.\n",
        "* Si no hay muchos datos de entrenamiento, es preferible usar una red peque√±a con pocas capas ocultas para evitar el sobreajuste.\n",
        "* El entrenamiento con pocas √©pocas es una t√©cnica √∫til para evitar el sobreajuste. Otra t√©cnica es el *early stopping* (coming soon...)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVRylWbi36xl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Vt6W50qGsJAL"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}