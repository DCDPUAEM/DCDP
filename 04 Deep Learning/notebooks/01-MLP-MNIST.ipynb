{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/01-MLP-MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "OCYJbEwVkjda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Conectar la notebook en modo GPU\n",
        "\n",
        "Entorno de ejecuci√≥n ‚Üí Cambiar tipo de entorno de ejecuci√≥n\n",
        "\n",
        "Algunas consideraciones:\n",
        "\n",
        "* No dejar la notebook conectada sin actividad ya que Colab penaliza esto al asignar un entorno con GPU.\n",
        "* No pedir el entorno con GPU si no se va a usar."
      ],
      "metadata": {
        "id": "GFJ63s_YhFD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recuerda la simbolog√≠a de las secciones:\n",
        "\n",
        "* üîΩ Esta secci√≥n no forma parte del proceso usual de Machine Learning. Es una exploraci√≥n did√°ctica de alg√∫n aspecto del funcionamiento del algoritmo.\n",
        "* ‚ö° Esta secci√≥n incluye t√©cnicas m√°s avanzadas destinadas a optimizar o profundizar en el uso de los algoritmos.\n",
        "* ‚≠ï Esta secci√≥n contiene un ejercicio o pr√°ctica a realizar. A√∫n si no se establece una fecha de entrega, es muy recomendable realizarla para practicar conceptos clave de cada tema."
      ],
      "metadata": {
        "id": "i5RvSZFi--p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neuronales MLP para clasificaci√≥n\n",
        "\n",
        "<img align=\"center\" width=\"50%\" src=\"https://github.com/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/img/mlp.png?raw=1\"/>\n",
        "\n",
        "En esta notebook usaremos una red neuronal de tipo **MultiLayer Perceptron (MLP)** para el problema de clasificaci√≥n en el dataset MNIST.\n",
        "\n",
        "Veremos que con una red neuronal podremos entrenar un modelo para la clasificaci√≥n de este dataset usando todas las features sin mucho problema.\n",
        "\n",
        "---\n",
        "\n",
        "Recordemos el mejor modelo de Machine Learning cl√°sico que hemos obtenido:\n",
        "\n",
        "<center>\n",
        "<p><img src=\"https://drive.google.com/uc?id=1XY3iypQcSR868H7xFBilyxuzsJTzed4g\" width=\"500\" /></p>\n",
        "</center>\n",
        "\n",
        "Este modelo era dif√≠cil de entrenar en cuesti√≥n de la duraci√≥n del entrenamiento y requiri√≥ una busqueda exhaustiva de par√°metros.\n",
        "\n",
        "Con PCA (50-60 componentes principales) y SVM estabamos alrededor de 97% en las m√©tricas."
      ],
      "metadata": {
        "id": "jVMPmLi1VBRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmarks para el dataset MNIST\n",
        "\n",
        "1. **No Routing Needed Between Capsules**, 2020. *Accuracy: 99.87%*\n",
        "\n",
        "    Modelo de redes CNN con Homogeneous Vector Capsules (HVCs) que modifican el flujo de datos entre capas. [Art√≠culo](https://arxiv.org/abs/2001.09136), [c√≥digo](https://github.com/AdamByerly/BMCNNwHFCs).\n",
        "\n",
        "2. **An Ensemble of Simple Convolutional Neural Network Models for MNIST Digit Recognition**, 2020. *Accuracy: 99.87%*\n",
        "\n",
        "    Modelo de ensamble de redes CNN [Art√≠culo](https://arxiv.org/abs/2008.10400), [c√≥digo](https://github.com/ansh941/MnistSimpleCNN)."
      ],
      "metadata": {
        "id": "VU2YX1qiLBpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. El conjunto de datos"
      ],
      "metadata": {
        "id": "QqvYSnkjVIzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observar que, ahora s√≠, usamos todo el conjunto de datos completo."
      ],
      "metadata": {
        "id": "_d9wyeG1tpKA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyilk52n8rbV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load MNIST handwritten digit data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "y_test_original = y_test.copy()  # Hacemos una copia del 'y_test', la usaremos al final"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordar que tenemos que dividir en tres conjuntos de entrenamiento: train, validation y test.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ts1ZZlHl1qTdkD_FZ2uvi9wkJtuTNH8M\" style=\"width: 60%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "-VtlF5rZwG2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=0.15,\n",
        "                                                  stratify=y_train,  # RECORDAR LA ESTRATIFIACI√ìN\n",
        "                                                  random_state=894)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "_APG4_h_fzEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que esto no afecta a las imagenes:"
      ],
      "metadata": {
        "id": "1LJ5JTw65bJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Escogemos algunos √≠ndices:\n",
        "idxs = np.random.choice(range(X_train.shape[0]),size=3,replace=False)\n",
        "\n",
        "# Hacemos 3 tipos de reescalamiento:\n",
        "X_minmax = MinMaxScaler().fit_transform(X_train[idxs,:].reshape(-1,28*28))\n",
        "X_std = StandardScaler().fit_transform(X_train[idxs,:].reshape(-1,28*28))\n",
        "X_scl = X_train[idxs,:].reshape(-1,28*28)/255.\n",
        "\n",
        "# T√≠tulos para cada fila\n",
        "row_titles = [\n",
        "    \"Im√°genes originales\",\n",
        "    \"MinMaxScaler (por feature)\",\n",
        "    \"StandardScaler (por feature)\",\n",
        "    \"Reescalado [0, 1] (x/255)\"\n",
        "]\n",
        "\n",
        "# Graficamos:\n",
        "fig, axs = plt.subplots(ncols=3, nrows=4, sharex=False,\n",
        "                       sharey=True, figsize=(6, 9))\n",
        "for i, idx in enumerate(idxs):\n",
        "\t# Fila 0: Originales\n",
        "\taxs[0,i].imshow(X_train[idx], cmap='plasma')\n",
        "\taxs[0,i].axis('off')\n",
        "\n",
        "\t# Fila 1: MinMax\n",
        "\taxs[1,i].imshow(X_minmax[i].reshape(28,28), cmap='plasma')\n",
        "\taxs[1,i].axis('off')\n",
        "\n",
        "\t# Fila 2: StandardScaler\n",
        "\taxs[2,i].imshow(X_std[i].reshape(28,28), cmap='plasma')\n",
        "\taxs[2,i].axis('off')\n",
        "\n",
        "\t# Fila 3: Reescalado manual\n",
        "\taxs[3,i].imshow(X_scl[i].reshape(28,28), cmap='plasma')\n",
        "\taxs[3,i].axis('off')\n",
        "\tif i == 1:\n",
        "\t\tfor j in range(4):\n",
        "\t\t\taxs[j,i].set_title(row_titles[j],fontsize=10)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "1hpMz6rz5e6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ Esto nos da una idea del data leakage"
      ],
      "metadata": {
        "id": "VB07z5LuH5-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apliquemos el preprocesamiento para este dataset:"
      ],
      "metadata": {
        "id": "p5bajmLh5Mnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"M√°ximo valor de X_train: {np.max(X_train)}\")\n",
        "print(f\"M√≠nimo valor de X_train: {np.min(X_train)}\")\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(f\"M√°ximo valor de X_train: {np.max(X_train)}\")\n",
        "print(f\"M√≠nimo valor de X_train: {np.min(X_train)}\")"
      ],
      "metadata": {
        "id": "K2j_drw-o2Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos 6 ejemplos aleatorios, junto con sus etiquetas"
      ],
      "metadata": {
        "id": "aMaXApsBWk4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------ Obtenemos algunos √≠ndices aleatorios:\n",
        "some_idxs = np.random.choice(list(range(y_train.shape[0])),size=6,replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=6, sharex=False,\n",
        "\t\t\t sharey=True, figsize=(10, 4))\n",
        "for i,idx in enumerate(some_idxs):\n",
        "\taxes[i].set_title(y_train[idx],fontsize=15)\n",
        "\taxes[i].imshow(X_train[idx], cmap='gray')\n",
        "\taxes[i].get_xaxis().set_visible(False)\n",
        "\taxes[i].get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bUTt4ZizVYwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definiendo la red"
      ],
      "metadata": {
        "id": "mW1Z8KJlcrzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Etiqueta de clase vs Vector de clase\n",
        "\n",
        "**IMPORTANTE‚ùó**\n",
        "\n",
        "Al usar redes neuronales, usalmente el vector de etiquetas debe estar codificado como vectores **one-hot**. Es decir:\n",
        "\n",
        "$$1 ‚Üí (1,0,...,0) $$\n",
        "$$2 ‚Üí (0,1,...,0) $$\n",
        "$$ ... $$\n",
        "\n",
        "Entonces, las etiquetas $y$ son matrices de tama√±o $N\\times m$ donde\n",
        "\n",
        "* $N$: n√∫mero de instancias\n",
        "* $m$: n√∫mero de clases\n",
        "\n",
        "\n",
        "\n",
        "Hacemos la codificaci√≥n usando la funci√≥n [`to_categorical`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) de [keras](https://www.tensorflow.org/guide/keras).\n",
        "\n",
        "$$y_j \\overset{\\text{to_categorical}}{\\rightarrow} (0,...,0,\\overset{j}{1},0,...,0)$$\n",
        "\n",
        "$$y_j \\overset{\\text{numpy.argmax}}{\\leftarrow} (0,...,0,\\overset{j}{1},0,...,0)$$\n",
        "\n",
        "‚ö† A lo largo de las versiones, a veces cambia de ubicaci√≥n este tipo de funciones.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LhgR_BXxQh1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"---------- Antes de la codificaci√≥n ----------\")\n",
        "print(f\"Primeras 5 etiquetas: {y_train[:5]}\")\n",
        "print(f\"Shape: {y_train.shape}\")\n",
        "\n",
        "y_train = to_categorical(y_train,num_classes=10)\n",
        "\n",
        "print(\"---------- Despu√©s de la codificaci√≥n ----------\")\n",
        "print(f\"Primeras 5 etiquetas:\\n{y_train[:5]}\\n\")\n",
        "print(f\"Shape: {y_train.shape}\")\n",
        "\n",
        "y_val = to_categorical(y_val,num_classes=10)\n",
        "y_test = to_categorical(y_test,num_classes=10)"
      ],
      "metadata": {
        "id": "e6m0Lsa287SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingredientes de una arquitectura"
      ],
      "metadata": {
        "id": "PX0WLYf7EFz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay dos principales maneras de definir modelos en Keras:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1lbLQ7D1_QElq_iTscpQ_rjXPWJ2uPke3\" width=500>\n",
        "</center>\n",
        "\n",
        "\n",
        "* [**Sequential**](https://keras.io/api/models/sequential/): Un modelo es una secuencia lineal de *layers*. Es sencilla de implementar pero no muy flexible.\n",
        "\n",
        "\n",
        "* [**Model**](https://www.tensorflow.org/api_docs/python/tf/keras/Model): Un modelo se especifica mediante una estructura similar a un *grafo*, indicando conexiones entre *layers*. Es muy flexible.\n",
        "\n"
      ],
      "metadata": {
        "id": "0zb07-KDEVuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "QP-kmKm8Ifn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ahora, usaremos los siguientes tipos b√°sicos de capas:\n",
        "\n",
        "* [**Dense**](https://keras.io/api/layers/core_layers/dense/): implementa la operaci√≥n:\n",
        "$$\\text{output} = \\text{activation}(\\text{input}\\cdot\\text{weights} + \\text{bias})$$\n",
        "donde `activation` es la funci√≥n de activaci√≥n y bias es un vector de sesgo creado por la capa (s√≥lo aplicable si `use_bias` es True). Es una capa **densa** por lo que cada neurona de esta capa se conecta con cada una de las neuronas de la capa anterior.\n",
        "* [**Flatten**](https://keras.io/api/layers/reshaping_layers/flatten/): Aplana los datos para tener un arreglo unidimensional.\n",
        "* [**Input**](https://keras.io/api/layers/core_layers/input/): Define el tensor de entrada de la red con su forma. Es el punto de entrada para los datos en el modelo."
      ],
      "metadata": {
        "id": "4d6agAfTRbbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Flatten, Input"
      ],
      "metadata": {
        "id": "rACJOLUmVPKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos ahora la arquitectura de la red neuronal MLP. Observa los siguientes elementos:\n",
        "\n",
        "* La **funci√≥n de activaci√≥n** de cada capa, [documentaci√≥n](https://keras.io/api/layers/activations/).\n",
        "* La **funci√≥n de perdida** de la red, es la funci√≥n de costo que mide que tanto error hay en las predicciones. El optimizador minimizar√° est√° funci√≥n, [documentaci√≥n](https://keras.io/api/losses/).\n",
        "* El **optimizador** es la clase que minimizar√° la funci√≥n de perdida. De su elecci√≥n depende qu√© tan r√°pido converjamos a una soluci√≥n, [documentaci√≥n](https://keras.io/api/optimizers/)\n",
        "* La(s) **m√©trica(s) de desempe√±o** a monitorear durante el entrenamiento, tanto en el conjunto de entrenamiento como en el de validaci√≥n. Adem√°s, podemos evaluar las m√©tricas usuales al generar las predicciones. [Documentaci√≥n](https://keras.io/api/metrics/)"
      ],
      "metadata": {
        "id": "buR2gumKxqlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28)))\n",
        "model.add(Flatten()) # Tenemos que aplanar las matrices representando a cada imagen, las capas densas s√≥lo funcionan con vectores de entrada\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))  # Cuando se trata de tareas de clasificaci√≥n multiclase, ponemos una activaci√≥n softmax en la capa de salida"
      ],
      "metadata": {
        "id": "60jIjz2c9gpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "oJxIalpahBnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El m√©todo `summary()` de un modelo de Keras (ya sea `Sequential` o `Model`) imprime informaci√≥n importante del modelo. [Documentaci√≥n](https://keras.io/api/models/model/)."
      ],
      "metadata": {
        "id": "mNqfxHgeiRA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es compilar el modelo. Esto lo hacemos con el m√©todo [`compile`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile).\n",
        "\n",
        "---\n",
        "\n",
        "Una gu√≠a general sobre funciones de perdida y m√©tricas\n",
        "\n",
        "| Aplicaci√≥n                     | Funci√≥n de P√©rdida (Loss)          | M√©trica usual           | √öltima capa (output layer)          |\n",
        "|---------------------------------|------------------------------------|-------------------------|-------------------------------------|\n",
        "| Clasificaci√≥n binaria          | `binary_crossentropy`              | `accuracy`              | `Dense(1, activation='sigmoid')`    |\n",
        "| Clasificaci√≥n multiclase       | `categorical_crossentropy`         | `accuracy`              | `Dense(num_clases, activation='softmax')` |\n",
        "| Regresi√≥n (un valor)           | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(1, activation='linear')`     |\n",
        "| Regresi√≥n (m√∫ltiples valores)  | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(num_valores, activation='linear')` |\n",
        "\n",
        "Una gu√≠a general sobre optimizadores:\n",
        "\n",
        "| Optimizador  | Ventajas                             | Casos de Uso T√≠picos         | Par√°metros Clave               |\n",
        "|--------------|--------------------------------------|------------------------------|--------------------------------|\n",
        "| **Adam**     | Convergencia r√°pida, adaptable      | Default para MLPs, CNN, RNN  | `lr`  |\n",
        "| **SGD**      | Mayor control, estable con momentum | Problemas convexos, fine-tuning | `lr`, `momentum`      |\n",
        "| **RMSprop**  | Bueno para datos ruidosos           | RNNs, problemas inestables    | `lr`, `rho`          |\n",
        "\n",
        "---\n",
        "\n",
        "‚ö† ‚ùó **IMPORTANTE** Antes de volver a entrenar un modelo, **debes recompilarlo** con el m√©todo `compile()`. Esto reinicializa los pesos aleatoriamente y evita que el entrenamiento contin√∫e desde los pesos previamente aprendidos.  "
      ],
      "metadata": {
        "id": "Px0VQcJGftdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "\t      optimizer='adam',\n",
        "\t      metrics=['acc']\n",
        "\t\t  )"
      ],
      "metadata": {
        "id": "okXXQBa8f1X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ö° Visualizando la arquitectura de la red"
      ],
      "metadata": {
        "id": "FyrmUWeEh_N5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se presentan dos maneras adicionales de visualizar la arquitectura de la red. Hay estrategias que producen efectos m√°s atractivos, puedes buscar por tu cuenta."
      ],
      "metadata": {
        "id": "uqMnufm6iCm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando [`plot_model`](https://keras.io/api/utils/model_plotting_utils/) de keras\n",
        "\n",
        "El `None` en el shape de las entradas y salidas se refiere a que no tiene esa informaci√≥n, son los ejemplos que pasan al *mismo tiempo*. Aqu√≠ se muestra la informaci√≥n relativa a los *batches*"
      ],
      "metadata": {
        "id": "-RlbmEMl16SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True,\n",
        "           show_layer_names=True, dpi=100)"
      ],
      "metadata": {
        "id": "vfCezyaNXgfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando visualkeras"
      ],
      "metadata": {
        "id": "GBcIozjp111I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq visualkeras"
      ],
      "metadata": {
        "id": "gkViMsYljCUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from visualkeras import layered_view\n",
        "\n",
        "layered_view(model,\n",
        "            legend=True,draw_funnel=False,\n",
        "            draw_volume=True,spacing=30)"
      ],
      "metadata": {
        "id": "Cls-tBPcjG-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos agregar m√°s detalles, como los colores"
      ],
      "metadata": {
        "id": "uxmiWMCcpe5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "color_map = defaultdict(dict)\n",
        "color_map[Dense]['fill'] = '#5b56b7'\n",
        "color_map[Flatten]['fill'] = '#0fbe0b'\n",
        "layered_view(model, legend=True,color_map=color_map)"
      ],
      "metadata": {
        "id": "QZeYkdfBpJEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenando la red"
      ],
      "metadata": {
        "id": "SCWhDOIhcx6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos la red con el m√©todo [`fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), la m√©canica es la misma que en los m√©todos de ML cl√°sico.\n",
        "\n",
        "Algunas diferencias son:\n",
        "\n",
        "* Especificar el n√∫mero de √©pocas. Entre m√°s √©pocas, m√°s puede aprender el m√≥delo, aunque hay m√°s riesgo de overfitting.\n",
        "\n",
        "* Especificar el conjunto de validaci√≥n, adem√°s del conjunto de entrenamiento. Este sirve para proporcionar un indicador no sesgado del desempe√±o del modelo. Se puede hacer especificamente, o como una fracci√≥n del conjunto de entrenamiento.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uFawgzy6iQBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa las m√©tricas y p√©rdida en el conjunto de entrenamiento y validaci√≥n.\n",
        "\n",
        "El entrenamiento regresa un objeto de tipo `History`. Su atributo History.history es un registro de valores de p√©rdidas de entrenamiento y valores de m√©tricas en √©pocas sucesivas, as√≠ como valores de p√©rdidas de validaci√≥n y valores de m√©tricas de validaci√≥n (si procede)."
      ],
      "metadata": {
        "id": "HiGm_48QijLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epocas = 8\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=n_epocas, validation_data=(X_val,y_val))"
      ],
      "metadata": {
        "id": "AiR8OwXtcxlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos la funci√≥n de perdida en cada √©poca, tanto en el conjunto de entrenamiento, como en el de validaci√≥n.\n",
        "\n",
        "Estas se llaman **gr√°ficas de entrenamiento**. Son muy importantes para evaluar si hay overfitting, entre otras cosas.\n",
        "\n",
        "Observa que los registros *hist√≥ricos* del entrenamiento (perdidas y m√©tricas) se encuentran en el diccionario `history.history` especificado anteriormente."
      ],
      "metadata": {
        "id": "W_gbtP6biie8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "acc_train = history.history['acc']\n",
        "acc_val = history.history['val_acc']\n",
        "\n",
        "epochs = range(1,n_epocas+1)\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(12,5))\n",
        "axs[0].plot(epochs, loss_train, 'g', label='Training loss')\n",
        "axs[0].plot(epochs, loss_val, 'b', label='validation loss')\n",
        "axs[0].title.set_text('Loss')\n",
        "axs[0].set(xlabel=\"√âpoca\", ylabel=\"Loss\")\n",
        "axs[0].legend()\n",
        "axs[1].plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "axs[1].plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "axs[1].title.set_text('Accuracy')\n",
        "axs[1].set(xlabel=\"√âpoca\", ylabel=\"Accuracy\")\n",
        "axs[1].legend()\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kxTBG2maTJ8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ ¬øHay se√±ales de overfitting? ¬øunderfitting?"
      ],
      "metadata": {
        "id": "HU4pE_eFe4Wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ö° De la siguiente forma podemos acceder a la matriz de pesos y sesgos en cada capa. Las guardamos como arreglos de numpy."
      ],
      "metadata": {
        "id": "il-DfAt8iaAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_layer_weights = model.layers[1].get_weights()[0]\n",
        "first_layer_biases  = model.layers[1].get_weights()[1]\n",
        "\n",
        "np.save(\"mnist_weights1.npy\",first_layer_weights)\n",
        "np.save(\"mnist_biases1.npy\",first_layer_biases)"
      ],
      "metadata": {
        "id": "gBNBoNKvVBqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_layer_weights = model.layers[2].get_weights()[0]\n",
        "second_layer_biases  = model.layers[2].get_weights()[1]\n",
        "\n",
        "np.save(\"mnist_weights2.npy\",second_layer_weights)\n",
        "np.save(\"mnist_biases2.npy\",second_layer_biases)"
      ],
      "metadata": {
        "id": "vdfwdS6HWQXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicciones y rendimiento"
      ],
      "metadata": {
        "id": "_qz0K0NOIyFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîΩ ¬øC√≥mo se ven las predicciones?"
      ],
      "metadata": {
        "id": "aGZMU7s6Xr30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import heatmap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----- Escogemos un elemento del conjunto test:\n",
        "idx = np.random.choice(range(X_test.shape[0]),size=1)[0]\n",
        "print(f\"√≠ndice test: {idx}\")\n",
        "x = X_test[idx].copy()\n",
        "\n",
        "# ----- Graficamos este ejemplo de prueba:\n",
        "plt.figure()\n",
        "plt.suptitle(y_test_original[idx],fontsize=15)\n",
        "plt.imshow(x, cmap='gray')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "# ----- Cambiamos a la forma adecuada para entrar a la red neuronal:\n",
        "x_input = x.reshape(-1,x.shape[0],x.shape[1])\n",
        "\n",
        "# ----- Lo pasamos por la red neuronal ya entrenada:\n",
        "prediction = model.predict(x_input)\n",
        "print(f\"\\nSalida de la red neuronal para este elemento:\")\n",
        "\n",
        "plt.figure(figsize=(5,1))\n",
        "heatmap(prediction, cmap='plasma',annot=np.round(prediction,2),cbar=False)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "print(f\"Son probabilidades, la suma de las entradas es {np.sum(prediction)}\")\n",
        "\n",
        "# ----- Tomamos el argmax:\n",
        "prediction = np.argmax(prediction, axis=1)\n",
        "print(f\"\\nTomamos el √≠ndice de la entrada con mayor probabilidad: {prediction}\")"
      ],
      "metadata": {
        "id": "FnIT0a9oXpWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos todas las predicciones sobre el conjunto de prueba."
      ],
      "metadata": {
        "id": "sZGUKuY5aFWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_matrix = model.predict(X_test,batch_size=1)  # Observa el batch_size\n",
        "predictions = np.argmax(predictions_matrix, axis=1)  # Prueba a comentar esta l√≠nea y discutamos qu√© pasa"
      ],
      "metadata": {
        "id": "x0YY_HBa9jAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos algunas predicciones"
      ],
      "metadata": {
        "id": "HlXiyLiGaLJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = np.random.choice(range(X_test.shape[0]),size=10,replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
        "\t\t\t sharey=True, figsize=(18, 4))\n",
        "for i,idx in enumerate(idxs):\n",
        "\taxes[i].set_title(predictions[idx])\n",
        "\taxes[i].imshow(X_test[idx], cmap='gray')\n",
        "\taxes[i].get_xaxis().set_visible(False)\n",
        "\taxes[i].get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "daQYjWh99iq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos las m√©tricas de desempe√±o de la tarea de clasificaci√≥n. Observar que ambas son **vectores** de etiquetas"
      ],
      "metadata": {
        "id": "1cUoiJrvir5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.shape)\n",
        "print(y_test_original.shape)"
      ],
      "metadata": {
        "id": "WCz6DqTG7vwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_score(y_pred=predictions,y_true=y_test_original)}\")\n",
        "print(f\"Test Recall: {recall_score(y_pred=predictions,y_true=y_test_original,average='macro')}\")\n",
        "print(f\"Test Precision: {precision_score(y_pred=predictions,y_true=y_test_original,average='macro')}\")"
      ],
      "metadata": {
        "id": "GxxW6UUA9qP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el roc-auc score"
      ],
      "metadata": {
        "id": "15IH0ptN_HJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(f\"Shape de y_test: {y_test.shape}\")\n",
        "print(f\"Shape de las predicciones para el conjunto de prueba: {predictions_matrix.shape}\")\n",
        "\n",
        "ra_score = roc_auc_score(y_test,predictions_matrix)\n",
        "print(f\"ROC-AUC score {ra_score}\")"
      ],
      "metadata": {
        "id": "CGdLt3Jq-hDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos la matriz de confusi√≥n"
      ],
      "metadata": {
        "id": "7ZCs1TCsiwr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "cm = confusion_matrix(y_test_original,predictions)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L24mC3bcO0AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚≠ï ¬øQu√© d√≠gitos son los que m√°s confunde la red?"
      ],
      "metadata": {
        "id": "XebS2v79iy74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La diferencia entre las m√©tricas de clasificaci√≥n (accuracy, precision, recall) y el ROC-AUC radica en lo que cada una eval√∫a. Las m√©tricas de clasificaci√≥n miden el rendimiento del modelo con un umbral de decisi√≥n fijo, t√≠picamente 0.5 para clasificaci√≥n binaria o el valor m√°ximo de probabilidad para multiclase. En contraste, el ROC-AUC eval√∫a la capacidad del modelo para distinguir entre clases a trav√©s de todos los posibles umbrales de decisi√≥n. Un modelo puede tener un ROC-AUC alto porque ordena correctamente las muestras seg√∫n su probabilidad de pertenencia a cada clase, pero mostrar m√©tricas de clasificaci√≥n moderadas porque las probabilidades predichas no est√°n calibradas para el umbral de decisi√≥n utilizado. Esta discrepancia indica que el modelo posee buena capacidad discriminativa pero requiere optimizaci√≥n del umbral de decisi√≥n o calibraci√≥n de probabilidades para maximizar su rendimiento en la clasificaci√≥n final."
      ],
      "metadata": {
        "id": "CGRooKhQRjXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîΩ Predicci√≥n en el mundo real\n",
        "\n",
        "Observa que este modelo est√° listo para hacer predicciones en el *mundo real*. Carguemos algunas imagenes de d√≠gitos hechos por t√≠:\n",
        "\n",
        "* Escribe un d√≠gito en una hoja\n",
        "* T√≥male foto\n",
        "* Guardalo como imagen png\n",
        "* S√∫bela a colab\n",
        "* Ejecuta la celda siguiente con las modificaciones pertinentes"
      ],
      "metadata": {
        "id": "GkOOiinlg8o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def procesar_imagen(ruta_imagen):\n",
        "    img = Image.open(ruta_imagen) # Leer la imagen\n",
        "    img_gris = img.convert('L') # Convertir a escala de grises\n",
        "    img_28x28 = img_gris.resize((28, 28),\n",
        "                                # Image.Resampling.LANCZOS\n",
        "                                ) # Redimensionar a 28x28 p√≠xeles\n",
        "    arreglo = np.array(img_28x28, dtype=int) # Convertir a arreglo NumPy\n",
        "    arreglo = np.clip(arreglo, 0, 255) # Asegurar que los valores est√°n en 0-255\n",
        "    return arreglo\n",
        "\n",
        "\n",
        "ruta = '/content/my_digits_3.png'  # Cambia por tu ruta\n",
        "\n",
        "arreglo_28x28 = procesar_imagen(ruta)\n",
        "arreglo_28x28 = 255 - arreglo_28x28  # Invierte colores\n",
        "arreglo_28x28 = arreglo_28x28.astype('int')/255\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(arreglo_28x28, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ojpNi9dYg8dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(arreglo_28x28)"
      ],
      "metadata": {
        "id": "97ur0wVDi_GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion = model.predict(arreglo_28x28.reshape(-1,28,28))\n",
        "np.argmax(prediccion)"
      ],
      "metadata": {
        "id": "2XPP86BdiVUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚≠ï Pr√°ctica y Ejercicios\n",
        "\n",
        "En esta pr√°ctica vamos a definir, compilar y entrenar varias arquitecturas de redes neuronales\n",
        "\n",
        "Implementa las siguientes redes neuronales de tipo MLP:\n",
        "\n",
        "* 1 capa oculta de 200 neuronas sin activaci√≥n. Entrena durante 30 √©pocas.\n",
        "* 1 capa oculta de 200 neuronas con activaci√≥n $tanh$. Entrena durante 30 √©pocas.\n",
        "* 3 capas ocultas de 100, 200 y 100 neuronas respectivamente, todas con activaci√≥n ReLU. Entrena durante 50 √©pocas.\n",
        "\n",
        "En cada uno de los experimentos determina las especificaciones de las capas de entrada y salida. Adem√°s, en cada caso, reporta el accuracy y recall en el conjunto de prueba, as√≠ como las curvas de entrenamiento (perdida y accuracy).\n",
        "\n",
        "* Con el objetivo de subir la m√©trica de accuracy en el conjunto de prueba, entrena un nuevo m√≥delo de red neuronal MLP cambiando los siguientes hiperpar√°metros:\n",
        "\n",
        " * N√∫mero de capas ocultas.\n",
        " * N√∫mero de neuronas en cada capa oculta.\n",
        " * Funci√≥n de activaci√≥n de cada capa oculta.\n",
        " * Optimizador ([opciones](https://keras.io/api/optimizers/)).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Como referencia, el mejor resultado hasta ahora, sin usar redes convolucionales, es un accuracy de 99.65% (https://arxiv.org/abs/1003.0358)\n",
        "\n",
        "Lista de resultados: http://yann.lecun.com/exdb/mnist/, https://paperswithcode.com/sota/image-classification-on-mnist"
      ],
      "metadata": {
        "id": "vDSCKhUMkOUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "476YuSzUohvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üü¢ Descargamos el conjunto de datos y preprocesamiento"
      ],
      "metadata": {
        "id": "C0uSyZVTX80C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=0.15,\n",
        "                                                  stratify=y_train,\n",
        "                                                  random_state=782)\n",
        "\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_val = X_val.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "\n",
        "y_test_original = y_test.copy()\n",
        "y_train = to_categorical(y_train,num_classes=10)\n",
        "y_val = to_categorical(y_val,num_classes=10)\n",
        "y_test = to_categorical(y_test,num_classes=10)"
      ],
      "metadata": {
        "id": "uDnEB9WX8m8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define una arquitectura con una capa oculta de 200 neuronas, con activaci√≥n `tanh`"
      ],
      "metadata": {
        "id": "WckUKa5QYYlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28)))\n",
        "model.add(Flatten())\n",
        "\n",
        "# a√±ade la capa oculta:\n",
        "\n",
        "\n",
        "# ---------------\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Imprimimos el summary:\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fYF4ustEYUtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Compila el modelo con la misma funci√≥n de perdida, m√©trica y optimzador"
      ],
      "metadata": {
        "id": "lvGvrGwSZy4T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOzzcuK_Z2Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Entrena el modelo en el conjunto de entrenamiento, usa el conjunto `X_val, y_val` como validaci√≥n. Entrena durante 15 √©pocas."
      ],
      "metadata": {
        "id": "XFd6B3X3Z2dq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czVlhvQZOQ_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üü¢ Graficamos la p√©rdida y m√©trica durante el entrenamiento, ¬øobservas overfitting o underfitting?"
      ],
      "metadata": {
        "id": "YRvIE3waO9Zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "acc_train = history.history['acc']\n",
        "acc_val = history.history['val_acc']\n",
        "\n",
        "epochs = range(1,n_epocas+1)\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(12,5))\n",
        "axs[0].plot(epochs, loss_train, 'g', label='Training loss')\n",
        "axs[0].plot(epochs, loss_val, 'b', label='validation loss')\n",
        "axs[0].title.set_text('Loss')\n",
        "axs[0].set(xlabel=\"√âpoca\", ylabel=\"Loss\")\n",
        "axs[0].legend()\n",
        "axs[1].plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "axs[1].plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "axs[1].title.set_text('Accuracy')\n",
        "axs[1].set(xlabel=\"√âpoca\", ylabel=\"Accuracy\")\n",
        "axs[1].legend()\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_5sL06wPO9Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Obten las predicciones y evalua el desempe√±o del modelo usando F1-score y Accuracy. Imprime ambas m√©tricas"
      ],
      "metadata": {
        "id": "LW3WaLK2SJAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "predictions_matrix = ...\n",
        "y_pred = np.argmax(predictions_matrix, axis=1)\n",
        "\n",
        "accuracy = ...\n",
        "f1score = ..."
      ],
      "metadata": {
        "id": "0HWXsHLySI2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ En una sola celda, define una red MLP con las siguientes especificaciones:\n",
        "\n",
        "* Capa de entrada (indica el `shape` adecuado)\n",
        "* Capa Flatten\n",
        "* Capa Oculta Densa de 200 neuronas, activaci√≥n `relu`\n",
        "* Capa Oculta Densa de 500 neuronas, activaci√≥n `tanh`\n",
        "* Capa Oculta Densa de 200 neuronas, activaci√≥n `relu`\n",
        "* Capa de Salida adecuada con activaci√≥n adecuada\n",
        "\n",
        "El resto de pasos como el ejercicio anterior.\n"
      ],
      "metadata": {
        "id": "5LcPO9HrTe74"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyZWUO79TesO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soluci√≥n\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "XohNww6KYNg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se muestra una soluci√≥n con un modelo entrenado previamente:"
      ],
      "metadata": {
        "id": "kk3G1vS_XfnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# URL del archivo raw en GitHub\n",
        "url = \"https://github.com/DCDPUAEM/DCDP/raw/main/04%20Deep%20Learning/data/mejor_modelo_mlp.h5\"\n",
        "\n",
        "# Descargar el archivo usando wget\n",
        "!wget {url}"
      ],
      "metadata": {
        "id": "m3pkWR-KYmfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el modelo\n",
        "modelo = keras.models.load_model('mejor_modelo_mlp.h5')\n",
        "\n",
        "# Ver arquitectura del modelo entrenado y cargado\n",
        "print(\"=== Resumen del modelo ===\")\n",
        "modelo.summary()"
      ],
      "metadata": {
        "id": "nyeP4o8RTrJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion = modelo.predict(X_test.reshape(-1,28*28))\n",
        "y_pred = np.argmax(prediccion, axis=1)\n",
        "print(y_pred[:10])"
      ],
      "metadata": {
        "id": "7IX973xfTzpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test_original,y_pred)\n",
        "plt.figure()\n",
        "heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_score(y_pred=y_pred,y_true=y_test_original)}\")\n",
        "print(f\"Test F1-score: {f1_score(y_pred=y_pred,y_true=y_test_original,average='macro')}\")"
      ],
      "metadata": {
        "id": "KhYOWA71UJdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5mdxHFeEUjU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}