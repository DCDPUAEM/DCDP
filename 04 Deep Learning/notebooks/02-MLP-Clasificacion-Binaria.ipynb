{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/02-MLP-Clasificacion-Binaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "DoFG1IdbXRc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción de Diabetes con MLP  \n",
        "\n",
        "<h2>Introducción</h2>\n",
        "\n",
        "La diabetes es una enfermedad crónica que afecta a millones de personas en el mundo, y su detección temprana es crucial para prevenir complicaciones graves. El *Diabetes Prediction Dataset* proporciona información médica y demográfica de pacientes, incluyendo variables como edad, género, índice de masa corporal (IMC), niveles de HbA1c, glucosa en sangre, historial de hipertensión, enfermedades cardíacas y hábitos de tabaquismo. Este conjunto de datos permite desarrollar modelos de aprendizaje automático para predecir el diagnóstico de diabetes (clasificación binaria: positivo/negativo), apoyando a profesionales de la salud en la identificación de pacientes en riesgo y en la personalización de tratamientos.  \n",
        "\n",
        "Sin embargo, el dataset presenta desafíos clave:  \n",
        "1. **Desbalance de clases**: Solo el **8.5%** de las muestras corresponden a casos positivos (diabetes), lo que puede sesgar el entrenamiento de modelos tradicionales.  \n",
        "2. **Variables categóricas**: Género y historial de tabaquismo requieren codificación adecuada (ej.: one-hot encoding).  \n",
        "3. **Tamaño del dataset**: Con **100,000 muestras**, es necesario evaluar si una arquitectura MLP puede capturar patrones complejos sin sobreajuste.  \n",
        "\n",
        "<h2>Objetivos</h2>\n",
        "\n",
        "1. **Diseñar arquitecturas MLP** eficientes para clasificación binaria, explorando diferentes arquitecturas (capas ocultas, neuronas, funciones de activación).  \n",
        "2. **Manejar el desbalance de clases** mediante:\n",
        "   - Reponderación con `class_weight` en Keras (ej.: `{0: 1.0, 1: 12.0}`).  \n",
        "   - Evaluación con métricas robustas (**Recall, F1-Score, AUC-ROC**) en lugar de *accuracy*.\n",
        "3. **Preprocesar variables categóricas** y numéricas para garantizar su compatibilidad con la MLP.\n",
        "4. **Validar la escalabilidad** de la MLP con datasets de tamaño medio (100k muestras), monitoreando tiempos de entrenamiento y uso de recursos.\n",
        "\n",
        "Este proyecto busca demostrar cómo una red neuronal básica (MLP) puede ser competitiva en problemas médicos reales, incluso con datos desbalanceados y heterogéneos, proporcionando un *baseline* para comparaciones con modelos más complejos (ej.: XGBoost, Redes Convolucionales).  \n",
        "\n",
        "https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset"
      ],
      "metadata": {
        "id": "wHK7GBmzJ86Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-instalamos keras para evitar el warning de la importación"
      ],
      "metadata": {
        "id": "o5e359HTVKPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq keras"
      ],
      "metadata": {
        "id": "KberOIoIZ99M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos directamente de kaggle el dataset"
      ],
      "metadata": {
        "id": "h76fcx_9VN2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "#--------- Este código lo copiamos desde Kaggle -----------\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"iammustafatz/diabetes-prediction-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "path = os.path.join(path, 'diabetes_prediction_dataset.csv') # Unimos la ruta de descarga con el nombre de archivo\n",
        "df = pd.read_csv(path) # Leemos el dataset\n",
        "df"
      ],
      "metadata": {
        "id": "RIrfySAaJCIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 Veamos que no hay datos faltantes"
      ],
      "metadata": {
        "id": "rtIMUcZmVq3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['gender'].unique())\n",
        "print(df['smoking_history'].unique())"
      ],
      "metadata": {
        "id": "aRjl6zfZY075"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "wYah1Vd7Y_KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔴 Haz codificación *one-hot* para las variables categóricas. No olvides usar `dtype=int` y `drop_first=True`."
      ],
      "metadata": {
        "id": "9WN3bgYMV9eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df ="
      ],
      "metadata": {
        "id": "e1lW3HOWY5TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 Dividamos el conjunto de entrenamiento en *train/validation/test*"
      ],
      "metadata": {
        "id": "n09l_HDYVyiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('diabetes', axis=1).values\n",
        "y = df['diabetes'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.15,\n",
        "                                                    stratify = y,\n",
        "                                                    random_state=423)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=0.2,\n",
        "                                                  stratify = y_train,\n",
        "                                                  random_state=423)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "hSuaBIhQJxP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 Visualizar el balance de clases"
      ],
      "metadata": {
        "id": "aqSlSu5gV3v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import countplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ratio = y[y == 1].shape[0] / y.shape[0]\n",
        "\n",
        "plt.figure()\n",
        "plt.title(f'Balance de clases\\nClase positiva {ratio} del total')\n",
        "countplot(data=df,x='diabetes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "56ZtC-PEfvpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 Probemos esta estrategia para el desbalanceo de clases. Consiste en calcular pesos para las clases, de acuerdo al desbalanceo. Posteriormente se usan esos pesos para ponderar las métricas durante el entrenamiento."
      ],
      "metadata": {
        "id": "YLqf4tGmWQHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                     classes=np.unique(y_train),\n",
        "                                     y=y_train)\n",
        "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
        "class_weights"
      ],
      "metadata": {
        "id": "3wWmAMGuhKxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔴 Haz re-escalamiento `MinMaxScaler`. No olvides evitar el *data leakage*"
      ],
      "metadata": {
        "id": "jVnKLp4kWfnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n"
      ],
      "metadata": {
        "id": "JWPMUKimZZfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔴 Define una red neuronal con la clase `Sequential` de Keras para este problema\n",
        "\n",
        "* Define la capa de entrada adaptada al número de features\n",
        "* Define el número de capas ocultas y la cantidad de neuronas en cada una de ellas, usa la activación `relu`.\n",
        "* Define la capa de salida adecuada para la clasificación binaria.\n",
        "* Compila el modelo con la métrica Recall (por el desbalaceo de clases), define el compilador y la función de perdida adecuada para la clasificación binaria.\n",
        "\n",
        "<br>\n",
        "\n",
        "----\n",
        "<br>\n",
        "\n",
        "Una guía general sobre funciones de perdida y métricas\n",
        "\n",
        "<br>\n",
        "\n",
        "| Aplicación                     | Función de Pérdida (Loss)          | Métrica usual           | Última capa (output layer)          |\n",
        "|---------------------------------|------------------------------------|-------------------------|-------------------------------------|\n",
        "| Clasificación binaria          | `binary_crossentropy`              | `accuracy`              | `Dense(1, activation='sigmoid')`    |\n",
        "| Clasificación multiclase       | `categorical_crossentropy`         | `accuracy`              | `Dense(num_clases, activation='softmax')` |\n",
        "| Regresión (un valor)           | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(1, activation='linear')`     |\n",
        "| Regresión (múltiples valores)  | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(num_valores, activation='linear')` |\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "Una guía general sobre optimizadores:\n",
        "\n",
        "<br>\n",
        "\n",
        "| Optimizador  | Ventajas                             | Casos de Uso Típicos         | Parámetros Clave               |\n",
        "|--------------|--------------------------------------|------------------------------|--------------------------------|\n",
        "| **Adam**     | Convergencia rápida, adaptable      | Default para MLPs, CNN, RNN  | `lr`  |\n",
        "| **SGD**      | Mayor control, estable con momentum | Problemas convexos, fine-tuning | `lr`, `momentum`      |\n",
        "| **RMSprop**  | Bueno para datos ruidosos           | RNNs, problemas inestables    | `lr`, `rho`          |\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "qFePEiWr6t4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "#----- Completa --------\n",
        "model = ...\n",
        "\n",
        "\n",
        "#-----------------------\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lUu0ofSSZ_Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔴 Entrena el modelo\n",
        "\n",
        "* Elige, al menos 20 épocas.\n",
        "* Usa el hiperparámetro `class_weight=class_weights`.\n",
        "* Usa el hiperparámetro `batch_size=256` o `batch_size=32`. Observa la diferencia en tiempo de entrenamiento.\n",
        "* Usa el conjunto de validación como `validation_data`.\n",
        "\n",
        "Recuerda almancenar el registro de entrenamiento en la variable `history`."
      ],
      "metadata": {
        "id": "Fz9kMh22_7os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = ..."
      ],
      "metadata": {
        "id": "yqgBWbXUaNN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 Graficamos las curvas de entrenamiento"
      ],
      "metadata": {
        "id": "dVV1gyN3Htxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "axs[1].plot(history.history['recall'])\n",
        "axs[1].plot(history.history['val_recall'])\n",
        "axs[1].set_title('Model Recall')\n",
        "axs[1].set_ylabel('Recall')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].legend(['Train', 'Validation'], loc='upper left')\n",
        "axs[0].plot(history.history['loss'])\n",
        "axs[0].plot(history.history['val_loss'])\n",
        "axs[0].set_title('Model Loss')\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].legend(['Train', 'Validation'], loc='upper left')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fDnINAyXaT68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔴 Obten las predicciones del modelo para el conjunto de prueba. Impríme el arreglo, ¿qué interpretación tienen los valores que observas?"
      ],
      "metadata": {
        "id": "2tOxuFXXIPnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred ="
      ],
      "metadata": {
        "id": "mTttAvL4ITh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 Obten las predicciones como valores de clase"
      ],
      "metadata": {
        "id": "L-LRShdeIdbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "DcK97Fg1IhvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔴 Mide el rendimiento del modelo en el conjunto de prueba. Reporta las métricas:\n",
        "\n",
        "* Accuracy\n",
        "* Recall\n",
        "* Precision\n",
        "* F1 Score"
      ],
      "metadata": {
        "id": "TJWxnoIVImoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "xSmex5XSImA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 Muestra la matriz de confusión"
      ],
      "metadata": {
        "id": "qZQAiNhcU8Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "39eZKaiYafjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔴 **OPCIONAL** Como comparación, realiza la misma tarea de clasificación binaria entrenando un clasificador de Machine Learning clásico (de scikit-learn).\n",
        "\n",
        "Reporta la mismas métricas y la matriz de confusión.\n",
        "\n",
        "* ¿Cuál tuvo mejor rendimiento?\n",
        "* ¿Cuál tardo más en entrenarse?"
      ],
      "metadata": {
        "id": "5xjW4MUbWxqt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mprW8jbuw7dW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}