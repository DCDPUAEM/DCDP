{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/02-MLP-Clasificacion-Binaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "DoFG1IdbXRc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicci贸n de Diabetes con MLP  \n",
        "\n",
        "<h2>Introducci贸n</h2>\n",
        "\n",
        "La diabetes es una enfermedad cr贸nica que afecta a millones de personas en el mundo, y su detecci贸n temprana es crucial para prevenir complicaciones graves. El *Diabetes Prediction Dataset* proporciona informaci贸n m茅dica y demogr谩fica de pacientes, incluyendo variables como edad, g茅nero, 铆ndice de masa corporal (IMC), niveles de HbA1c, glucosa en sangre, historial de hipertensi贸n, enfermedades card铆acas y h谩bitos de tabaquismo. Este conjunto de datos permite desarrollar modelos de aprendizaje autom谩tico para predecir el diagn贸stico de diabetes (clasificaci贸n binaria: positivo/negativo), apoyando a profesionales de la salud en la identificaci贸n de pacientes en riesgo y en la personalizaci贸n de tratamientos.  \n",
        "\n",
        "Sin embargo, el dataset presenta desaf铆os clave:  \n",
        "1. **Desbalance de clases**: Solo el **8.5%** de las muestras corresponden a casos positivos (diabetes), lo que puede sesgar el entrenamiento de modelos tradicionales.  \n",
        "2. **Variables categ贸ricas**: G茅nero y historial de tabaquismo requieren codificaci贸n adecuada (ej.: one-hot encoding).  \n",
        "3. **Tama帽o del dataset**: Con **100,000 muestras**, es necesario evaluar si una arquitectura MLP puede capturar patrones complejos sin sobreajuste.  \n",
        "\n",
        "<h2>Objetivos</h2>\n",
        "\n",
        "1. **Dise帽ar arquitecturas MLP** eficientes para clasificaci贸n binaria, explorando diferentes arquitecturas (capas ocultas, neuronas, funciones de activaci贸n).  \n",
        "2. **Manejar el desbalance de clases** mediante:\n",
        "   - Reponderaci贸n con `class_weight` en Keras (ej.: `{0: 1.0, 1: 12.0}`).  \n",
        "   - Evaluaci贸n con m茅tricas robustas (**Recall, F1-Score, AUC-ROC**) en lugar de *accuracy*.\n",
        "3. **Preprocesar variables categ贸ricas** y num茅ricas para garantizar su compatibilidad con la MLP.\n",
        "4. **Validar la escalabilidad** de la MLP con datasets de tama帽o medio (100k muestras), monitoreando tiempos de entrenamiento y uso de recursos.\n",
        "\n",
        "Este proyecto busca demostrar c贸mo una red neuronal b谩sica (MLP) puede ser competitiva en problemas m茅dicos reales, incluso con datos desbalanceados y heterog茅neos, proporcionando un *baseline* para comparaciones con modelos m谩s complejos (ej.: XGBoost, Redes Convolucionales).  \n",
        "\n",
        "https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset"
      ],
      "metadata": {
        "id": "wHK7GBmzJ86Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-instalamos keras para evitar el warning de la importaci贸n"
      ],
      "metadata": {
        "id": "o5e359HTVKPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq keras"
      ],
      "metadata": {
        "id": "KberOIoIZ99M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos directamente de kaggle el dataset"
      ],
      "metadata": {
        "id": "h76fcx_9VN2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "#--------- Este c贸digo lo copiamos desde Kaggle -----------\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"iammustafatz/diabetes-prediction-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "path = os.path.join(path, 'diabetes_prediction_dataset.csv') # Unimos la ruta de descarga con el nombre de archivo\n",
        "df = pd.read_csv(path) # Leemos el dataset\n",
        "df"
      ],
      "metadata": {
        "id": "RIrfySAaJCIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Veamos que no hay datos faltantes"
      ],
      "metadata": {
        "id": "rtIMUcZmVq3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['gender'].unique())\n",
        "print(df['smoking_history'].unique())"
      ],
      "metadata": {
        "id": "aRjl6zfZY075"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "wYah1Vd7Y_KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Haz codificaci贸n *one-hot* para las variables categ贸ricas. No olvides usar `dtype=int` y `drop_first=True`."
      ],
      "metadata": {
        "id": "9WN3bgYMV9eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df ="
      ],
      "metadata": {
        "id": "e1lW3HOWY5TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Dividamos el conjunto de entrenamiento en *train/validation/test*"
      ],
      "metadata": {
        "id": "n09l_HDYVyiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('diabetes', axis=1).values\n",
        "y = df['diabetes'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.15,\n",
        "                                                    stratify = y,\n",
        "                                                    random_state=423)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=0.2,\n",
        "                                                  stratify = y_train,\n",
        "                                                  random_state=423)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "hSuaBIhQJxP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Visualizar el balance de clases"
      ],
      "metadata": {
        "id": "aqSlSu5gV3v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import countplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ratio = y[y == 1].shape[0] / y.shape[0]\n",
        "\n",
        "plt.figure()\n",
        "plt.title(f'Balance de clases\\nClase positiva {ratio} del total')\n",
        "countplot(data=df,x='diabetes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "56ZtC-PEfvpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Probemos esta estrategia para el desbalanceo de clases. Consiste en calcular pesos para las clases, de acuerdo al desbalanceo. Posteriormente se usan esos pesos para ponderar las m茅tricas durante el entrenamiento."
      ],
      "metadata": {
        "id": "YLqf4tGmWQHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                     classes=np.unique(y_train),\n",
        "                                     y=y_train)\n",
        "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
        "class_weights"
      ],
      "metadata": {
        "id": "3wWmAMGuhKxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Haz re-escalamiento `MinMaxScaler`. No olvides evitar el *data leakage*"
      ],
      "metadata": {
        "id": "jVnKLp4kWfnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n"
      ],
      "metadata": {
        "id": "JWPMUKimZZfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define una red neuronal con la clase `Sequential` de Keras para este problema\n",
        "\n",
        "* Define la capa de entrada adaptada al n煤mero de features\n",
        "* Define el n煤mero de capas ocultas y la cantidad de neuronas en cada una de ellas, usa la activaci贸n `relu`.\n",
        "* Define la capa de salida adecuada para la clasificaci贸n binaria.\n",
        "* Compila el modelo con la m茅trica Recall (por el desbalaceo de clases), define el compilador y la funci贸n de perdida adecuada para la clasificaci贸n binaria.\n",
        "\n",
        "<br>\n",
        "\n",
        "----\n",
        "<br>\n",
        "\n",
        "Una gu铆a general sobre funciones de perdida y m茅tricas\n",
        "\n",
        "<br>\n",
        "\n",
        "| Aplicaci贸n                     | Funci贸n de P茅rdida (Loss)          | M茅trica usual           | ltima capa (output layer)          |\n",
        "|---------------------------------|------------------------------------|-------------------------|-------------------------------------|\n",
        "| Clasificaci贸n binaria          | `binary_crossentropy`              | `accuracy`              | `Dense(1, activation='sigmoid')`    |\n",
        "| Clasificaci贸n multiclase       | `categorical_crossentropy`         | `accuracy`              | `Dense(num_clases, activation='softmax')` |\n",
        "| Regresi贸n (un valor)           | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(1, activation='linear')`     |\n",
        "| Regresi贸n (m煤ltiples valores)  | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(num_valores, activation='linear')` |\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "Una gu铆a general sobre optimizadores:\n",
        "\n",
        "<br>\n",
        "\n",
        "| Optimizador  | Ventajas                             | Casos de Uso T铆picos         | Par谩metros Clave               |\n",
        "|--------------|--------------------------------------|------------------------------|--------------------------------|\n",
        "| **Adam**     | Convergencia r谩pida, adaptable      | Default para MLPs, CNN, RNN  | `lr`  |\n",
        "| **SGD**      | Mayor control, estable con momentum | Problemas convexos, fine-tuning | `lr`, `momentum`      |\n",
        "| **RMSprop**  | Bueno para datos ruidosos           | RNNs, problemas inestables    | `lr`, `rho`          |\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "qFePEiWr6t4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "#----- Completa --------\n",
        "model = ...\n",
        "\n",
        "\n",
        "#-----------------------\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lUu0ofSSZ_Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Entrena el modelo\n",
        "\n",
        "* Elige, al menos 20 茅pocas.\n",
        "* Usa el hiperpar谩metro `class_weight=class_weights`.\n",
        "* Usa el hiperpar谩metro `batch_size=256` o `batch_size=32`. Observa la diferencia en tiempo de entrenamiento.\n",
        "* Usa el conjunto de validaci贸n como `validation_data`.\n",
        "\n",
        "Recuerda almancenar el registro de entrenamiento en la variable `history`."
      ],
      "metadata": {
        "id": "Fz9kMh22_7os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = ..."
      ],
      "metadata": {
        "id": "yqgBWbXUaNN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Graficamos las curvas de entrenamiento"
      ],
      "metadata": {
        "id": "dVV1gyN3Htxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "axs[1].plot(history.history['recall'])\n",
        "axs[1].plot(history.history['val_recall'])\n",
        "axs[1].set_title('Model Recall')\n",
        "axs[1].set_ylabel('Recall')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].legend(['Train', 'Validation'], loc='upper left')\n",
        "axs[0].plot(history.history['loss'])\n",
        "axs[0].plot(history.history['val_loss'])\n",
        "axs[0].set_title('Model Loss')\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].legend(['Train', 'Validation'], loc='upper left')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fDnINAyXaT68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Obten las predicciones del modelo para el conjunto de prueba. Impr铆me el arreglo, 驴qu茅 interpretaci贸n tienen los valores que observas?"
      ],
      "metadata": {
        "id": "2tOxuFXXIPnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred ="
      ],
      "metadata": {
        "id": "mTttAvL4ITh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Obten las predicciones como valores de clase"
      ],
      "metadata": {
        "id": "L-LRShdeIdbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "DcK97Fg1IhvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Mide el rendimiento del modelo en el conjunto de prueba. Reporta las m茅tricas:\n",
        "\n",
        "* Accuracy\n",
        "* Recall\n",
        "* Precision\n",
        "* F1 Score"
      ],
      "metadata": {
        "id": "TJWxnoIVImoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "xSmex5XSImA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Muestra la matriz de confusi贸n"
      ],
      "metadata": {
        "id": "qZQAiNhcU8Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "39eZKaiYafjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **OPCIONAL** Como comparaci贸n, realiza la misma tarea de clasificaci贸n binaria entrenando un clasificador de Machine Learning cl谩sico (de scikit-learn).\n",
        "\n",
        "Reporta la mismas m茅tricas y la matriz de confusi贸n.\n",
        "\n",
        "* 驴Cu谩l tuvo mejor rendimiento?\n",
        "* 驴Cu谩l tardo m谩s en entrenarse?"
      ],
      "metadata": {
        "id": "5xjW4MUbWxqt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mprW8jbuw7dW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}